import os
from pathlib import Path
from typing import List
from dotenv import load_dotenv
from langchain_core.documents import Document
from mcp.server.fastmcp import FastMCP
from rag import KBSRetrievalChain
import config
import glob
import pickle
from langchain_teddynote import logging

load_dotenv()
DB_DIR = Path(config.DB_DIR)
PARSING_OUTPUT_DIR = Path(config.PARSING_OUTPUT_KBS_DIR)

logging.langsmith(project_name="htm-mcp-server")

def load_documents_from_pkl(filepath):
    """
    Pickle íŒŒì¼ì—ì„œ Langchain Document ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜

    Args:
        filepath: ì›ë³¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: path/to/filename.pdf)
    Returns:
        Langchain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    # í™•ìž¥ìž ì œê±°í•˜ê³  ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    abs_path = os.path.abspath(filepath)
    base_path = os.path.splitext(abs_path)[0]
    pkl_path = f"{base_path}.pkl"

    with open(pkl_path, "rb") as f:
        documents = pickle.load(f)
    return documents

# load documentts from parsing_outputs
pkl_files = glob.glob(str(PARSING_OUTPUT_DIR / "*.pkl"))

if not pkl_files:
    print("âŒ PARSING_OUTPUT_DIRì—ì„œ .pkl íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ëª¨ë“  .pkl íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ
    all_documents = []
    for pkl_file in pkl_files:
        print(f"ðŸ“„ {pkl_file} íŒŒì¼ ë¡œë“œ ì¤‘...")  # í•œêµ­ì–´ ì½”ë©˜íŠ¸
        documents = load_documents_from_pkl(pkl_file)
        all_documents.extend(documents)

    print(f"âœ… ì´ {len(all_documents)}ê°œì˜ ë¬¸ì„œê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

rag_chain = KBSRetrievalChain(
    persist_directory = str(DB_DIR),
    db_index_name = config.DB_INDEX_NAME,
    k = config.DEFAULT_TOP_K,
    split_docs = all_documents,
).initialize()

mcp = FastMCP(
    name="í‚¹ë¤ë¹Œë”ìŠ¤ì¿¨(KBS) ê²€ìƒ‰(RAG)",
    version="0.0.1",
    description="í‚¹ë¤ë¹Œë”ìŠ¤ì¿¨(KBS) ê²€ìƒ‰(RAG)",
    host="0.0.0.0",  # Host address (0.0.0.0 allows connections from any IP)
    port=8001 
)

def format_search_results(docs: List[Document]) -> str:
    """
    Format search results as markdown.
    
    Args:
        docs: List of documents to format
        
    Returns:
        Markdown formatted search results

    """

    if not docs:
        return "No relevant information found."
    
    markdown_results = "## Search Results\n\n"
    
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get("source", "Unknown source")
        page = doc.metadata.get("page", None)
        page_info = f" (Page: {page+1})" if page is not None else ""
        
        markdown_results += f"### Result {i}{page_info}\n\n"
        markdown_results += f"{doc.page_content}\n\n"
        markdown_results += f"Source: {source}\n\n"
        markdown_results += "---\n\n"
    
    return markdown_results

def format_search_results_with_image_metadata(docs: List[Document]) -> str:
    """
    ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ë¥¼ í™œìš©í•œ ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ…
    """
    if not docs:
        return "No relevant information found."
    
    markdown_results = "## Search Results\n\n"
    
    for i, doc in enumerate(docs, 1):
        source = doc.metadata.get("source", "Unknown source")
        page = doc.metadata.get("page", None)
        page_info = f" (Page: {page+1})" if page is not None else ""
        
        markdown_results += f"### Result {i}{page_info}\n\n"
        markdown_results += f"{doc.page_content}\n\n"
        
        # ì´ë¯¸ì§€ ì •ë³´ê°€ ìžˆëŠ” ê²½ìš° ì¶”ê°€
        if "images" in doc.metadata:
            images = doc.metadata["images"]
            if images:
                markdown_results += "**Related Images:**\n"
                for img in images:
                    markdown_results += f"- {img}\n"
                markdown_results += "\n"
        
        markdown_results += f"Source: {source}\n\n"
        markdown_results += "---\n\n"

        print(markdown_results)
    
    return markdown_results

# @mcp.tool()
# async def keyword_search(query: str, top_k: int = 3) -> str:
#     """
#     Performs keyword-based search on PDF documents.
#     Returns the most relevant results based on exact word/phrase matches.
#     Ideal for finding specific terms, definitions, or exact phrases in documents.
    
#     Parameters:
#         query: Search query
#         top_k: Number of results to return

#     """

#     try:
#         results = rag_chain.search_keyword(query, top_k)
#         return format_search_results(results)
#     except Exception as e:
#         return f"An error occurred during search: {str(e)}"

# @mcp.tool()
# async def semantic_search(query: str, top_k: int = 3) -> str:
#     """
#     Performs semantic search on PDF documents.
#     Finds content semantically similar to the query, delivering relevant information even without exact word matches.
#     Best for conceptual questions, understanding themes, or when you need information related to a topic.
    
#     Parameters:
#         query: Search query
#         top_k: Number of results to return

#     """

#     try:
#         results = rag_chain.search_semantic(query, top_k)
#         return format_search_results(results)
#     except Exception as e:
#         return f"An error occurred during search: {str(e)}"

@mcp.tool()
async def search(query: str, top_k: int = 4) -> str:
    """
    Performs hybrid search (keyword + semantic) on MD documents.
    Combines exact keyword matching and semantic similarity to deliver optimal results.
    The most versatile search option for general questions or when unsure which search type is best.
    
    Parameters:
        query: Search query
        top_k: Number of results to return

    """

    try:
        results = rag_chain.search_hybrid(query, top_k)
        # print(results)
        return format_search_results_with_image_metadata(results)
    except Exception as e:
        return f"An error occurred during search: {str(e)}"

if __name__ == "__main__":
    mcp.run('sse')