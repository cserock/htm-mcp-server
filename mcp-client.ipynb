{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP + LangGraph Client Example\n",
    "\n",
    "**ì°¸ê³ ìë£Œ**\n",
    "- https://modelcontextprotocol.io/introduction\n",
    "- https://github.com/langchain-ai/langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ì„¤ì •\n",
    "\n",
    "ì•„ë˜ ì„¤ì¹˜ ë°©ë²•ì„ ì°¸ê³ í•˜ì—¬ `uv` ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "**uv ì„¤ì¹˜ ë°©ë²•**\n",
    "\n",
    "```bash\n",
    "# macOS/Linux\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Windows (PowerShell)\n",
    "irm https://astral.sh/uv/install.ps1 | iex\n",
    "```\n",
    "\n",
    "**ì˜ì¡´ì„± ì„¤ì¹˜**\n",
    "\n",
    "```bash\n",
    "uv pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í™˜ê²½ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ì— `mcp_server_remote.py` ë¥¼ ì‹¤í–‰í•´ë‘¡ë‹ˆë‹¤. í„°ë¯¸ë„ì„ ì—´ê³  ê°€ìƒí™˜ê²½ì´ í™œì„±í™” ë˜ì–´ ìˆëŠ” ìƒíƒœì—ì„œ ì„œë²„ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "> ëª…ë ¹ì–´\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "python mcp_server_remote.py\n",
    "```\n",
    "\n",
    "`async with` ë¡œ ì¼ì‹œì ì¸ Session ì—°ê²°ì„ ìƒì„± í›„ í•´ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='search', description='\\n    Performs hybrid search (keyword + semantic) on MD documents.\\n    Combines exact keyword matching and semantic similarity to deliver optimal results.\\n    The most versatile search option for general questions or when unsure which search type is best.\\n    \\n    Parameters:\\n        query: Search query\\n        top_k: Number of results to return\\n\\n    ', args_schema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'top_k': {'default': 4, 'title': 'Top K', 'type': 'integer'}}, 'required': ['query'], 'title': 'searchArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x10ed5d440>)]\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "## Search Results\n",
      "\n",
      "### Result 1 (Page: 325)\n",
      "\n",
      "ìš”17:21-23 ì•„ë²„ì§€ì—¬, ì•„ë²„ì§€ê»˜ì„œ ë‚´ ì•ˆì—, ë‚´ê°€ ì•„ë²„ì§€ ì•ˆì— ìˆëŠ” ê²ƒ ê°™ì´ ê·¸ë“¤ë„ ë‹¤ í•˜ë‚˜ê°€ ë˜ì–´ ìš°ë¦¬ ì•ˆì— ìˆê²Œ\n",
      "í•˜ì‚¬ ì„¸ìƒìœ¼ë¡œ ì•„ë²„ì§€ê»˜ì„œ ë‚˜ë¥¼ ë³´ë‚´ì‹  ê²ƒì„ ë¯¿ê²Œ í•˜ì˜µì†Œì„œ (22)ë‚´ê²Œ ì£¼ì‹  ì˜ê´‘ì„ ë‚´ê°€ ê·¸ë“¤ì—ê²Œ ì£¼ì—ˆì‚¬ì˜¤ë‹ˆ ì´ëŠ” ìš°\n",
      "ë¦¬ê°€ í•˜ë‚˜ê°€ ëœ ê²ƒ ê°™ì´ ê·¸ë“¤ë„ í•˜ë‚˜ê°€ ë˜ê²Œ í•˜ë ¤ í•¨ì´ë‹ˆì´ë‹¤ (23)ê³§ ë‚´ê°€ ê·¸ë“¤ ì•ˆì— ìˆê³  ì•„ë²„ì§€ê»˜ì„œ ë‚´ ì•ˆì— ê³„ì‹œ\n",
      "ì–´ ê·¸ë“¤ë¡œ ì˜¨ì „í•¨ì„ ì´ë£¨ì–´ í•˜ë‚˜ê°€ ë˜ê²Œ í•˜ë ¤ í•¨ì€ ì•„ë²„ì§€ê»˜ì„œ ë‚˜ë¥¼ ë³´ë‚´ì‹  ê²ƒê³¼ ë˜ ë‚˜ë¥¼ ì‚¬ë‘í•˜ì‹¬ ê°™ì´ ê·¸ë“¤ë„ ì‚¬ë‘\n",
      "í•˜ì‹  ê²ƒì„ ì„¸ìƒìœ¼ë¡œ ì•Œê²Œ í•˜ë ¤ í•¨ì´ë¡œì†Œì´ë‹¤\n",
      "* ë¶€ë¥´ì‹¬ì˜ ìë¦¬ì™€ ì˜ì  ê³µë™ì²´ì— ëŒ€í•´ ì¢€ ë” ì•Œê¸° ì›í•˜ëŠ” ë¶„ì€\n",
      "ã€í‚¹ë¤ë¹Œë”(ê·œì¥)ã€ì±… ì°¸ì¡°\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 2 (Page: 292)\n",
      "\n",
      "# â…£. í‚¹ë¤ ë¯¿ìŒì²´ê³„ì™€ ë©˜íƒˆë¦¬í‹°\n",
      "1\n",
      "# ì‹¬ì¤‘ì„ ìƒˆë¡­ê²Œ í•˜ê¸°(ë¯¿ìŒì²´ê³„ í™•ë¦½)\n",
      "ì•½1:2 ê·¸ëŸ¬ë¯€ë¡œ ëª¨ë“  ë”ëŸ¬ìš´ ê²ƒê³¼ ë„˜ì¹˜ëŠ” ì•…ì„ ë‚´ë²„ë¦¬ê³  ë„ˆí¬ ì˜í˜¼ì„ ëŠ¥íˆ êµ¬ì›í•  ë°” ë§ˆìŒ(í—¬, ì¹´ë¥´ë””ì•„: ì‹¬ì¤‘)ì— ì‹¬\n",
      "ì–´ì§„ ë§ì”€ì„ ì˜¨ìœ í•¨ìœ¼ë¡œ ë°›ìœ¼ë¼\n",
      "ì•½4:8 í•˜ë‚˜ë‹˜ì„ ê°€ê¹Œì´í•˜ë¼ ê·¸ë¦¬í•˜ë©´ ë„ˆí¬ë¥¼ ê°€ê¹Œì´í•˜ì‹œë¦¬ë¼ ì£„ì¸ë“¤ì•„ ì†ì„ ê¹¨ë—ì´ í•˜ë¼ ë‘ ë§ˆìŒ(í—¬, ë’µì‹œì½”ìŠ¤: ë‘\n",
      "í˜¼)ì„ í’ˆì€ ìë“¤ì•„ ë§ˆìŒ(í—¬, ì¹´ë¥´ë””ì•„: ì‹¬ì¤‘)ì„ ì„±ê²°í•˜ê²Œ í•˜ë¼\n",
      "# í‚¹ë¤ ë¯¿ìŒì²´ê³„ í™•ë¦½ì„ ìœ„í•œ 7ê°€ì§€ ì•Œì•½ ë¨¹ê¸°\n",
      "ë‚˜ëŠ” ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ ì•ˆì—ì„œ\n",
      "1) ë¬´í•œí•˜ì‹  í•˜ë‚˜ë‹˜ì˜ ì§€í˜œì™€ ëŠ¥ë ¥ì„ ëˆ„ë¦½ë‹ˆë‹¤.\n",
      "2) í•­ìƒ ê¸°ë»í•˜ê³  ë²”ì‚¬ì— ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "3) ë§í•  ìˆ˜ ì—†ëŠ” ì€í˜œì™€ í‰ê°•ì„ ëˆ„ë¦½ë‹ˆë‹¤.\n",
      "4) ì–¸ì œë‚˜ ì¸ë‚´ë¥¼ í†µí•˜ì—¬ ì˜¨ì „í•¨ì„ ëˆ„ë¦½ë‹ˆë‹¤.\n",
      "5) ë§ì”€ëŒ€ë¡œ ë§í•¨ìœ¼ë¡œ ì£¼ì˜ ëœ»ì„ ì´ë£¹ë‹ˆë‹¤.\n",
      "6) ëŠ˜ ì‹ ì„±í•œ ê°•ê±´í•¨ê³¼ ììœ ë¥¼ ëˆ„ë¦½ë‹ˆë‹¤.\n",
      "7) ì°¨ê³  ë„˜ì¹˜ëŠ” ë¶€ìš”ì™€ í˜•í†µì„ ëˆ„ë¦½ë‹ˆë‹¤.\n",
      "2\n",
      "# í‚¹ë¤ ë©˜íƒˆë¦¬í‹°\n",
      "# 1) í‚¹ë¤ ë©˜íƒˆë¦¬í‹°ë€?\n",
      "í‚¹ë¤ ë©˜íƒˆë¦¬í‹°(Kingdom Mentality: í•˜ë‚˜ë‹˜ë‚˜ë¼ì˜ ì‚¬ê³ ë°©ì‹)ëŠ” ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ ì•ˆì—ì„œ ì„±ë ¹ì„ í†µí•˜ì—¬ í•˜\n",
      "ë‚˜ë‹˜ í†µì¹˜ì˜ ê´€ì ìœ¼ë¡œ ë³´ëŠ” ì‚¬ê³ ë°©ì‹ì´ë‹¤. ì˜ˆìˆ˜ë‹˜ê»˜ì„œ ë§ì”€í•˜ì‹œê³  ê°€ë¥´ì³ ì£¼ì‹  ê²ƒë“¤ì€ ì˜¤ëŠ˜ë‚ ë„ ì„±ë ¹ë‹˜\n",
      "ì„ í†µí•´ì„œ ì•Œê²Œ ë˜ê³  ë°°ìš¸ ìˆ˜ ìˆì§€ë§Œ, í‚¹ë¤ ë©˜íƒˆë¦¬í‹° êµíšŒì˜ êµë¦¬ì™€ ì „í†µìœ¼ë¡œ ì¸í•˜ì—¬ ì•„ì§ ì œëŒ€ë¡œ ìˆ˜ìš©í•˜\n",
      "ì§€ ëª»í•˜ëŠ” â€œì„±ë ¹ë‹˜ì˜ ì¸ë„í•˜ì‹¬â€ê³¼ â€œì„±ë ¹ì˜ ê¶ŒëŠ¥ ì•ˆì—ì„œ ë§ì”€ì˜ í’€ì–´ì§â€, â€œì„±ë ¹ë‹˜ì˜ ë‚˜íƒ€ë‚˜ì‹¬ê³¼ í˜„\n",
      "ì¬ì  ì—­ì‚¬â€ì— ì ê·¹ì ìœ¼ë¡œ ì˜ì§€í•˜ëŠ” ì‚¬ê³ ë°©ì‹ì´ë‹¤. ë˜í•œ, í•˜ë‚˜ë‹˜ì„ ì˜í™”ë¡­ê²Œ í•˜ê³  í•˜ë‚˜ë‹˜ì˜ ëœ»ì„ ì´ ë•…\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 3 (Page: 110)\n",
      "\n",
      "ë¡¬ 8:9 ë§Œì¼ ë„ˆí¬ ì†ì— í•˜ë‚˜ë‹˜ì˜ ì˜ì´ ê±°í•˜ì‹œë©´ ë„ˆí¬ê°€ ìœ¡ì‹ ì— ìˆì§€ ì•„ë‹ˆí•˜ê³  ì˜ì— ìˆë‚˜ë‹ˆ ëˆ„êµ¬ë“ ì§€ ê·¸ë¦¬ìŠ¤ë„ì˜ ì˜\n",
      "ì´ ì—†ìœ¼ë©´ ê·¸ë¦¬ìŠ¤ë„ì˜ ì‚¬ëŒì´ ì•„ë‹ˆë¼\n",
      "â€œìš°ë¦¬ë¡œ ë˜í•œ ìƒˆ ìƒëª… ê°€ìš´ë°ì„œâ€\n",
      "ìƒˆ ìƒëª…(a new life)ì´ë€ ë‹¨ìˆœí•œ ìƒˆ ìƒëª…ì´ ì•„ë‹ˆë¼ ìƒëª…ì˜ ì§ˆì ì¸ ë³€í™”ë¥¼ ì˜ë¯¸(newness of life)í•œë‹¤. ì´\n",
      "ê²ƒì€ ìƒˆë¡œìš´ í”¼ì¡°ë¬¼(ê³ í›„5:17), ìƒˆ ì‚¬ëŒ(ì—¡4:24)ì—ì„œë„ ë™ì¼í•˜ë‹¤. ì´ê²ƒì€ ìš°ë¦¬ì˜ íƒ€ë½í•œ ì˜ì´ ìƒˆë¡œì›Œì§€ëŠ”\n",
      "ê²ƒì´ ì•„ë‹ˆë¼ ë³¸ì§ˆì ìœ¼ë¡œ ë‹¤ë¥¸ ê·¸ë¦¬ìŠ¤ë„ì˜ ìƒëª…ìœ¼ë¡œ ë‹¤ì‹œ íƒœì–´ë‚œë‹¤ëŠ” ëœ»ì´ë‹¤.\n",
      "ë”°ë¼ì„œ â€œìƒˆ ìƒëª… ê°€ìš´ë°ì„œ í–‰í•œë‹¤â€ë¼ëŠ” ì˜ë¯¸ëŠ” ì„¸ìƒì— ë¬¶ì—¬ ìˆëŠ” ë§ˆìŒìœ¼ë¡œ í˜•ì„±ëœ ìê¸°ì˜ì‹ì´ ë‚´ ì‚¶\n",
      "ì˜ ì£¼ì¸ì´ ì•„ë‹ˆê³ , ë‚´ ì•ˆì— ê³„ì‹  ê·¸ë¦¬ìŠ¤ë„ì˜ ìƒëª…ìœ¼ë¡œ ë§ë¯¸ì•”ì•„ ê·¸ë¦¬ìŠ¤ë„ ì˜ì‹ì„ ê°€ì§„ ì°¸ ìì•„ê°€ í•˜ë‚˜ë‹˜\n",
      "ì˜ ì˜ìœ¼ë¡œë¶€í„° ì£¼ì–´ì§€ëŠ” ì§„ë¦¬ì˜ ë§ì”€ìœ¼ë¡œ ì‚´ì•„ê°„ë‹¤ëŠ” ê²ƒì´ë‹¤.\n",
      "2\n",
      "# ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì˜ ì£½ìœ¼ì‹¬ê³¼ ë¶€í™œ\n",
      "í•˜ë‚˜ë‹˜ì˜ ì•„ë“¤ì´ì‹  ì˜ˆìˆ˜ë‹˜ì´ ì§€ì‹  ì‹­ìê°€ëŠ” ì£½ìŒë§Œì„ ì˜ë¯¸í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë™ì‹œì— ë¶€í™œì„ ì˜ë¯¸í•œë‹¤. ì‹­\n",
      "ìê°€ì˜ ì•ë©´ì´ ìœ¡ì‹ ìœ¼ë¡œ ì˜¤ì‹  ì˜ˆìˆ˜ë‹˜ì˜ ì£½ìŒì´ë¼ë©´ ì‹­ìê°€ì˜ ë’·ë©´ì€ ë¶€í™œì´ë‹¤. ì˜ˆìˆ˜ë‹˜ì˜ ì£½ìœ¼ì‹¬ê³¼ ë¶€í™œ\n",
      "ì€ ë‚˜ëˆ„ì–´ì„œ ìƒê°í•  ìˆ˜ ì—†ê³ , ë‘ ë©´ì„ ë™ì‹œì— ìƒê°í•  ë•Œë§Œ ì‹­ìê°€ì˜ ë„ì˜ ì „ë¶€ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. ì˜ˆìˆ˜ë‹˜ì˜ ì£½\n",
      "ìœ¼ì‹¬ê³¼ ë¶€í™œ ì¤‘ í•œ ë©´ë§Œ ì´ì•¼ê¸°í•˜ë©´ ì˜¨ì „í•œ ì‹­ìê°€ì˜ ë©”ì‹œì§€ê°€ ë˜ì§€ ëª»í•œë‹¤. ìš°ë¦¬ëŠ” í•­ìƒ ì‹­ìê°€ì— ë§¤ë‹¬\n",
      "ë ¤ ì£½ìœ¼ì…¨ì„ ë¿ë§Œ ì•„ë‹ˆë¼, ì£½ìŒì—ì„œ ë¶€í™œí•˜ì‹  ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ë¥¼ ë§ˆìŒì— í’ˆì–´ì•¼ í•œë‹¤.\n",
      "ë™ì „(coin)ì—ëŠ” í•­ìƒ ì•ë©´ê³¼ ë’·ë©´ì´ ìˆëŠ” ê²ƒì²˜ëŸ¼, ì‹­ìê°€ì˜ ë„ì—ëŠ” ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì˜ ì£½ìœ¼ì‹¬ê³¼ ë¶€í™œì´ í•­ìƒ í•¨ê»˜\n",
      "í•œë‹¤. ì§„ë¦¬ëŠ” í•˜ë‚˜ì´ì§€ë§Œ ì–‘ë©´ì„±ì„ ë ê³  ìˆë‹¤. ì‹­ìê°€ì˜ ì£½ìœ¼ì‹¬ê³¼ ë¶€í™œì„ í•¨ê»˜ ë§í•˜ì§€ ì•ŠëŠ” ë³µìŒì€ ì™œê³¡\n",
      "ëœ ë³µìŒì´ë‹¤.\n",
      "ë‹¤ìŒ ì„±ê²½ì˜ ë§ì”€ì„ ë‹¤ì‹œ ë¬µìƒí•´ ë³´ì. (ë¡œë§ˆì„œ 6ì¥ì€ ì‹­ìê°€ì˜ ì¥ì´ë¼ê³  ë¶ˆë¦°ë‹¤.)\n",
      "ë¡¬ 6:5 ë§Œì¼ ìš°ë¦¬ê°€ ê·¸ì˜ ì£½ìœ¼ì‹¬ê³¼ ê°™ì€ ëª¨ì–‘ìœ¼ë¡œ ì—°í•©í•œ ìê°€ ë˜ì—ˆìœ¼ë©´ ë˜í•œ ê·¸ì˜ ë¶€í™œê³¼ ê°™ì€ ëª¨ì–‘ìœ¼ë¡œ ì—°í•©í•œ ì\n",
      "ë„ ë˜ë¦¬ë¼\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 4 (Page: 97)\n",
      "\n",
      "![](./images/figure/4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned_Page_96_Index_1161.png)\n",
      "\n",
      "<image>\n",
      "<title>\n",
      "ì‹ ì²´, ë§ˆìŒ, í˜¼ì˜ ê´€ê³„ êµ¬ì¡°\n",
      "</title>\n",
      "<details>\n",
      "ì´ ì´ë¯¸ì§€ëŠ” ì‹ ì²´, ë§ˆìŒ, í˜¼ì˜ ê´€ê³„ë¥¼ í”¼ë¼ë¯¸ë“œ í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ê³  ìˆìœ¼ë©°, ê° ìš”ì†Œì˜ ìƒí˜¸ì‘ìš©ê³¼ ê·¸ ì˜ë¯¸ë¥¼ ì„¤ëª…í•˜ê³  ìˆë‹¤. ì‹ ì²´ëŠ” ì™¸ë¶€ ì„¸ê³„ì—ì„œì˜ í–‰ë™ ì–‘ì‹ì„ ë‚˜íƒ€ë‚´ê³ , ë§ˆìŒì€ ì‚¬ê³  ì²´ê³„ì™€ ê´€ë ¨ì´ ìˆìœ¼ë©°, í˜¼ì€ ì˜ì‹ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ê¸°ëŠ¥í•œë‹¤. ë˜í•œ, ì‹¬ì¤‘ì€ ì‹ ë… ì²´ê³„ì™€ ì—°ê²°ë˜ì–´ ìˆë‹¤.\n",
      "</details>\n",
      "<entities>\n",
      "ì‹ ì²´, ë§ˆìŒ, í˜¼, ì‹¬ì¤‘, ì˜ì‹\n",
      "</entities>\n",
      "<hypothetical_questions>\n",
      "- ì‹ ì²´ì™€ ë§ˆìŒì˜ ê´€ê³„ëŠ” ê°œì¸ì˜ í–‰ë™ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ê¹Œ?\n",
      "- í˜¼ì˜ ê°œë…ì´ í˜„ëŒ€ ì‹¬ë¦¬í•™ì—ì„œ ì–´ë–»ê²Œ í•´ì„ë  ìˆ˜ ìˆì„ê¹Œ?\n",
      "</hypothetical_questions>\n",
      "</image>\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 5 (Page: 114)\n",
      "\n",
      "ê·¸ëŸ°ë° ì˜¤ëŠ˜ë‚  ê·¸ ì‹­ìê°€ë¥¼ ìš°ìƒì‹œí•˜ê³  ìˆë‹¤. ë§ˆì¹˜ ì‹­ìê°€ë¥¼ ë¶€ì ì²˜ëŸ¼ ìƒê°í•˜ê³  ìˆë‹¤. ì´ ë°© ì € ë°©ì— ì‹­\n",
      "ìê°€ë¥¼ ê±¸ê³  ëª©ì—ë‹¤ ì†ì—ë‹¤ ì‹­ìê°€ í˜•ìƒì„ ì§€ë‹ˆê³  ìˆìœ¼ë©´ ë˜ ì‹­ìê°€ë¥¼ ì‚¬ë‘í•˜ë©´, ëª¨ë“  ì €ì£¼ê°€ ëŠì–´ì§€ê³ \n",
      "ëª¨ë“  ì¼ì´ ì˜ë  ê²ƒì´ë¼ê³  ìƒê°í•œë‹¤. í•˜ì§€ë§Œ, ì´ëŠ” ì‚¬ì‹¤ì´ ì•„ë‹ˆë‹¤. ì˜¤íˆë ¤ ë‹¹ì‹ ì€ ì†ê³  ìˆëŠ” ê²ƒì´ë©°, ì˜ˆìˆ˜\n",
      "ë‹˜ì˜ ì£½ìœ¼ì‹¬ì„ í—›ë˜ê²Œ í•˜ê³  ìˆìœ¼ë©°, ë‹¹ì‹ ì´ ë§ˆê·€ì˜ í‘œì ì´ ë˜ëŠ” ê²ƒì´ë‹¤.\n",
      "ì´ëŸ° ì¼ë“¤ì€ ê³¼ê±° ì´ìŠ¤ë¼ì—˜ ë°±ì„±ì—ê²Œë„ ì¼ì–´ë‚¬ë‹¤. ìœ ëŒ€ íˆìŠ¤ê¸°ì•¼ì™• ë•Œ ì´ìŠ¤ë¼ì—˜ ë°±ì„±ì€ ê³¼ê±° ëª¨ì„¸ì˜ ë†‹\n",
      "ë±€ ì‚¬ê±´ì„ ê¸°ì–µí–ˆê³ , ì‹œê°„ì´ ì§€ë‚˜ì ê·¸ê²ƒì„ ìš°ìƒìˆ­ë°° í–ˆë˜ ê²ƒê³¼ ë˜‘ê°™ì€ í–‰ë™ì´ ì§€ê¸ˆë„ ì¼ì–´ë‚˜ê³  ìˆë‹¤.\n",
      "ì™•í•˜ 18:3-4 íˆìŠ¤ê¸°ì•¼ê°€ ê·¸ì˜ ì¡°ìƒ ë‹¤ìœ—ì˜ ëª¨ë“  í–‰ìœ„ì™€ ê°™ì´ ì—¬í˜¸ì™€ê»˜ì„œ ë³´ì‹œê¸°ì— ì •ì§í•˜ê²Œ í–‰í•˜ì—¬ (4) ê·¸ê°€ ì—¬ëŸ¬\n",
      "ì‚°ë‹¹ë“¤ì„ ì œê±°í•˜ë©° ì£¼ìƒì„ ê¹¨ëœ¨ë¦¬ë©° ì•„ì„¸ë¼ ëª©ìƒì„ ì°ìœ¼ë©° ëª¨ì„¸ê°€ ë§Œë“¤ì—ˆë˜ ë†‹ë±€ì„ ì´ìŠ¤ë¼ì—˜ ìì†ì´ ì´ë•Œê¹Œì§€ í–¥í•˜\n",
      "ì—¬ ë¶„í–¥í•˜ë¯€ë¡œ ê·¸ê²ƒì„ ë¶€ìˆ˜ê³  ëŠí›„ìŠ¤ë‹¨ì´ë¼ ì¼ì»¬ì—ˆë”ë¼\n",
      "ì‹­ìê°€ëŠ” ë¶€ì ì´ ì•„ë‹ˆë‹¤. ì‹­ìê°€ì— ëŠ¥ë ¥ì´ ìˆëŠ” ê²ƒì€ ì˜ˆìˆ˜ë‹˜ì˜ ì£½ìœ¼ì‹¬ìœ¼ë¡œ ì¸í•œ í”¼ í˜ë¦¼ê³¼ ê·¸ ì‹­ìê°€ì—ì„œ\n",
      "ì˜›ì‚¬ëŒì˜ ì£½ìŒ ë•Œë¬¸ì— ë‹¹ì‹  ì•ˆì— ê·¸ë¦¬ìŠ¤ë„ê°€ ë‚˜íƒ€ë‚˜ì‹¬ì— ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œì•„ì•¼ í•œë‹¤.\n",
      "1) ë‚´ê°€ ê±¸ê³  ìˆëŠ” ì‹­ìê°€ìƒì˜ ì˜ˆìˆ˜ë‹˜ì€ ìš°ë¦¬ì˜ êµ¬ì›ìì´ì‹œê³  ì‚´ì•„ê³„ì‹  í•˜ë‚˜ë‹˜ì˜ ì•„ë“¤ì´ì‹œë‹¤.\n",
      "2) ê·¸ë¶„ì€ ë‚˜ ë•Œë¬¸ì— ëª¨ë“  ì£„ë¥¼ ì§Šì–´ì§€ì‹œê³  ì£½ìœ¼ì‹œê³ , ìœ¨ë²•ì˜ ì €ì£¼ê°€ ë˜ì…¨ë‹¤.\n",
      "3) ë‚˜ëŠ” ì´ ë¶„ê³¼ ì—°í•©í•˜ì—¬ ì£½ê³  ë¶€í™œí•˜ì˜€ìŒìœ¼ë¡œ ìƒˆë¡œìš´ í”¼ì¡°ë¬¼ë¡œ ê±°ë“­ë‚œ ìì´ë‹¤.\n",
      "4) ë‚˜ëŠ” ëŠì„ì—†ì´ ë‚´ ê±°ì§“ìì•„ë¥¼ ë¶€ì¸í•˜ê³ , ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì‚¶ì„ ì‚¬ëŠ” ìì´ë‹¤.\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 6 (Page: 288)\n",
      "\n",
      "ë¯¿ìŒì˜ ë²•ì¹™, ìˆ˜í™•ì˜ ë²•ì¹™ì„ ê¸°ì–µí•˜ë¼. ìš°ë¦¬ ëª¨ë‘ëŠ” ê°ìê°€ ë¯¿ìŒìœ¼ë¡œ ì‹¬ëŠ” ê²ƒì„ ê±°ë‘”ë‹¤. ë‚´ ì•ˆì— â€˜ì—†\n",
      "ìŒâ€™ì„ ì‹¬ìœ¼ë©´ â€˜ì—†ìŒâ€™ì„ ê±°ë‘ê³ , â€˜ìˆìŒâ€™ì„ ì‹¬ìœ¼ë©´ â€˜ìˆìŒâ€™ì„ ê±°ë‘”ë‹¤. ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ë¥¼ í†µí•´ í•˜ë‚˜\n",
      "ë‹˜ ì•„ë²„ì§€ê»˜ì„œ ì£¼ì‹  ëª¨ë“  ê²ƒì´ ì´ë¯¸ ìš°ë¦¬ ì•ˆì— ìˆë‹¤ëŠ” ì§„ë¦¬ë¡œ, ì¦‰ ìˆìŒì˜ì‹ì„ ê°€ì§€ê³  ë¯¿ìŒìœ¼ë¡œ ìš°ë¦¬ ë§ˆìŒ\n",
      "ì— ì‹¬ìŒìœ¼ë¡œì¨, ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ê»˜ì„œ ë²•ì ìœ¼ë¡œ ì´ë£¨ì‹  ëª¨ë“  ê²ƒì„ í˜„ì‹¤ì—ì„œë„ ëˆ„ë¦¬ëŠ” ìš°ë¦¬ê°€ ë˜ì–´ì•¼í•œë‹¤.\n",
      "ê°ˆ 6:7 ìŠ¤ìŠ¤ë¡œ ì†ì´ì§€ ë§ë¼ í•˜ë‚˜ë‹˜ì€ ì—…ì‹ ì—¬ê¹€ì„ ë°›ì§€ ì•„ë‹ˆí•˜ì‹œë‚˜ë‹ˆ ì‚¬ëŒì´ ë¬´ì—‡ìœ¼ë¡œ ì‹¬ë“ ì§€ ê·¸ëŒ€ë¡œ ê±°ë‘ë¦¬ë¼\n",
      "# (3) ì„±ë ¹ í•˜ë‚˜ë‹˜ì˜ ê°ˆë§(ì°½ì¡°)ì˜ì‹\n",
      "ê±°ì§“ìì•„ì˜ ì˜ì‹ì€ ê³µí—ˆí•¨ê³¼ ìƒì‹¤ê°ìœ¼ë¡œ ì¸í•´ í‰ê°•ì„ ëˆ„ë¦¬ì§€ ëª»í•˜ë©°, ëŠ˜ ì˜ë¯¸ìˆê³  ê°€ì¹˜ìˆëŠ” ê²ƒì„ ì°¾ê³ \n",
      "ìˆë‹¤. ì´ ê³µí—ˆí•¨ê³¼ ìƒì‹¤ê°ì´ ì»¤ì§€ê²Œ ë˜ë©´, ìš°ë¦¬ëŠ” ì¡´ì¬ ê¹Šì€ ê³³ì—ì„œë¶€í„° ìˆ˜ì¹˜ì‹¬, ë¬´ê°€ì¹˜í•¨ì„ ëŠë‚€ë‹¤. ì´\n",
      "ëŸ¬í•œ ê°ì •ê³¼ ëŠë‚Œì„ ë®ê³  ìƒì‡„í•˜ê¸° ìœ„í•´ ìš°ë¦¬ëŠ” ëŠì„ì—†ì´ ì™¸ë¶€ì˜ ê²ƒì„ ì·¨í•˜ê³  ì¶”êµ¬í•¨ìœ¼ë¡œ, ì§€ê¸ˆ ìˆëŠ” ê·¸\n",
      "ëŒ€ë¡œê°€ ì•„ë‹Œ ë¯¸ë˜ì— ìˆëŠ” ê·¸ ë¬´ì—‡ìœ¼ë¡œ ì‚´ì•„ìˆìŒì„ ëŠë¼ê³ ì í•œë‹¤. ì°¸ ë§Œì¡±ê³¼ í‰ê°• ë˜ì‹œëŠ” í•˜ë‚˜ë‹˜ ëŒ€ì‹ ì—\n",
      "ë³´ë‹¤ ì˜ë¯¸ìˆê³  ê°€ì¹˜ìˆëŠ” ê²ƒì„ ì°¾ê¸° ìœ„í•´, ê·¸ëŸ¼ìœ¼ë¡œì¨ ìì‹ ì˜ ì¡´ì¬ë¥¼ ì¦ëª…í•˜ê¸° ìœ„í•´ ë°œë²„ë‘¥ì¹˜ë©° ì‚´ì•„ê°„\n",
      "ë‹¤ëŠ” ê²ƒì´ë‹¤. ì„¸ìƒ ëª¨ë“  ê²ƒì„ ì°½ì¡°í•˜ì‹  í•˜ë‚˜ë‹˜ì˜ ë§ì”€ì´ì ì°½ì¡°ì£¼ì´ì‹œë©° ì§€ê¸ˆ ì´ ìˆœê°„ì—ë„ ì˜¨ ìš°ì£¼ ë§Œë¬¼\n",
      "ì„ ë¶™ë“¤ê³  ê³„ì‹œëŠ” ì˜ˆìˆ˜ë‹˜ì„ ì¶”êµ¬í•˜ê¸° ë³´ë‹¤ëŠ”, ì–¸ì  ê°€ëŠ” ì‚¬ë¼ì§ˆ ëˆˆì— ë³´ì´ëŠ” ë¬¼ì§ˆì„¸ê³„ì—ë§Œ ê´€ì‹¬ì„ ê¸°ìš¸\n",
      "ì´ë©° ê´€ê³„í•˜ê³  ì¶”êµ¬í•œë‹¤.\n",
      "íˆ11:3 ë¯¿ìŒìœ¼ë¡œ ëª¨ë“  ì„¸ê³„ê°€ í•˜ë‚˜ë‹˜ì˜ ë§ì”€ìœ¼ë¡œ ì§€ì–´ì§„ ì¤„ì„ ìš°ë¦¬ê°€ ì•„ë‚˜ë‹ˆ ë³´ì´ëŠ” ê²ƒì€ ë‚˜íƒ€ë‚œ ê²ƒìœ¼ë¡œ ë§ë¯¸ì•”ì•„\n",
      "ëœ ê²ƒì´ ì•„ë‹ˆë‹ˆë¼\n",
      "ê³ í›„4:18 ìš°ë¦¬ê°€ ì£¼ëª©í•˜ëŠ” ê²ƒì€ ë³´ì´ëŠ” ê²ƒì´ ì•„ë‹ˆìš” ë³´ì´ì§€ ì•ŠëŠ” ê²ƒì´ë‹ˆ ë³´ì´ëŠ” ê²ƒì€ ì ê¹ì´ìš” ë³´ì´ì§€ ì•ŠëŠ” ê²ƒì€\n",
      "ì˜ì›í•¨ì´ë¼\n",
      "ì´ ì„¸ìƒì—ì„œ ê°€ì¥ ê°€ì¹˜ìˆëŠ” ì¼ì€ ë‚´ê°€ ì•Œê³  ìˆëŠ” ê²ƒì„ ë§¤ì¼ ì‚¶ì„ í†µí•´ì„œ ì²´í—˜í•¨ìœ¼ë¡œ ìì‹ ì˜ ì¡´ì¬ë¥¼ ì¦ëª…\n",
      "í•˜ëŠ” ê²ƒì´ë‹¤. ìš°ë¦¬ ì˜ì€ í•˜ë‚˜ë‹˜ì´ ëˆ„êµ¬ì´ì‹ ì§€, ë‚´ê°€ ëˆ„êµ¬ì¸ì§€ ì™œ ì‚¬ëŠ”ì§€ ì–´ë–»ê²Œ ì‚´ì•„ì•¼ í•˜ëŠ”ì§€ë¥¼ ì•ˆë‹¤.\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 7 (Page: 113)\n",
      "\n",
      "ì€ ìš°ë¦¬ì˜ íƒ€ë½í•œ í˜•ìƒì´ë¼ëŠ” ê²ƒì„ ë³´ì•„ì•¼ í•˜ë©°, 4) ìš°ë¦¬ì˜ íƒ€ë½í•œ ë³¸ì„±ê³¼ ì£„ì•…ëœ ì‹¤ì²´ê°€ ì˜ˆìˆ˜ ê·¸ë¦¬ìŠ¤ë„ì™€\n",
      "ì—°í•©í•¨ìœ¼ë¡œ ë§ˆì¹¨ë‚´ ê·¸ ì‹­ìê°€ì—ì„œ ì£½ì€ ê²ƒì„ ë³´ì•„ì•¼ í•œë‹¤.\n",
      "# â–¶ì‹­ìê°€ ëª©ê±¸ì´ì˜ ì§„ì •í•œ ì˜ë¯¸\n",
      "ë§ì€ ì‚¬ëŒë“¤ì´ ì‹­ìê°€ ëª©ê±¸ì´ë‚˜ ë¬¸ì–‘ì„ í•˜ê³  ë‹¤ë‹Œë‹¤. ê·¸ê²ƒì€ ì•„ë§ˆ â€˜ë‚˜ëŠ” ì˜ˆìˆ˜ë‹˜ì„ ë¯¿ê³  ì‚¬ë‘í•©ë‹ˆë‹¤â€™\n",
      "ë¼ëŠ” ëœ»ì¼ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì‹¤ì œì˜ ëœ»ì€ â€˜ë‚˜ëŠ” ì£½ì„ ìˆ˜ë°–ì— ì—†ëŠ” ë§ˆê·€ì˜ ìì‹ì…ë‹ˆë‹¤. ì˜ˆìˆ˜ë‹˜ì´ ì‹­ìê°€ì—\n",
      "ì„œ ë‚´ ëŒ€ì‹ ì— ì£„ê°€ ë˜ê³  ì €ì£¼ë¥¼ ë°›ìœ¼ì‚¬ ë±€ê°™ì´ ë˜ì–´ ë²„ë¦° ê²ƒì…ë‹ˆë‹¤. ì‚¬ì‹¤ ê·¸ ë±€ì€ ë°”ë¡œ ë‚˜ì…ë‹ˆë‹¤. ê·¸ëŸ°ë°\n",
      "ì˜ˆìˆ˜ë‹˜ì˜ ëŒ€ì†ìœ¼ë¡œ ì¸í•˜ì—¬ ë‚´ê°€ ê·¸ ì£„ì™€ ì €ì£¼ì— ëŒ€í•´ì„œ ì£½ì—ˆìŠµë‹ˆë‹¤. ì´ì œëŠ” ë‚˜ëŠ” ë‚˜ì˜ ì‚¶ì´ ì•„ë‹ˆë¼ ì˜ˆìˆ˜\n",
      "ë‹˜ì˜ ì‚¶ì„ ì‚¬ëŠ” ìì…ë‹ˆë‹¤â€™ë¼ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë³µìŒì€ ë‚˜ì˜ ì‚¶ì´ ì•„ë‹Œ ë‚˜ì˜ ì£½ìŒì„ í†µí•œ ê·¸ë¦¬ìŠ¤ë„ì˜ ì‚¶\n",
      "ì— ëŒ€í•´ ë§í•˜ê³  ìˆë‹¤. ì‹­ìê°€ê°€ ì–¼ë§ˆë‚˜ í˜ì˜¤ìŠ¤ëŸ½ê³  ì•…í•œ ê²ƒì¸ì§€ë¥¼ ì•„ëŠ” ìë§Œì´ ì‹­ìê°€ì˜ ì£½ìŒì„ í†µí•´ ë‚˜\n",
      "íƒ€ë‚œ ì˜ˆìˆ˜ë‹˜ì˜ ì‚¬ë‘ì„ ì²´í—˜í•  ìˆ˜ ìˆë‹¤.\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "### Result 8 (Page: 273)\n",
      "\n",
      "![](./images/figure/4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned_Page_272_Index_3194.png)\n",
      "\n",
      "<image>\n",
      "<title>\n",
      "ê±°ì§“ ìì•„ì™€ ì„¸ ì°¨ì›ì˜ ì‚¶ì˜ êµ¬ì¡°\n",
      "</title>\n",
      "<details>\n",
      "ì´ë¯¸ì§€ëŠ” ê±°ì§“ ìì•„ì˜ ê°œë…ê³¼ í˜¼, ì •ì‹ , ëª¸, ë§ˆìŒ, ì‹¬ì¤‘, ì‹ ì²´ ê°„ì˜ ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìŠµë‹ˆë‹¤. ì´ êµ¬ì¡°ëŠ” ë¯¿ìŒ, ì¸ì‹, íˆ¬ì‚¬, ì‹¤ìƒ, ì—ë„ˆì§€ì˜ íë¦„ì„ í†µí•´ ì„¸ ì°¨ì›ì˜ ì‚¶ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "</details>\n",
      "<entities>\n",
      "ê±°ì§“ ìì•„, í˜¼, ì •ì‹ , ëª¸, ë§ˆìŒ, ì‹¬ì¤‘, ì‹ ì²´, ë¯¿ìŒ, ì¸ì‹, íˆ¬ì‚¬, ì‹¤ìƒ, ì—ë„ˆì§€\n",
      "</entities>\n",
      "<hypothetical_questions>\n",
      "- ê±°ì§“ ìì•„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ì–´ë–¤ ë°©ë²•ì´ ìˆì„ê¹Œìš”?\n",
      "- ì„¸ ì°¨ì›ì˜ ì‚¶ì„ ê²½í—˜í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ë¯¿ìŒì˜ ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?\n",
      "</hypothetical_questions>\n",
      "</image>\n",
      "\n",
      "Source: 4a414ed1-67ae-49f6-acf5-a92ad7a3c206_31_kbs_cleaned.pdf\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì‹¬ì¤‘(å¿ƒä¸­)ì€ ë§ˆìŒì˜ ì¤‘ì‹¬, ì¦‰ ë‚´ë©´ ê¹Šì€ ê³³ì— ìë¦¬í•œ ë§ˆìŒì˜ í•µì‹¬ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ì‹¬ì¤‘ì€ ë‹¨ìˆœí•œ ê°ì •ì´ë‚˜ ìƒê°ì„ ë„˜ì–´ì„œì„œ ê°œì¸ì˜ ì‹ ë… ì²´ê³„, ì˜ì‹ì˜ ì¤‘ì‹¬, ê·¸ë¦¬ê³  ì˜ì  ìƒíƒœì™€ ê¹Šì´ ì—°ê²°ë˜ì–´ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ìë£Œì— ë”°ë¥´ë©´ ì‹¬ì¤‘ì€ í—¬ë¼ì–´ë¡œ 'ì¹´ë¥´ë””ì•„'ë¼ê³  í•˜ë©°, ë¯¿ìŒì²´ê³„ í™•ë¦½ê³¼ ì˜ì  ì„±ì¥ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì•¼ê³ ë³´ì„œ 1ì¥ 2ì ˆì—ì„œëŠ” \"ë„ˆí¬ ì˜í˜¼ì„ ëŠ¥íˆ êµ¬ì›í•  ë°” ë§ˆìŒ(ì‹¬ì¤‘)ì— ì‹¬ì–´ì§„ ë§ì”€ì„ ì˜¨ìœ í•¨ìœ¼ë¡œ ë°›ìœ¼ë¼\"ê³  í•˜ì—¬ ì‹¬ì¤‘ì— ì‹¬ì–´ì§„ ë§ì”€ì´ ì˜í˜¼ êµ¬ì›ì— ì˜í–¥ì„ ì¤€ë‹¤ê³  ë§í•©ë‹ˆë‹¤. ë˜í•œ, ì•¼ê³ ë³´ì„œ 4ì¥ 8ì ˆì—ì„œëŠ” \"ë§ˆìŒ(ì‹¬ì¤‘)ì„ ì„±ê²°í•˜ê²Œ í•˜ë¼\"ê³  í•˜ì—¬ ì‹¬ì¤‘ì˜ ì •ê²°í•¨ì´ ì¤‘ìš”í•¨ì„ ê°•ì¡°í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì‹¬ì¤‘ì€ ì‹ ì²´, ë§ˆìŒ, í˜¼ê³¼ë„ ê´€ê³„ê°€ ìˆìœ¼ë©°, ì‹ ë… ì²´ê³„ì™€ ì—°ê²°ë˜ì–´ ê°œì¸ì˜ í–‰ë™ê³¼ ì‚¬ê³ ì— ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤. ì‹¬ì¤‘ì€ ë‹¨ìˆœí•œ ë§ˆìŒì˜ ì‘ìš©ì´ ì•„ë‹ˆë¼, ì˜ì ì´ê³  ë‚´ë©´ì ì¸ ê¹Šì€ ì°¨ì›ì˜ ë§ˆìŒ ìƒíƒœë¡œì„œ, í•˜ë‚˜ë‹˜ê³¼ì˜ ê´€ê³„, ë¯¿ìŒ, ê·¸ë¦¬ê³  ì˜ì  ì‚¶ì˜ ì¤‘ì‹¬ì´ ë©ë‹ˆë‹¤.\n",
      "\n",
      "ìš”ì•½í•˜ë©´, ì‹¬ì¤‘ì€ ë‚´ë©´ ê¹Šì€ ë§ˆìŒì˜ ì¤‘ì‹¬ìœ¼ë¡œì„œ, ì‹ ë…ê³¼ ì˜ì  ìƒíƒœë¥¼ ë‹´ê³  ìˆìœ¼ë©°, ë¯¿ìŒê³¼ ì˜ì  ì„±ì¥ì— í•µì‹¬ì ì¸ ì—­í• ì„ í•˜ëŠ” ê°œë…ì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-mini\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"tbb-db-schema\": {\n",
    "            # ì„œë²„ì˜ í¬íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.(8005ë²ˆ í¬íŠ¸)\n",
    "            \"url\": \"http://localhost:8006/sse\",\n",
    "            # \"url\": \"http://localhost:8008/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë– ë‹ˆ?\"})\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"í…€ë¸”ë²… ìŠ¤í‚¤ë§ˆ\"})\n",
    "    # í˜„ì¬ì‹œê°„ì„ êµ¬í•˜ëŠ” MCP\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"í˜„ì¬ ì„œìš¸ ì‹œê°„ì€ ëª‡ì‹œì¸ê°€ìš”?\"})\n",
    "\n",
    "    # kbs rag mcp í…ŒìŠ¤íŠ¸\n",
    "    answer = await astream_graph(agent, {\"messages\": \"ì‹¬ì¤‘ì— ëŒ€í•´ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"ì‹­ì¼ì¡°ëŠ” ì™œ í•´ì•¼í•˜ë‚˜ìš”?\"})\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"ë“œë¦¼ê³¼ ë‚˜ëˆ” ì¤‘ ì–´ëŠ ê²ƒì´ ë” ì¤‘ìš”í•œì§€ ë³¸ë¬¸ì„ ì¸ìš©í•´ì„œ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"ë³¸ë¬¸ì—ì„œ ì‹­ì¼ì¡°ì™€ ê´€ë ¨ëœ ì„±ê²½êµ¬ì ˆì„ ì°¾ì•„ì£¼ì„¸ìš”.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3665, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/rc/w7m_bf7x39bfb8wclzs_8xsr0000gn/T/ipykernel_44989/1848944460.py\", line 10, in <module>\n",
      "  |     async with MultiServerMCPClient(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 357, in __aenter__\n",
      "  |     await self.connect_to_server(server_name, **connection)\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 170, in connect_to_server\n",
      "  |     await self.connect_to_server_via_sse(\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 276, in connect_to_server_via_sse\n",
      "  |     sse_transport = await self.exit_stack.enter_async_context(\n",
      "  |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "  |     result = await _enter(cm)\n",
      "  |              ^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    |     yield\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    |     resp = await self._pool.handle_async_request(req)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    |     raise exc from None\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    |     response = await connection.handle_async_request(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    |     raise exc\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    |     stream = await self._connect(request)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
      "    |     stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
      "    |     return await self._backend.connect_tcp(\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
      "    |     with map_exceptions(exc_map):\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    |     raise to_exc(exc) from exc\n",
      "    | httpcore.ConnectError: All connection attempts failed\n",
      "    | \n",
      "    | The above exception was the direct cause of the following exception:\n",
      "    | \n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 47, in sse_client\n",
      "    |     async with aconnect_sse(\n",
      "    |                ^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx_sse/_api.py\", line 69, in aconnect_sse\n",
      "    |     async with client.stream(method, url, headers=headers, **kwargs) as response:\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1583, in stream\n",
      "    |     response = await self.send(\n",
      "    |                ^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    |     response = await self._send_handling_auth(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    |     response = await self._send_handling_redirects(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    |     response = await self._send_single_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    |     response = await transport.handle_async_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    |     with map_httpcore_exceptions():\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    |     raise mapped_exc(message) from exc\n",
      "    | httpx.ConnectError: All connection attempts failed\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            # ì„œë²„ì˜ í¬íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.(8005ë²ˆ í¬íŠ¸)\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    answer = await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì˜ ê²½ìš°ì—ëŠ” session ì´ ë‹«í˜”ê¸° ë•Œë¬¸ì— ë„êµ¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í˜„ì¬ ì €ëŠ” ì‹¤ì‹œê°„ ì¸í„°ë„· ì ‘ì†ì´ ë¶ˆê°€ëŠ¥í•˜ì—¬ ìµœì‹  ì„œìš¸ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì§ì ‘ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ 6ì›”ì˜ ì„œìš¸ì€ ì´ˆì—¬ë¦„ ë‚ ì”¨ë¡œ, í‰ê·  ê¸°ì˜¨ì€ 20~28ë„ ì‚¬ì´ì´ë©°, ìŠµë„ê°€ ë†’ê³  ê°„í˜¹ ì†Œë‚˜ê¸°ê°€ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì •í™•í•œ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë„¤ì´ë²„, ë‹¤ìŒ, ê¸°ìƒì²­, ë˜ëŠ” ìŠ¤ë§ˆíŠ¸í°ì˜ ë‚ ì”¨ ì•±ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”! í•„ìš”í•˜ë‹¤ë©´ ì„œìš¸ì˜ ê³„ì ˆë³„ ê¸°í›„ íŠ¹ì§•ì´ë‚˜ ì—¬í–‰ íŒë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_a1102cf978'}, id='run-40cb5132-6563-454d-83ec-cc4fb6567166'),\n",
       " 'metadata': {'langgraph_step': 1,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ê·¸ëŸ¼ Async Session ì„ ìœ ì§€í•˜ë©° ë„êµ¬ì— ì ‘ê·¼í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_weather', description='\\n    Get current weather information for the specified location.\\n\\n    This function simulates a weather service by returning a fixed response.\\n    In a production environment, this would connect to a real weather API.\\n\\n    Args:\\n        location (str): The name of the location (city, region, etc.) to get weather for\\n\\n    Returns:\\n        str: A string containing the weather information for the specified location\\n    ', args_schema={'properties': {'location': {'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x10b898fe0>)]\n"
     ]
    }
   ],
   "source": [
    "# 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ì´ˆê¸°í™” (ì´ ë¶€ë¶„ì´ í•„ìš”í•¨)\n",
    "# ì´ˆê¸°í™”\n",
    "await client.__aenter__()\n",
    "\n",
    "# ì´ì œ ë„êµ¬ê°€ ë¡œë“œë¨\n",
    "print(client.get_tools())  # ë„êµ¬ê°€ í‘œì‹œë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_react_agent(model, client.get_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's always Sunny in ì„œìš¸\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” í•­ìƒ ë§‘ìŒì…ë‹ˆë‹¤! ì˜¤ëŠ˜ë„ í™”ì°½í•œ í•˜ë£¨ë¥¼ ë³´ë‚´ì‹¤ ìˆ˜ ìˆê² ë„¤ìš”."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276'}, id='run-3f2f12d4-9aef-4379-9d53-3a83e3b18046'),\n",
       " 'metadata': {'langgraph_step': 3,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdio í†µì‹  ë°©ì‹\n",
    "\n",
    "Stdio í†µì‹  ë°©ì‹ì€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í†µì‹ ì„ ìœ„í•´ í‘œì¤€ ì…ë ¥/ì¶œë ¥ ì‚¬ìš©\n",
    "\n",
    "ì°¸ê³ : ì•„ë˜ì˜ python ê²½ë¡œëŠ” ìˆ˜ì •í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# StdIO ì„œë²„ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# - command: Python ì¸í„°í”„ë¦¬í„° ê²½ë¡œ\n",
    "# - args: ì‹¤í–‰í•  MCP ì„œë²„ ìŠ¤í¬ë¦½íŠ¸\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    # args=[\"mcp_server_local.py\"],\n",
    "    args=[\"./resources/mcp_rag_help_center/mcp_server.py\"],\n",
    ")\n",
    "\n",
    "# StdIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ì™€ í†µì‹ \n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # ì—°ê²° ì´ˆê¸°í™”\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP ë„êµ¬ ë¡œë“œ\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„±\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        # await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë– ë‹ˆ?\"})\n",
    "        await astream_graph(agent, {\"messages\": \"ì°½ì‘ìì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG ë¥¼ êµ¬ì¶•í•œ MCP ì„œë²„ ì‚¬ìš©\n",
    "\n",
    "- íŒŒì¼: `mcp_server_rag.py`\n",
    "\n",
    "ì‚¬ì „ì— langchain ìœ¼ë¡œ êµ¬ì¶•í•œ `mcp_server_rag.py` íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "stdio í†µì‹  ë°©ì‹ìœ¼ë¡œ ë„êµ¬ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì—¬ê¸°ì„œ ë„êµ¬ëŠ” `retriever` ë„êµ¬ë¥¼ ê°€ì ¸ì˜¤ê²Œ ë˜ë©°, ì´ ë„êµ¬ëŠ” `mcp_server_rag.py` ì—ì„œ ì •ì˜ëœ ë„êµ¬ì…ë‹ˆë‹¤. ì´ íŒŒì¼ì€ ì‚¬ì „ì— ì„œë²„ì—ì„œ ì‹¤í–‰ë˜ì§€ **ì•Šì•„ë„** ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì •ì±…ï½¥ë²•ì œ\n",
      "ê¸°ì—…ï½¥ì‚°ì—…\n",
      "ê¸°ìˆ ï½¥ì—°êµ¬\n",
      "ì¸ë ¥ï½¥êµìœ¡\n",
      "3\n",
      "íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜, AIì˜ ê³µê³µì„±Â·ì§€ì†ê°€ëŠ¥ì„±ê³¼ í•¨ê»˜ ê·œì œ ì™„í™” ë…¼ì˜\n",
      "n íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì˜ ì£¼ìš” ê²°ê³¼ë¬¼ë¡œ í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ìœ„í•œ ì„ ì–¸ë¬¸ì´ ë°œí‘œë˜ì—ˆìœ¼ë©°, \n",
      "ê³µìµì„ ìœ„í•œ AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AIâ€™ë„ ì¶œë²”\n",
      "n íŒŒë¦¬ AI ì •ìƒíšŒì˜ì—ì„œëŠ” AI ê·œì œ ì™„í™”ì™€ íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ ì˜ì œë¡œ ë– ì˜¬ëìœ¼ë©°, ë§ˆí¬ë¡± í”„ë‘ìŠ¤ \n",
      "ëŒ€í†µë ¹ì€ 1,090ì–µ ìœ ë¡œ ê·œëª¨ì˜ AI ì¸í”„ë¼ ë¯¼ê°„ íˆ¬ì í”„ë¡œì íŠ¸ë„ ë°œí‘œ\n",
      "KEY Contents\n",
      "Â£ ë¯¸êµ­ê³¼ ì˜êµ­ì„ ì œì™¸í•œ 60ê°œêµ­, í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸ ë°œí‘œ\n",
      "n í”„ë‘ìŠ¤ ì •ë¶€ê°€ 2025ë…„ 2ì›” 10~11ì¼, íŒŒë¦¬ì—ì„œ â€˜AI í–‰ë™ ì •ìƒíšŒì˜(AI Action Summit)â€™ë¥¼ ê°œìµœ\n",
      "âˆ™ì´ë²ˆ ì •ìƒíšŒì˜ì—ëŠ” ì „ ì„¸ê³„ 87ê°œ êµ­ê°€ì—ì„œ ê¸°ì—…, êµ­ì œê¸°êµ¬, ì‹œë¯¼ë‹¨ì²´ ë“± ì´ 1,000ì—¬ ëª…ì´ ì°¸ì—¬í•´ AI ê¸€ë¡œë²Œ \n",
      "ê±°ë²„ë„ŒìŠ¤ë¥¼ ì‹¬ë„ ìˆê²Œ ë…¼ì˜\n",
      "n ì •ìƒíšŒì˜ ì£¼ìš” ê²°ê³¼ë¬¼ë¡œ í•œêµ­ì„ í¬í•¨í•œ 60ê°œêµ­ì´ ê³µë™ ì°¸ì—¬í•œ â€˜ì¸ë¥˜ì™€ ì§€êµ¬ë¥¼ ìœ„í•œ í¬ìš©ì ì´ê³  \n",
      "ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸â€™ì´ ë°œí‘œë˜ì—ˆê³  ë¯¸êµ­ê³¼ ì˜êµ­ì€ ì„ ì–¸ì— ë¶ˆì°¸    \n",
      "âˆ™ì„ ì–¸ë¬¸ì€ ê³µìµì„ ìœ„í•œ AI ë° ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ëª©í‘œë¡œ ì œì‹œí•˜ê³ , ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ êµ¬ì²´ì  í–‰ë™ìœ¼ë¡œ \n",
      "â‘ ê³µìµì„ ìœ„í•œ AI í”Œë«í¼ ë° ì¸íë² ì´í„° ì¶œë²” â‘¡í™˜ê²½ì  ì§€ì†ê°€ëŠ¥ì„±ì„ ìœ„í•œ AI ì—ë„ˆì§€ ê´€ì¸¡ì†Œ ì„¤ë¦½ \n",
      "â‘¢ì¼ìë¦¬ì— ëŒ€í•œ AI ì˜í–¥ ê´€ì¸¡ ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì‹œ\n",
      "n ì´ë²ˆ ì •ìƒíšŒì˜ì—ì„œëŠ” 9ê°œêµ­*ê³¼ êµ¬ê¸€, ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“±ì˜ ê¸°ì—…ì´ 4ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•´ ê³µìµì„ ìœ„í•œ \n",
      "AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AI(Current AI)â€™ë„ ì¶œë²”\n",
      "* ë‚˜ì´ì§€ë¦¬ì•„, ë…ì¼, ëª¨ë¡œì½”, ìŠ¤ìœ„ìŠ¤, ìŠ¬ë¡œë² ë‹ˆì•„, ì¹ ë ˆ, ì¼€ëƒ, í”„ë‘ìŠ¤, í•€ë€ë“œ  \n",
      "âˆ™ì´ í”„ë¡œì íŠ¸ëŠ” ê³µìµ AI í™˜ê²½ ì¡°ì„±ì„ ëª©í‘œë¡œ â–³AI í›ˆë ¨ì„ ìœ„í•œ ê³ í’ˆì§ˆ ê³µê³µ ë°ì´í„° ì ‘ê·¼ì„± í™•ëŒ€ \n",
      "â–³ì˜¤í”ˆì†ŒìŠ¤ ì¸í”„ë¼ ì§€ì› â–³AIì˜ ì‚¬íšŒì Â·í™˜ê²½ì  ì˜í–¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì‹œìŠ¤í…œ ê°œë°œ ì§€ì›ì„ ì¶”ì§„\n",
      "Â£ íŒŒë¦¬ AI ì •ìƒíšŒì˜, AI ê·œì œ ì™„í™” ë° AI íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ í™”ë‘ë¡œ ë¶€ìƒ\n",
      "SPRi AI Brief\n",
      "2025ë…„ 3ì›”í˜¸\n",
      "4\n",
      "EU ì§‘í–‰ìœ„ì›íšŒ, ê²½ìŸë ¥ ê°•í™” ë¡œë“œë§µì˜ ì¼í™˜ìœ¼ë¡œ AI ê¸°ê°€íŒ©í† ë¦¬ êµ¬ì¶• ì¶”ì§„\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒê°€ 5ê°œë…„ ì •ì±… ë¡œë“œë§µ â€˜ê²½ìŸë ¥ ë‚˜ì¹¨ë°˜â€™ì— ë”°ë¼ í˜ì‹  ê²©ì°¨ í•´ì†Œë¥¼ ìœ„í•œ AI ì •ì±…ìœ¼ë¡œ \n",
      "â€˜AI ê¸°ê°€íŒ©í† ë¦¬â€™ì™€ â€˜AI ì ìš©â€™ ì „ëµì„ ì œì‹œ\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒëŠ” íŒŒë¦¬ AI ì •ìƒíšŒì˜ì—ì„œ ì´ 2ì²œì–µ ìœ ë¡œ ê·œëª¨ì˜ â€˜ì¸ë² ìŠ¤íŠ¸AIâ€™ ê³„íšì˜ ì¼í™˜ìœ¼ë¡œ \n",
      "200ì–µ ìœ ë¡œë¥¼ íˆ¬ì…í•´ 4ê°œì˜ AI ê¸°ê°€íŒ©í† ë¦¬ë¥¼ ê±´ì„¤í•˜ê² ë‹¤ê³  ë°œí‘œ  \n",
      "KEY Contents\n",
      "Â£ EU ì§‘í–‰ìœ„ì›íšŒ, 5ê°œë…„ ì •ì±… ë¡œë“œë§µ í•˜ì—ì„œ AI ê¸°ê°€íŒ©í† ë¦¬ì™€ AI ì ìš© ì „ëµ ì¶”ì§„ \n",
      "n ìš°ë¥´ì¤„ë¼ í° ë°ì–´ ë¼ì´ì—”(Ursula von der Leyen) EU ì§‘í–‰ìœ„ì›ì¥ì´ 2025ë…„ 1ì›” 29ì¼ 2ê¸° EU \n",
      "ì§‘í–‰ë¶€(2024ë…„ 12ì›” ì¶œë²”)ì˜ 5ê°œë…„ ì •ì±… ë¡œë“œë§µ â€˜ê²½ìŸë ¥ ë‚˜ì¹¨ë°˜(Competitive Compass)â€™ì„ ë°œí‘œ\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒëŠ” ê²½ìŸë ¥ ì œê³ ë¥¼ ìœ„í•´ â–³í˜ì‹  ê²©ì°¨ í•´ì†Œ â–³è„«íƒ„ì†Œí™” â–³ê³µê¸‰ë§ ì•ˆë³´ì˜ 3ê°œ ì˜ì—­ì„ ì¤‘ì  \n",
      "ê³¼ì œë¡œ ì œì‹œí–ˆìœ¼ë©°, ì´ì¤‘ í˜ì‹  ê²©ì°¨ í•´ì†Œì™€ ê´€ë ¨í•´ AI ì •ì±…ì„ í¬í•¨\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒëŠ” í•µì‹¬ ë¶„ì•¼ì˜ AI ê°œë°œê³¼ ì‚°ì—…ê³„ AI ë„ì… í™œì„±í™”ë¥¼ ìœ„í•œ â€˜AI ê¸°ê°€íŒ©í† ë¦¬(AI Gigafactory)â€™ì™€ \n",
      "â€˜AI ì ìš©(Apply AI)â€™ ì „ëµì„ ì œì•ˆ\n",
      "âˆ™AI ê¸°ê°€íŒ©í† ë¦¬ëŠ” ì…ë²• ì¶”ì§„ ì˜ˆì •ì¸ â€˜EU í´ë¼ìš°ë“œ ë° AI ê°œë°œë²•(EU Cloud and AI Development \n",
      "Act)â€™*ì„ í†µí•´ ê³µê³µê³¼ ë¯¼ê°„ ìê¸ˆì„ í™œìš©í•˜ì—¬ ì´ˆê±°ëŒ€ AI ëª¨ë¸ í›ˆë ¨ì— íŠ¹í™”ëœ ëŒ€ê·œëª¨ ë°ì´í„°ì„¼í„°ë¥¼ \n",
      "êµ¬ì¶•í•¨ìœ¼ë¡œì¨ EU ì „ì—­ì˜ AI ìƒíƒœê³„ë¥¼ í™œì„±í™”í•œë‹¤ëŠ” ê³„íš\n",
      "* ê³ ì„±ëŠ¥ ì—°ì‚° ìì›ê³¼ ë””ì§€í„¸ ì¸í”„ë¼ì— ëŒ€í•œ ê°•ë ¥í•œ ê·œì œ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ í´ë¼ìš°ë“œì™€ AI ë¶„ì•¼ì—ì„œ ìœ ëŸ½ì˜ ë¦¬ë”ì‹­ ê°•í™”ë¥¼ ìœ„í•œ ë²•ì•ˆ\n",
      "âˆ™AI ì ìš© ì „ëµì€ ì œì¡°ì—…, ì—ë„ˆì§€, ìë™ì°¨, ë¡œë´‡ê³µí•™, ì œì•½, í•­ê³µ, ê¸ˆìœµ ì„œë¹„ìŠ¤ ì‚°ì—…ì˜ AI ì ìš©ì„ ì´‰ì§„í•˜ê³  \n",
      "ë³´ê±´ê³¼ ì‚¬ë²• ë“±ì˜ ê³µê³µì„œë¹„ìŠ¤ ê°œì„ ì„ ì¶”ì§„\n",
      "CONTENTS\n",
      "ì •ì±…ï½¥ë²•ì œ\n",
      "âˆ™ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ëŒ€ìƒ AI ì •ì±… ë³´ê³ ì„œ ë°œê°„\n",
      "2\n",
      "âˆ™íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜, AIì˜ ê³µê³µì„±Â·ì§€ì†ê°€ëŠ¥ì„±ê³¼ í•¨ê»˜ ê·œì œ ì™„í™” ë…¼ì˜\n",
      "3\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒ, ê²½ìŸë ¥ ê°•í™” ë¡œë“œë§µì˜ ì¼í™˜ìœ¼ë¡œ AI ê¸°ê°€íŒ©í† ë¦¬ êµ¬ì¶• ì¶”ì§„\n",
      "4\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒ, 2025ë…„ ì—…ë¬´ í”„ë¡œê·¸ë¨ì—ì„œ â€˜AI ì±…ì„ ì§€ì¹¨â€™ ì² íšŒ ê³„íš ë°œí‘œ\n",
      "5\n",
      "âˆ™ì˜êµ­, AIì•ˆì „ì—°êµ¬ì†Œì˜ ëª…ì¹­ AIë³´ì•ˆì—°êµ¬ì†Œë¡œ ë³€ê²½í•˜ê³  ì•¤ìŠ¤ë¡œí”½ê³¼ AI í˜‘ë ¥ ë°œí‘œ\n",
      "6\n",
      "ê¸°ì—…ï½¥ì‚°ì—…\n",
      "âˆ™êµ¬ê¸€, ì„±ëŠ¥ ê°œì„ í•œ â€˜ì œë¯¸ë‚˜ì´ 2.0â€™ ì œí’ˆêµ° í™•ëŒ€ ì¶œì‹œ\n",
      "8\n",
      "âˆ™ ì˜¤í”ˆAI, ì‹¬ì¸µ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ â€˜ë”¥ ë¦¬ì„œì¹˜â€™ ê³µê°œ\n",
      "9\n",
      "âˆ™ì˜¤í”ˆAI, GPT-5 ì¶œì‹œ ë¡œë“œë§µ ë°œí‘œ ë° GPT-4.5 í”„ë¦¬ë·° ê³µê°œ\n",
      "10\n",
      "âˆ™xAI, ìµœì‹  AI ëª¨ë¸ â€˜ê·¸ë¡ 3â€™ í”„ë¦¬ë·° ì¶œì‹œ\n",
      "11\n",
      "âˆ™í¼í”Œë ‰ì‹œí‹°, ì‹¬ì¸µ ì¡°ì‚¬ì™€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” â€˜ë”¥ ë¦¬ì„œì¹˜â€™ ë¬´ë£Œ ì¶œì‹œ\n",
      "12\n",
      "âˆ™ì•Œë¦¬ë°”ë°”, ë”¥ì‹œí¬ V3 ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì˜ â€˜íì›2.5-Maxâ€™ ì¶œì‹œ\n",
      "13\n",
      "âˆ™ì•„í¬ ì¸ë² ìŠ¤íŠ¸, 2025ë…„ í˜ì‹  ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ AI ì—ì´ì „íŠ¸ ì„ ì •\n",
      "14\n",
      "ê¸°ìˆ ï½¥ì—°êµ¬\n",
      "âˆ™ìƒí•˜ì´êµí†µâ¼¤ ì—°êµ¬ì§„, ì†ŒëŸ‰ì˜ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•œ ì¶”ë¡  AI ëª¨ë¸ ê°œë°œ\n",
      "16\n",
      "âˆ™ìŠ¤íƒ í¬ë“œâ¼¤ì™€ ì›Œì‹±í„´â¼¤ ì—°êµ¬ì§„, ì €ë¹„ìš©ìœ¼ë¡œ ê³ ì„±ëŠ¥ ì¶”ë¡  AI ëª¨ë¸ ê°œë°œ\n",
      "17\n",
      "âˆ™ë°”ì´íŠ¸ëŒ„ìŠ¤, ì¸ë¬¼ ì›€ì§ì„ì„ ìƒì„±í•˜ëŠ” AI ëª¨ë¸ â€˜ì˜´ë‹ˆíœ´ë¨¼-1â€™ ê°œë°œ\n",
      "18\n",
      "âˆ™AIì•ˆì „ì„¼í„°ì™€ ìŠ¤ì¼€ì¼ AI, ê³ ë‚œë„ ë²¤ì¹˜ë§ˆí¬ â€˜HLEâ€™ ê³µê°œ\n",
      "19\n",
      "ì¸ë ¥ï½¥êµìœ¡ \n",
      "âˆ™ë”œë¡œì´íŠ¸ ì¡°ì‚¬ ê²°ê³¼, ì „ ì„¸ê³„ ê¸°ì—…ë“¤ì€ ì ì§„ì ìœ¼ë¡œ AI ë„ì… í™•ëŒ€\n",
      "21\n",
      "âˆ™ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì—°êµ¬ ê²°ê³¼, ìƒì„± AI ì‹ ë¢°í• ìˆ˜ë¡ ë¹„íŒì  ì‚¬ê³  ê°ì†Œ\n",
      "22\n",
      "âˆ™ì•¤ìŠ¤ë¡œí”½, AIê°€ ë…¸ë™ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ â€˜ì•¤ìŠ¤ë¡œí”½ ê²½ì œ ì§€ìˆ˜â€™ ê³µê°œ \n",
      "23\n",
      "âˆ™ì•¤ìŠ¤ë¡œí”½ì„ ë¹„ë¡¯í•œ ì—¬ëŸ¬ ê¸°ì—…ë“¤, ì…ì‚¬ ì§€ì› ì‹œ AI ë„êµ¬ ì‚¬ìš©ê¸ˆì§€ ìš”êµ¬\n",
      "24\n",
      "ì£¼ìš”í–‰ì‚¬ì¼ì •\n",
      "25\n",
      "| 2025ë…„ 3ì›”í˜¸ |\n",
      "SPRi AI Brief\n",
      "2025ë…„ 3ì›”í˜¸\n",
      "2\n",
      "ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ëŒ€ìƒ AI ì •ì±… ë³´ê³ ì„œ ë°œê°„\n",
      "n AI ì •ì±…ì— ê´€í•˜ì—¬ ëŒ€í†µë ¹ê³¼ ì—°ë°© ì •ë¶€ì— ìë¬¸ì„ ì œê³µí•˜ëŠ” ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ(NAIAC)ê°€ \n",
      "íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ê°€ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì§„í•´ì•¼ í•  AI ì •ì±…ì„ ì •ë¦¬í•œ ë³´ê³ ì„œë¥¼ ë°œí‘œ\n",
      "n ë³´ê³ ì„œëŠ” ì •ì±… ìš°ì„ ìˆœìœ„ë¡œ â–³ë…¸ë™ë ¥ â–³AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ â–³êµìœ¡ â–³ê³¼í•™ â–³ë³´ê±´ â–³ì •ë¶€ \n",
      "â–³ì¤‘ì†Œê¸°ì—… ì§€ì› â–³AI ê±°ë²„ë„ŒìŠ¤ â–³ë¯¸êµ­ ì‹œë¯¼ â–³ë²• ì§‘í–‰ì„ ì œì‹œ\n",
      "KEY Contents\n",
      "Â£ ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, ë¯¸êµ­ì˜ AI ì£¼ë„ê¶Œ ìœ ì§€ë¥¼ ìœ„í•œ 10ëŒ€ ì •ì±… ìš°ì„ ìˆœìœ„ ì œì‹œ\n",
      "n ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒëŠ” 2025ë…„ 1ì›” 28ì¼ ë¯¸êµ­ì˜ ê¸°ìˆ  ì£¼ë„ê¶Œ ìœ ì§€ë¥¼ ìœ„í•´ íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ê°€ ì¶”ì§„\n",
      "í•´ì•¼ í•  AI ì¤‘ì  ë¶„ì•¼ë¥¼ ì œì‹œí•œ ë³´ê³ ì„œë¥¼ ë°œí‘œí•˜ê³ , ì •ì±… ìš°ì„ ìˆœìœ„ë¡œ â–³ë…¸ë™ë ¥ â–³AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ \n",
      "â–³êµìœ¡ â–³ê³¼í•™ â–³ë³´ê±´ â–³ì •ë¶€ â–³ì¤‘ì†Œê¸°ì—… ì§€ì› â–³AI ê±°ë²„ë„ŒìŠ¤ â–³ë¯¸êµ­ ì‹œë¯¼ â–³ë²• ì§‘í–‰ì„ ì„ ì •\n",
      "âˆ™(ë…¸ë™ë ¥) AIê°€ ë…¸ë™ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€ì‘í•´ ì—°ë°© ì •ë¶€ì™€ ì£¼Â·ì§€ë°© ì •ë¶€ ê°„ í˜‘ë ¥ì„ ê°•í™”í•˜ê³  AIë¥¼ ë¹„ë¡¯í•œ \n",
      "ê¸°ìˆ  ê°œë°œ ì§€ì› ë“± AIë¡œ ì‹¤ì§ ìœ„í—˜ì— ì²˜í•œ ê·¼ë¡œì ì§€ì› ì „ëµì„ ë§ˆë ¨\n",
      "âˆ™(AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ) AIì˜ ê´‘ë²”ìœ„í•œ ë„ì…ì„ ìœ„í•´ ì „êµ­ ê·œëª¨ì˜ AI ì¸ì‹ ì œê³  ìº í˜ì¸ì„ ì‹œí–‰í•˜ê³  AI ê¸°ì´ˆ \n",
      "êµìœ¡, ì „ë¬¸ê³¼ì •, AI ìê²©ì¦ ê³¼ì •ê³¼ ê°™ì€ êµìœ¡ í”„ë¡œê·¸ë¨ì„ ê°•í™”\n",
      "âˆ™(êµìœ¡) êµìœ¡ í™˜ê²½ì— íŠ¹í™”ëœ AI ìœ„í—˜ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ê³  AI êµìœ¡ ê³¼ì •ê³¼ AI ë„êµ¬ ê°œë°œ í•´ì»¤í†¤ì„ ê°œìµœ\n",
      "âˆ™(ê³¼í•™) ì¤‘ìš”í•œ ì‚¬íšŒ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ AI ì ìš©ì„ í™•ëŒ€í•˜ê³ , ê³¼í•™ ë¶„ì•¼ì˜ AI ì—°êµ¬ì— ëŒ€í•œ ìê¸ˆ ìš°ì„ ìˆœìœ„ë¥¼ \n",
      "ì„¤ì •í•˜ë©° ì§€ì›ì„ ê°•í™”í•˜ëŠ” ì „ëµì„ ì¶”ì§„\n",
      "âˆ™(ë³´ê±´) ë°±ì•…ê´€ ê³¼í•™ê¸°ìˆ ìœ„ì›íšŒ(NSTC) ì‚°í•˜ AIíŠ¹ë³„ìœ„ì›íšŒ ë‚´ì— ê°œì¸ ê±´ê°•ì •ë³´ì˜ ì•ˆì „í•˜ê³  ì±…ì„ ìˆëŠ” \n",
      "ì‚¬ìš©ì„ ë‹´ë‹¹í•  ì†Œìœ„ì›íšŒë¥¼ ì‹ ì„¤ \n",
      "âˆ™(ì •ë¶€) AIë¡œ ì •ë¶€ì˜ ìš´ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒí•˜ê¸° ìœ„í•´ êµ­ê°€AIì´ë‹ˆì…”í‹°ë¸Œ ì‚¬ë¬´êµ­ì— ì¸ë ¥ê³¼ ìì›ì„ ì¶©ì›í•˜ê³  AI \n",
      "ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬ì¶•\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜(AI Action Summit)ëŠ” 2025ë…„ 2ì›” 10~11ì¼ í”„ë‘ìŠ¤ íŒŒë¦¬ì—ì„œ ê°œìµœëœ ê¸€ë¡œë²Œ AI ì •ìƒíšŒì˜ì…ë‹ˆë‹¤. ì´ íšŒì˜ì—ëŠ” ì „ ì„¸ê³„ 87ê°œêµ­ì—ì„œ ì •ë¶€, ê¸°ì—…, êµ­ì œê¸°êµ¬, ì‹œë¯¼ë‹¨ì²´ ë“± ì•½ 1,000ì—¬ ëª…ì´ ì°¸ì—¬í•´ AIì˜ ê¸€ë¡œë²Œ ê±°ë²„ë„ŒìŠ¤, ê³µê³µì„±, ì§€ì†ê°€ëŠ¥ì„±, ê·œì œ ì™„í™”, íˆ¬ì í™•ëŒ€ ë“±ì„ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ìš” ë‚´ìš©ê³¼ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AI ì„ ì–¸ë¬¸ ë°œí‘œ**\n",
      "   - í•œêµ­ì„ í¬í•¨í•œ 60ê°œêµ­ì´ â€˜ì¸ë¥˜ì™€ ì§€êµ¬ë¥¼ ìœ„í•œ í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸â€™ì„ ê³µë™ ë°œí‘œí–ˆìŠµë‹ˆë‹¤(ë¯¸êµ­, ì˜êµ­ì€ ë¶ˆì°¸).\n",
      "   - ì„ ì–¸ë¬¸ì€ ê³µìµì„ ìœ„í•œ AI, ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ëª©í‘œë¡œ í•˜ë©°, êµ¬ì²´ì  í–‰ë™ìœ¼ë¡œ\n",
      "     1) ê³µìµì„ ìœ„í•œ AI í”Œë«í¼ ë° ì¸íë² ì´í„° ì¶œë²”,\n",
      "     2) í™˜ê²½ì  ì§€ì†ê°€ëŠ¥ì„±ì„ ìœ„í•œ AI ì—ë„ˆì§€ ê´€ì¸¡ì†Œ ì„¤ë¦½,\n",
      "     3) ì¼ìë¦¬ì— ëŒ€í•œ AI ì˜í–¥ ê´€ì¸¡ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ë“±ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ê³µìµ AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AI(Current AI)â€™ ì¶œë²”**\n",
      "   - 9ê°œêµ­(í”„ë‘ìŠ¤, ë…ì¼, í•€ë€ë“œ, ìŠ¤ìœ„ìŠ¤, ìŠ¬ë¡œë² ë‹ˆì•„, ì¼€ëƒ, ë‚˜ì´ì§€ë¦¬ì•„, ëª¨ë¡œì½”, ì¹ ë ˆ)ê³¼ êµ¬ê¸€, ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“± ê¸€ë¡œë²Œ ê¸°ì—…ì´ 4ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•´ ê³µìµ AI í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.\n",
      "   - ì´ í”„ë¡œì íŠ¸ëŠ” ê³ í’ˆì§ˆ ê³µê³µ ë°ì´í„° ì ‘ê·¼ì„± í™•ëŒ€, ì˜¤í”ˆì†ŒìŠ¤ ì¸í”„ë¼ ì§€ì›, AIì˜ ì‚¬íšŒì Â·í™˜ê²½ì  ì˜í–¥ ì¸¡ì • ì‹œìŠ¤í…œ ê°œë°œ ë“±ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **AI ê·œì œ ì™„í™” ë° íˆ¬ì í™•ëŒ€ ë…¼ì˜**\n",
      "   - ë§ˆí¬ë¡± í”„ë‘ìŠ¤ ëŒ€í†µë ¹ì€ 1,090ì–µ ìœ ë¡œ ê·œëª¨ì˜ AI ì¸í”„ë¼ ë¯¼ê°„ íˆ¬ì í”„ë¡œì íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n",
      "   - AI ê·œì œ ì™„í™”ì™€ íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ ì˜ì œë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **EUì˜ AI ì •ì±… ë°œí‘œ**\n",
      "   - EU ì§‘í–‰ìœ„ì›íšŒëŠ” 2,000ì–µ ìœ ë¡œ ê·œëª¨ì˜ â€˜ì¸ë² ìŠ¤íŠ¸AIâ€™ ê³„íšì˜ ì¼í™˜ìœ¼ë¡œ 200ì–µ ìœ ë¡œë¥¼ íˆ¬ì…í•´ 4ê°œì˜ AI ê¸°ê°€íŒ©í† ë¦¬(ëŒ€ê·œëª¨ AI ë°ì´í„°ì„¼í„°)ë¥¼ ê±´ì„¤í•˜ê² ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n",
      "   - AI ì ìš© ì „ëµì„ í†µí•´ ì œì¡°ì—…, ì—ë„ˆì§€, ìë™ì°¨, ë¡œë´‡ê³µí•™, ì œì•½, í•­ê³µ, ê¸ˆìœµ ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì— AI ë„ì…ì„ ì´‰ì§„í•  ê³„íšì…ë‹ˆë‹¤.\n",
      "\n",
      "**ìš”ì•½**: íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ëŠ” AIì˜ ê³µê³µì„±, ì§€ì†ê°€ëŠ¥ì„±, ê·œì œ ì™„í™”, íˆ¬ì í™•ëŒ€ë¥¼ ë…¼ì˜í•˜ëŠ” ê¸€ë¡œë²Œ í˜‘ë ¥ì˜ ì¥ìœ¼ë¡œ, í¬ìš©ì  AI ì„ ì–¸ë¬¸ê³¼ ê³µìµ AI í”„ë¡œì íŠ¸ ì¶œë²” ë“± ì‹¤ì§ˆì  ê²°ê³¼ë¥¼ ë„ì¶œí•œ ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# RAG ì„œë²„ë¥¼ ìœ„í•œ StdIO ì„œë²„ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    args=[\"./mcp_server_rag.py\"],\n",
    ")\n",
    "\n",
    "# StdIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì„œë²„ì™€ í†µì‹ \n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # ì—°ê²° ì´ˆê¸°í™”\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP ë„êµ¬ ë¡œë“œ (ì—¬ê¸°ì„œëŠ” retriever ë„êµ¬)\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        await astream_graph(\n",
    "            agent, {\"messages\": \"íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSE ë°©ì‹ê³¼ StdIO ë°©ì‹ í˜¼í•© ì‚¬ìš©\n",
    "\n",
    "- íŒŒì¼: `mcp_server_rag.py` ëŠ” StdIO ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "- `langchain-dev-docs` ëŠ” SSE ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "\n",
    "SSE ë°©ì‹ê³¼ StdIO ë°©ì‹ì„ í˜¼í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# 1. ë‹¤ì¤‘ ì„œë²„ MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹  (í‘œì¤€ ì…ì¶œë ¥ ì‚¬ìš©)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"langchain-dev-docs\": {\n",
    "            # SSE ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”\n",
    "            \"url\": \"https://teddynote.io/mcp/langchain/sse\",\n",
    "            # SSE(Server-Sent Events) ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "            \"transport\": \"sse\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ëª…ì‹œì  ì—°ê²° ì´ˆê¸°í™”\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "prompt = (\n",
    "    \"You are a smart agent. \"\n",
    "    \"Use `retriever` tool to search on AI related documents and answer questions.\"\n",
    "    \"Use `langchain-dev-docs` tool to search on langchain / langgraph related documents and answer questions.\"\n",
    "    \"Answer in Korean.\"\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    model, client.get_tools(), prompt=prompt, checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "êµ¬ì¶•í•´ ë†“ì€ `mcp_server_rag.py` ì—ì„œ ì •ì˜í•œ `retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” `langchain-dev-docs` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\"messages\": \"langgraph-dev-docs ì°¸ê³ í•´ì„œ self-rag ì˜ ì •ì˜ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MemorySaver` ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ê¸° ê¸°ì–µì„ ìœ ì§€í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, multi-turn ëŒ€í™”ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent, {\"messages\": \"ì´ì „ì˜ ë‚´ìš©ì„ bullet point ë¡œ ìš”ì•½í•´ì¤˜\"}, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain ì— í†µí•©ëœ ë„êµ¬ + MCP ë„êµ¬\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LangChain ì— í†µí•©ëœ ë„êµ¬ë¥¼ ê¸°ì¡´ì˜ MCP ë¡œë§Œ ì´ë£¨ì–´ì§„ ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©ì´ ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤. (news íƒ€ì…, ìµœê·¼ 3ì¼ ë‚´ ë‰´ìŠ¤)\n",
    "tavily = TavilySearchResults(max_results=3, topic=\"news\", days=3)\n",
    "\n",
    "# ê¸°ì¡´ì˜ MCP ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "tools = client.get_tools() + [tavily]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# ì¬ê·€ ì œí•œ ë° ìŠ¤ë ˆë“œ ì•„ì´ë”” ì„¤ì •\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=2)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "prompt = \"You are a smart agent with various tools. Answer questions in Korean.\"\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_react_agent(model, tools, prompt=prompt, checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒˆë¡­ê²Œ ì¶”ê°€í•œ `tavily` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì°¾ì•„ì¤˜\"}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retriever` ë„êµ¬ê°€ ì›í™œí•˜ê²Œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ì´ë¦„ì„ ê²€ìƒ‰í•´ì¤˜\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smithery ì—ì„œ ì œê³µí•˜ëŠ” MCP ì„œë²„\n",
    "\n",
    "- ë§í¬: https://smithery.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ìš©í•œ ë„êµ¬ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- Sequential Thinking: https://smithery.ai/server/@smithery-ai/server-sequential-thinking\n",
    "  - êµ¬ì¡°í™”ëœ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì—­ë™ì ì´ê³  ì„±ì°°ì ì¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” MCP ì„œë²„\n",
    "- Desktop Commander: https://smithery.ai/server/@wonderwhy-er/desktop-commander\n",
    "  - ë‹¤ì–‘í•œ í¸ì§‘ ê¸°ëŠ¥ìœ¼ë¡œ í„°ë¯¸ë„ ëª…ë ¹ì„ ì‹¤í–‰í•˜ê³  íŒŒì¼ì„ ê´€ë¦¬í•˜ì„¸ìš”. ì½”ë”©, ì…¸ ë° í„°ë¯¸ë„, ì‘ì—… ìë™í™”\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- smithery ì—ì„œ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¬ë•Œ, ì•„ë˜ì˜ ì˜ˆì‹œì²˜ëŸ¼ `\"transport\": \"stdio\"` ë¡œ ê¼­ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatAnthropic(model=\"claude-3-7-sonnet-latest\", temperature=0, max_tokens=20000)\n",
    "\n",
    "# 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"server-sequential-thinking\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@smithery-ai/server-sequential-thinking\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        },\n",
    "        \"desktop-commander\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@wonderwhy-er/desktop-commander\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        },\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹  (í‘œì¤€ ì…ì¶œë ¥ ì‚¬ìš©)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ì´ˆê¸°í™”\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=3)\n",
    "agent = create_react_agent(model, client.get_tools(), checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Desktop Commander` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í„°ë¯¸ë„ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"í˜„ì¬ ê²½ë¡œë¥¼ í¬í•¨í•œ í•˜ìœ„ í´ë” êµ¬ì¡°ë¥¼ tree ë¡œ ê·¸ë ¤ì¤˜. ë‹¨, .venv í´ë”ëŠ” ì œì™¸í•˜ê³  ì¶œë ¥í•´ì¤˜.\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” `Sequential Thinking` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµì  ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  \"\n",
    "            \"`Sequential Thinking` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.\"\n",
    "        )\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
