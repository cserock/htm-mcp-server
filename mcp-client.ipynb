{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP + LangGraph Client Example\n",
    "\n",
    "**참고자료**\n",
    "- https://modelcontextprotocol.io/introduction\n",
    "- https://github.com/langchain-ai/langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경설정\n",
    "\n",
    "아래 설치 방법을 참고하여 `uv` 를 설치합니다.\n",
    "\n",
    "**uv 설치 방법**\n",
    "\n",
    "```bash\n",
    "# macOS/Linux\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Windows (PowerShell)\n",
    "irm https://astral.sh/uv/install.ps1 | iex\n",
    "```\n",
    "\n",
    "**의존성 설치**\n",
    "\n",
    "```bash\n",
    "uv pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경변수를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전에 `mcp_server_remote.py` 를 실행해둡니다. 터미널을 열고 가상환경이 활성화 되어 있는 상태에서 서버를 실행해 주세요.\n",
    "\n",
    "> 명령어\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "python mcp_server_remote.py\n",
    "```\n",
    "\n",
    "`async with` 로 일시적인 Session 연결을 생성 후 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_db_schema_info', description='\\n    Get the db schema for Tumblbug Database.\\n    Returns the original json contents without summarizing.\\n    ', args_schema={'properties': {}, 'title': 'get_db_schema_infoArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121d3fa60>)]\n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\n",
      "  \"query_tips\": [\n",
      "    \"주민등록번호, 휴대폰번호, 계좌번호 등의 민감한 개인정보는 노출되지 않도록 주의해 주세요.\",\n",
      "    \"생성일, 수정일, 프로젝트 시작일, 프로젝트 종료일 등의 날짜 컬럼을 where절에서 사용시 D+0 보다 크거나 같고 D+1 보다는 작게 쿼리를 작성해 주세요.\"\n",
      "  ],\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"table_name\": \"users\",\n",
      "      \"description\": \"사용자 테이블\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"사용자id|창작자id|후원자id\",\n",
      "        \"login\": \"이메일\",\n",
      "        \"created_at\": \"생성일\",\n",
      "        \"updated_at\": \"수정일\",\n",
      "        \"admin\": \"어드민 여부\",\n",
      "        \"is_creator\": \"창작자 여부\",\n",
      "        \"is_star_creator\": \"스타 창작자 여부\",\n",
      "        \"fullname\": \"이름\",\n",
      "        \"short_description\": \"설명\",\n",
      "        \"user_permalink\": \"사용자 링크|사용자 퍼머링크\",\n",
      "        \"homepage\": \"홈페이지URL\",\n",
      "        \"locname\": \"지역\",\n",
      "        \"phone1\": \"휴대폰번호 앞자리\",\n",
      "        \"phone2\": \"휴대폰번호 중간자리\",\n",
      "        \"phone3\": \"휴대폰번호 마지막자리\",\n",
      "        \"gender\": \"성별\",\n",
      "        \"email_verified\": \"이메일 인증 여부\",\n",
      "        \"address\": \"주소\",\n",
      "        \"last_logged_ip\": \"최종 로그인 ip\",\n",
      "        \"last_logged_in\": \"최종 로그인 시각\",\n",
      "        \"last_logged_out\": \"최종 로그아웃 시각\",\n",
      "        \"receive_newsletters\": \"뉴스레터 수신 여부\",\n",
      "        \"is_receive_project_notification\": \"프로젝트 알림 수신 여부\",\n",
      "        \"is_receive_message_notification\": \"메시지 알림 수신 여부\",\n",
      "        \"state\": \"상태 (0:정상,1:탈퇴)\",\n",
      "        \"age_range\": \"나이 범위\",\n",
      "        \"age_range_start\": \"나이 범위 시작\",\n",
      "        \"birthday\": \"생년월일\",\n",
      "        \"is_adult\": \"성인 여부\",\n",
      "        \"profile_image_filename\": \"프로필 이미지\",\n",
      "        \"uuid\": \"사용자 uuid\",\n",
      "        \"is_more_than_14yrs_old\": \"14세 이상 여부\",\n",
      "        \"is_auth\": \"본인 인증 여부\",\n",
      "        \"is_open_pledge_history\": \"후원 내역 공개 여부\",\n",
      "        \"last_passwd_changed_at\": \"최종 패스워드 변경일\",\n",
      "        \"is_push_project_update\": \"프로젝트 업데이트 push 수신 여부\",\n",
      "        \"is_push_project_progress\": \"프로젝트 진행상황 업데이트 push 수신 여부\",\n",
      "        \"is_push_message\": \"메시지 push 수신 여부\",\n",
      "        \"is_push_activity\": \"활동 push 수신 여부\",\n",
      "        \"is_push_marketing\": \"마케팅 push 수신 여부\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"projects\",\n",
      "      \"description\": \"프로젝트 테이블\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"프로젝트id\",\n",
      "        \"title\": \"프로젝트 제목\",\n",
      "        \"permalink\": \"프로젝트 링크|프로젝트 퍼머링크\",\n",
      "        \"project_type\": \"프로젝트 타입(FUNDING:펀딩,PREORDER:프리오더,PREORDER_FANCALL:프리오더 팬콜,PREORDER_GLOBAL:프리오더 글로벌)\",\n",
      "        \"rate_plan_type\": \"프로젝트 요금제\",\n",
      "        \"completemoney\": \"프로젝트 목표액\",\n",
      "        \"shipping_fee\": \"프로젝트 배송비\",\n",
      "        \"free_shipping_min_money\": \"프로젝트 무료 배송 가능 최소 비용\",\n",
      "        \"created_at\": \"프로젝트 생성일\",\n",
      "        \"updated_at\": \"프로젝트 변경일\",\n",
      "        \"short_description\": \"프로젝트 요약\",\n",
      "        \"start_date\": \"프로젝트 시작일\",\n",
      "        \"creator_id\": \"창작자id\",\n",
      "        \"description\": \"프로젝트 설명\",\n",
      "        \"user_description\": \"창작자 설명\",\n",
      "        \"locname\": \"지역\",\n",
      "        \"public_setting\": \"프로젝트 공개 여부\",\n",
      "        \"featured\": \"프로젝트 피처드 여부\",\n",
      "        \"success_mailed\": \"프로젝트 성공 메일 발송 여부\",\n",
      "        \"published_at\": \"프로젝트 심사 요청 일시\",\n",
      "        \"end_date\": \"프로젝트 종료일\",\n",
      "        \"prelaunched_at\": \"프로젝트 공개 예정 시작일\",\n",
      "        \"opened_at\": \"창작자가 입력한 프로젝트 시작일\",\n",
      "        \"use_prelaunch\": \"프로젝트 공개 예정 사용 여부\",\n",
      "        \"planned_at\": \"창작자가 지정한 프로젝트 시작일\",\n",
      "        \"is_fixed_plan\": \"프로젝트 시작일을 창작자가 지정했는지 여부\",\n",
      "        \"expected_delivery_date\": \"예상 배송일\",\n",
      "        \"progress_status\": \"프로젝트 성공 이후 진행 상황(FUNDING_SUCCESS:펀딩|모금 성공,IN_PROGRESS:진행중,DELIVERY_START:배송시작,DELIVERY_COMPLETE:배송완료)\",\n",
      "        \"is_reward_delivery_delayed\": \"배송 지연 여부\",\n",
      "        \"delivery_completed_at\": \"배송 완료일\",\n",
      "        \"estimated_settlement_date\": \"프로젝트 정산 예정일\",\n",
      "        \"current_money\": \"프로젝트 현재 모금액|프로젝트 현재 후원액\",\n",
      "        \"mailed_at\": \"메일 발송일\",\n",
      "        \"warranty_count_cache\": \"프로젝트 후원수|프로젝트 모금수\",\n",
      "        \"state\": \"프로젝트 상태(draft:작성중,submitted:심사요청,verified:승인,rejected:보완요청,final_rejected:반려,cancelled:취소,failed:실패,ongoing_not_reached:진행중,ongoing_reached:진행중/목표금액 도달,succeeded_not_balanced:성공,succeeded_balanced:성공/정산완료,prelaunched:공개예정)\",\n",
      "        \"weekly_project_warranties_count\": \"주간 프로젝트 후원수|주간 프로젝트 모금수\",\n",
      "        \"short_title\": \"프로젝트 짧은 제목\",\n",
      "        \"uuid\": \"프로젝트 uuid\",\n",
      "        \"public_state\": \"프로젝트 공개 여부(0:비공개,1:공개,2:비공개,3:비공개,4:비공개)\",\n",
      "        \"deposit_account_id\": \"프로젝트 정산id\",\n",
      "        \"cover_image_filename\": \"프로젝트 대표이미지, 'https://img.tumblbug.com/'를 붙여서 사용\",\n",
      "        \"taxpayer_id\": \"세금계산서id\",\n",
      "        \"taxpayer_type\": \"세금계산서 타입\",\n",
      "        \"posts_count\": \"포스트 작성 수\",\n",
      "        \"creator_posts_count_cache\": \"창작자 포스트 작성 수\",\n",
      "        \"backer_posts_count_cache\": \"후원자 포스트 작성 수\",\n",
      "        \"review_count_cache\": \"리뷰 작성 수\",\n",
      "        \"tags\": \"프로젝트 태그\",\n",
      "        \"category_id\": \"프로젝트 카테고리id\",\n",
      "        \"is_active\": \"프로젝트 활성화 여부\",\n",
      "        \"liked_count_cache\": \"프로젝트 좋아요 수\",\n",
      "        \"is_only_adult\": \"성인 프로젝트 여부\",\n",
      "        \"use_community\": \"커뮤니티 기능 사용여부 (0:미사용,1:사용)\",\n",
      "        \"payout_at\": \"정산 완료일\",\n",
      "        \"original_project_id\": \"팬콜 프로젝트인 경우 원본 프로젝트id\",\n",
      "        \"is_request_fancall_available\": \"팬콜 요청 투표 오픈 가능 여부\",\n",
      "        \"use_request_fancall\": \"팬콜 요청 투표 개시 여부\",\n",
      "        \"request_fancall_count_cache\": \"팬콜 요청 득표 수\",\n",
      "        \"request_fancall_first_started_at\": \"팬콜 요청 투표 최초 시작 일시\",\n",
      "        \"request_fancall_started_at\": \"팬콜 요청 투표 최근 시작 일시\",\n",
      "        \"request_fancall_ended_at\": \"팬콜 요청 투표 마지막 종료 일시\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"project_descriptions\",\n",
      "      \"description\": \"프로젝트 상세설명 테이블\",\n",
      "      \"query_tips\": \"`프로젝트id`를 기준으로 `프로젝트 상세설명' select시 참고 쿼리 : \\\"select * from project_descriptions where project_id = `프로젝트id` order by updated_at desc limit 1\\\"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"프로젝트 상세설명id\",\n",
      "        \"project_id\": \"프로젝트id\",\n",
      "        \"created_at\": \"생성일\",\n",
      "        \"updated_at\": \"수정일, 프로젝트 상세설명 select시에 가장 최근에 수정한 것을 select 해야함\",\n",
      "        \"purpose\": \"프로젝트 소개\",\n",
      "        \"rewards_description\": \"프로젝트 선물 설명\",\n",
      "        \"budget\": \"프로젝트 예산\",\n",
      "        \"schedule\": \"프로젝트 일정\",\n",
      "        \"introduction\": \"프로젝트 팀소개\",\n",
      "        \"is_admin\": \"어드민 여부\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"project_warranties\",\n",
      "      \"description\": \"후원 내역 테이블\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"address\": \"배송주소|배송지\",\n",
      "        \"cancelled_at\": \"후원취소시간\",\n",
      "        \"card_quota\": \"신용카드무이자할부개월수(0:일시불,그외무이자할부개월수)\",\n",
      "        \"created_at\": \"생성일\",\n",
      "        \"delivered_at\": \"배송완료일\",\n",
      "        \"extra_money\": \"추가 후원금\",\n",
      "        \"id\": \"후원id|후원번호\",\n",
      "        \"is_blocked\": \"포스트 차단\",\n",
      "        \"is_deleted\": \"삭제 여부(0:미삭제,1:삭제)\",\n",
      "        \"is_email_muted\": \"메일 차단\",\n",
      "        \"is_reviewed\": \"리뷰작성상태(0:미작성,1:작성)\",\n",
      "        \"money\": \"후원금\",\n",
      "        \"paid_at\": \"결제완료일시\",\n",
      "        \"paymenttype\": \"결제방법|결제타입|결제종류(0:신용카드,1:계좌이체,2:네이버페이)\",\n",
      "        \"paymenttype_id\": \"결제방법id|결제타입id|결제종류id\",\n",
      "        \"phone\": \"휴대폰번호\",\n",
      "        \"project_id\": \"프로젝트id\",\n",
      "        \"receiver\": \"받는사람|수취인\",\n",
      "        \"reward_id\": \"추가후원 업데이트 후 사용 안함\",\n",
      "        \"shipping_code\": \"택배번호\",\n",
      "        \"shipping_corp\": \"택배사\",\n",
      "        \"shipping_fee\": \"배송비\",\n",
      "        \"shipping_modify_due_date\": \"배송정보수정 마감일자. 후원자가 배송정보를 수정할 수 있는 마감일\",\n",
      "        \"state\": \"후원상태(0:후원 중,1:후원 취소,2:결제 완료,3:결제 재시도 중,4:결제 누락,5:결제 대기,6:결제 취소,7:환불 요청,8:환불 거절,9:환불 진행 중,10:환불 완료)\",\n",
      "        \"updated_at\": \"수정일\",\n",
      "        \"uuid\": \"후원uuid\",\n",
      "        \"warrantier_id\": \"후원자id|사용자id\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"withdraw_results\",\n",
      "      \"description\": \"결제 내역 테이블\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"결제id\",\n",
      "        \"bank_name\": \"은행명\",\n",
      "        \"commission\": \"결제수수료\",\n",
      "        \"created_at\": \"생성일\",\n",
      "        \"member_code\": \"결제코드\",\n",
      "        \"money\": \"결제금액\",\n",
      "        \"paymenttype\": \"결제방법|결제타입|결제종류(0:신용카드,1:계좌이체,2:네이버페이)\",\n",
      "        \"paymenttype_id\": \"결제방법id|결제타입id|결제종류id\",\n",
      "        \"project_warranty_id\": \"후원id\",\n",
      "        \"service_type\": \"PG사종류(0:Nice,1:CMS,2:Naverpay)\",\n",
      "        \"updated_at\": \"수정일\",\n",
      "        \"withdraw_at\": \"결제완료일시\",\n",
      "        \"withdrawal_status\": \"결제상태\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "텀블벅 DB 구조는 주요 테이블로 users, projects, project_descriptions, project_warranties, withdraw_results가 있습니다.\n",
      "\n",
      "1. users (사용자 테이블)\n",
      "- id: 사용자id\n",
      "- login: 이메일\n",
      "- fullname: 이름\n",
      "- phone1, phone2, phone3: 휴대폰번호\n",
      "- gender: 성별\n",
      "- email_verified: 이메일 인증 여부\n",
      "- address: 주소\n",
      "- created_at, updated_at: 생성일, 수정일\n",
      "- admin: 어드민 여부\n",
      "- is_creator: 창작자 여부\n",
      "- is_star_creator: 스타 창작자 여부\n",
      "- 기타 알림 수신 여부, 상태, 나이 범위, 프로필 이미지 등 사용자 관련 정보 컬럼 다수\n",
      "\n",
      "2. projects (프로젝트 테이블)\n",
      "- id: 프로젝트id\n",
      "- title: 프로젝트 제목\n",
      "- permalink: 프로젝트 링크\n",
      "- project_type: 프로젝트 타입 (펀딩, 프리오더 등)\n",
      "- completemoney: 목표액\n",
      "- shipping_fee: 배송비\n",
      "- created_at, updated_at: 생성일, 변경일\n",
      "- start_date, end_date: 프로젝트 시작일, 종료일\n",
      "- creator_id: 창작자id\n",
      "- description, short_description: 프로젝트 설명\n",
      "- locname: 지역\n",
      "- state: 프로젝트 상태 (작성중, 심사요청, 승인, 반려, 취소, 실패, 진행중, 성공 등)\n",
      "- progress_status: 진행 상황 (모금 성공, 진행중, 배송 시작 등)\n",
      "- current_money: 현재 모금액\n",
      "- cover_image_filename: 대표 이미지\n",
      "- category_id: 카테고리id\n",
      "- tags: 태그\n",
      "- 기타 프로젝트 관련 상세 정보 컬럼 다수\n",
      "\n",
      "3. project_descriptions (프로젝트 상세설명 테이블)\n",
      "- id: 상세설명id\n",
      "- project_id: 프로젝트id\n",
      "- purpose: 프로젝트 소개\n",
      "- rewards_description: 선물 설명\n",
      "- budget: 예산\n",
      "- schedule: 일정\n",
      "- introduction: 팀소개\n",
      "- created_at, updated_at: 생성일, 수정일\n",
      "\n",
      "4. project_warranties (후원 내역 테이블)\n",
      "- id: 후원id\n",
      "- project_id: 프로젝트id\n",
      "- warrantier_id: 후원자id\n",
      "- money: 후원금\n",
      "- state: 후원상태 (후원 중, 취소, 결제 완료 등)\n",
      "- created_at, updated_at: 생성일, 수정일\n",
      "- address, receiver, phone: 배송 주소 및 수취인 정보\n",
      "- paymenttype: 결제방법\n",
      "- cancelled_at, paid_at, delivered_at: 후원 취소, 결제 완료, 배송 완료 시각\n",
      "- 기타 후원 관련 정보 컬럼 다수\n",
      "\n",
      "5. withdraw_results (결제 내역 테이블)\n",
      "- id: 결제id\n",
      "- project_warranty_id: 후원id\n",
      "- money: 결제금액\n",
      "- bank_name: 은행명\n",
      "- commission: 결제수수료\n",
      "- paymenttype: 결제방법\n",
      "- withdraw_at: 결제 완료 시각\n",
      "- withdrawal_status: 결제 상태\n",
      "- created_at, updated_at: 생성일, 수정일\n",
      "\n",
      "필요한 테이블이나 컬럼에 대해 더 상세히 설명해 드릴 수 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-mini\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"tbb-db-schema\": {\n",
    "            # 서버의 포트와 일치해야 합니다.(8005번 포트)\n",
    "            # \"url\": \"http://localhost:8005/sse\",\n",
    "            \"url\": \"http://localhost:8008/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"서울의 날씨는 어떠니?\"})\n",
    "    answer = await astream_graph(agent, {\"messages\": \"텀블벅 스키마\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3665, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/rc/w7m_bf7x39bfb8wclzs_8xsr0000gn/T/ipykernel_44989/1848944460.py\", line 10, in <module>\n",
      "  |     async with MultiServerMCPClient(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 357, in __aenter__\n",
      "  |     await self.connect_to_server(server_name, **connection)\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 170, in connect_to_server\n",
      "  |     await self.connect_to_server_via_sse(\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 276, in connect_to_server_via_sse\n",
      "  |     sse_transport = await self.exit_stack.enter_async_context(\n",
      "  |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "  |     result = await _enter(cm)\n",
      "  |              ^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    |     yield\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    |     resp = await self._pool.handle_async_request(req)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    |     raise exc from None\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    |     response = await connection.handle_async_request(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    |     raise exc\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    |     stream = await self._connect(request)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
      "    |     stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
      "    |     return await self._backend.connect_tcp(\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
      "    |     with map_exceptions(exc_map):\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    |     raise to_exc(exc) from exc\n",
      "    | httpcore.ConnectError: All connection attempts failed\n",
      "    | \n",
      "    | The above exception was the direct cause of the following exception:\n",
      "    | \n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 47, in sse_client\n",
      "    |     async with aconnect_sse(\n",
      "    |                ^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx_sse/_api.py\", line 69, in aconnect_sse\n",
      "    |     async with client.stream(method, url, headers=headers, **kwargs) as response:\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1583, in stream\n",
      "    |     response = await self.send(\n",
      "    |                ^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    |     response = await self._send_handling_auth(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    |     response = await self._send_handling_redirects(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    |     response = await self._send_single_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    |     response = await transport.handle_async_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    |     with map_httpcore_exceptions():\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    |     raise mapped_exc(message) from exc\n",
      "    | httpx.ConnectError: All connection attempts failed\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            # 서버의 포트와 일치해야 합니다.(8005번 포트)\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    answer = await astream_graph(agent, {\"messages\": \"서울의 현재 시간은?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음의 경우에는 session 이 닫혔기 때문에 도구에 접근할 수 없는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "현재 저는 실시간 인터넷 접속이 불가능하여 최신 서울의 날씨 정보를 직접 제공할 수 없습니다. 하지만 일반적으로 6월의 서울은 초여름 날씨로, 평균 기온은 20~28도 사이이며, 습도가 높고 간혹 소나기가 내릴 수 있습니다.\n",
      "\n",
      "정확한 오늘의 날씨를 확인하려면 네이버, 다음, 기상청, 또는 스마트폰의 날씨 앱을 참고해 주세요! 필요하다면 서울의 계절별 기후 특징이나 여행 팁도 알려드릴 수 있습니다."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_a1102cf978'}, id='run-40cb5132-6563-454d-83ec-cc4fb6567166'),\n",
       " 'metadata': {'langgraph_step': 1,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"서울의 현재 시간은?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 그럼 Async Session 을 유지하며 도구에 접근하는 방식으로 변경해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_weather', description='\\n    Get current weather information for the specified location.\\n\\n    This function simulates a weather service by returning a fixed response.\\n    In a production environment, this would connect to a real weather API.\\n\\n    Args:\\n        location (str): The name of the location (city, region, etc.) to get weather for\\n\\n    Returns:\\n        str: A string containing the weather information for the specified location\\n    ', args_schema={'properties': {'location': {'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x10b898fe0>)]\n"
     ]
    }
   ],
   "source": [
    "# 1. 클라이언트 생성\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 명시적으로 연결 초기화 (이 부분이 필요함)\n",
    "# 초기화\n",
    "await client.__aenter__()\n",
    "\n",
    "# 이제 도구가 로드됨\n",
    "print(client.get_tools())  # 도구가 표시됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph 의 에이전트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에이전트 생성\n",
    "agent = create_react_agent(model, client.get_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 실행하여 결과를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's always Sunny in 서울\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "서울의 날씨는 항상 맑음입니다! 오늘도 화창한 하루를 보내실 수 있겠네요."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276'}, id='run-3f2f12d4-9aef-4379-9d53-3a83e3b18046'),\n",
       " 'metadata': {'langgraph_step': 3,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"서울의 현재 시간은?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdio 통신 방식\n",
    "\n",
    "Stdio 통신 방식은 로컬 환경에서 사용하기 위해 사용합니다.\n",
    "\n",
    "- 통신을 위해 표준 입력/출력 사용\n",
    "\n",
    "참고: 아래의 python 경로는 수정하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# StdIO 서버 파라미터 설정\n",
    "# - command: Python 인터프리터 경로\n",
    "# - args: 실행할 MCP 서버 스크립트\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    # args=[\"mcp_server_local.py\"],\n",
    "    args=[\"./resources/mcp_rag_help_center/mcp_server.py\"],\n",
    ")\n",
    "\n",
    "# StdIO 클라이언트를 사용하여 서버와 통신\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # 클라이언트 세션 생성\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # 연결 초기화\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP 도구 로드\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(tools)\n",
    "\n",
    "        # 에이전트 생성\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # 에이전트 응답 스트리밍\n",
    "        # await astream_graph(agent, {\"messages\": \"서울의 날씨는 어떠니?\"})\n",
    "        await astream_graph(agent, {\"messages\": \"창작자에 대해 설명해줘\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG 를 구축한 MCP 서버 사용\n",
    "\n",
    "- 파일: `mcp_server_rag.py`\n",
    "\n",
    "사전에 langchain 으로 구축한 `mcp_server_rag.py` 파일을 사용합니다.\n",
    "\n",
    "stdio 통신 방식으로 도구에 대한 정보를 가져옵니다. 여기서 도구는 `retriever` 도구를 가져오게 되며, 이 도구는 `mcp_server_rag.py` 에서 정의된 도구입니다. 이 파일은 사전에 서버에서 실행되지 **않아도** 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "정책･법제\n",
      "기업･산업\n",
      "기술･연구\n",
      "인력･교육\n",
      "3\n",
      "파리 AI 행동 정상회의, AI의 공공성·지속가능성과 함께 규제 완화 논의\n",
      "n 파리 AI 행동 정상회의의 주요 결과물로 포용적이고 지속가능한 AI를 위한 선언문이 발표되었으며, \n",
      "공익을 위한 AI 프로젝트 ‘커런트 AI’도 출범\n",
      "n 파리 AI 정상회의에서는 AI 규제 완화와 투자 확대가 핵심 의제로 떠올랐으며, 마크롱 프랑스 \n",
      "대통령은 1,090억 유로 규모의 AI 인프라 민간 투자 프로젝트도 발표\n",
      "KEY Contents\n",
      "£ 미국과 영국을 제외한 60개국, 포용적이고 지속가능한 AI에 대한 선언문 발표\n",
      "n 프랑스 정부가 2025년 2월 10~11일, 파리에서 ‘AI 행동 정상회의(AI Action Summit)’를 개최\n",
      "∙이번 정상회의에는 전 세계 87개 국가에서 기업, 국제기구, 시민단체 등 총 1,000여 명이 참여해 AI 글로벌 \n",
      "거버넌스를 심도 있게 논의\n",
      "n 정상회의 주요 결과물로 한국을 포함한 60개국이 공동 참여한 ‘인류와 지구를 위한 포용적이고 \n",
      "지속가능한 AI에 대한 선언문’이 발표되었고 미국과 영국은 선언에 불참    \n",
      "∙선언문은 공익을 위한 AI 및 지속가능한 AI를 목표로 제시하고, 이를 달성하기 위한 구체적 행동으로 \n",
      "①공익을 위한 AI 플랫폼 및 인큐베이터 출범 ②환경적 지속가능성을 위한 AI 에너지 관측소 설립 \n",
      "③일자리에 대한 AI 영향 관측 네트워크를 제시\n",
      "n 이번 정상회의에서는 9개국*과 구글, 세일즈포스 등의 기업이 4억 달러를 투자해 공익을 위한 \n",
      "AI 프로젝트 ‘커런트 AI(Current AI)’도 출범\n",
      "* 나이지리아, 독일, 모로코, 스위스, 슬로베니아, 칠레, 케냐, 프랑스, 핀란드  \n",
      "∙이 프로젝트는 공익 AI 환경 조성을 목표로 △AI 훈련을 위한 고품질 공공 데이터 접근성 확대 \n",
      "△오픈소스 인프라 지원 △AI의 사회적·환경적 영향을 측정하기 위한 시스템 개발 지원을 추진\n",
      "£ 파리 AI 정상회의, AI 규제 완화 및 AI 투자 확대가 핵심 화두로 부상\n",
      "SPRi AI Brief\n",
      "2025년 3월호\n",
      "4\n",
      "EU 집행위원회, 경쟁력 강화 로드맵의 일환으로 AI 기가팩토리 구축 추진\n",
      "n EU 집행위원회가 5개년 정책 로드맵 ‘경쟁력 나침반’에 따라 혁신 격차 해소를 위한 AI 정책으로 \n",
      "‘AI 기가팩토리’와 ‘AI 적용’ 전략을 제시\n",
      "n EU 집행위원회는 파리 AI 정상회의에서 총 2천억 유로 규모의 ‘인베스트AI’ 계획의 일환으로 \n",
      "200억 유로를 투입해 4개의 AI 기가팩토리를 건설하겠다고 발표  \n",
      "KEY Contents\n",
      "£ EU 집행위원회, 5개년 정책 로드맵 하에서 AI 기가팩토리와 AI 적용 전략 추진 \n",
      "n 우르줄라 폰 데어 라이엔(Ursula von der Leyen) EU 집행위원장이 2025년 1월 29일 2기 EU \n",
      "집행부(2024년 12월 출범)의 5개년 정책 로드맵 ‘경쟁력 나침반(Competitive Compass)’을 발표\n",
      "∙EU 집행위원회는 경쟁력 제고를 위해 △혁신 격차 해소 △脫탄소화 △공급망 안보의 3개 영역을 중점 \n",
      "과제로 제시했으며, 이중 혁신 격차 해소와 관련해 AI 정책을 포함\n",
      "n EU 집행위원회는 핵심 분야의 AI 개발과 산업계 AI 도입 활성화를 위한 ‘AI 기가팩토리(AI Gigafactory)’와 \n",
      "‘AI 적용(Apply AI)’ 전략을 제안\n",
      "∙AI 기가팩토리는 입법 추진 예정인 ‘EU 클라우드 및 AI 개발법(EU Cloud and AI Development \n",
      "Act)’*을 통해 공공과 민간 자금을 활용하여 초거대 AI 모델 훈련에 특화된 대규모 데이터센터를 \n",
      "구축함으로써 EU 전역의 AI 생태계를 활성화한다는 계획\n",
      "* 고성능 연산 자원과 디지털 인프라에 대한 강력한 규제 프레임워크를 통해 클라우드와 AI 분야에서 유럽의 리더십 강화를 위한 법안\n",
      "∙AI 적용 전략은 제조업, 에너지, 자동차, 로봇공학, 제약, 항공, 금융 서비스 산업의 AI 적용을 촉진하고 \n",
      "보건과 사법 등의 공공서비스 개선을 추진\n",
      "CONTENTS\n",
      "정책･법제\n",
      "∙미국 국가AI자문위원회, 트럼프 행정부 대상 AI 정책 보고서 발간\n",
      "2\n",
      "∙파리 AI 행동 정상회의, AI의 공공성·지속가능성과 함께 규제 완화 논의\n",
      "3\n",
      "∙EU 집행위원회, 경쟁력 강화 로드맵의 일환으로 AI 기가팩토리 구축 추진\n",
      "4\n",
      "∙EU 집행위원회, 2025년 업무 프로그램에서 ‘AI 책임 지침’ 철회 계획 발표\n",
      "5\n",
      "∙영국, AI안전연구소의 명칭 AI보안연구소로 변경하고 앤스로픽과 AI 협력 발표\n",
      "6\n",
      "기업･산업\n",
      "∙구글, 성능 개선한 ‘제미나이 2.0’ 제품군 확대 출시\n",
      "8\n",
      "∙ 오픈AI, 심층 조사를 수행하는 에이전트 ‘딥 리서치’ 공개\n",
      "9\n",
      "∙오픈AI, GPT-5 출시 로드맵 발표 및 GPT-4.5 프리뷰 공개\n",
      "10\n",
      "∙xAI, 최신 AI 모델 ‘그록 3’ 프리뷰 출시\n",
      "11\n",
      "∙퍼플렉시티, 심층 조사와 분석을 수행하는 ‘딥 리서치’ 무료 출시\n",
      "12\n",
      "∙알리바바, 딥시크 V3 능가하는 성능의 ‘큐원2.5-Max’ 출시\n",
      "13\n",
      "∙아크 인베스트, 2025년 혁신 기술 중 하나로 AI 에이전트 선정\n",
      "14\n",
      "기술･연구\n",
      "∙상하이교통⼤ 연구진, 소량의 고품질 데이터를 활용한 추론 AI 모델 개발\n",
      "16\n",
      "∙스탠포드⼤와 워싱턴⼤ 연구진, 저비용으로 고성능 추론 AI 모델 개발\n",
      "17\n",
      "∙바이트댄스, 인물 움직임을 생성하는 AI 모델 ‘옴니휴먼-1’ 개발\n",
      "18\n",
      "∙AI안전센터와 스케일 AI, 고난도 벤치마크 ‘HLE’ 공개\n",
      "19\n",
      "인력･교육 \n",
      "∙딜로이트 조사 결과, 전 세계 기업들은 점진적으로 AI 도입 확대\n",
      "21\n",
      "∙마이크로소프트 연구 결과, 생성 AI 신뢰할수록 비판적 사고 감소\n",
      "22\n",
      "∙앤스로픽, AI가 노동시장에 미치는 영향을 분석한 ‘앤스로픽 경제 지수’ 공개 \n",
      "23\n",
      "∙앤스로픽을 비롯한 여러 기업들, 입사 지원 시 AI 도구 사용금지 요구\n",
      "24\n",
      "주요행사일정\n",
      "25\n",
      "| 2025년 3월호 |\n",
      "SPRi AI Brief\n",
      "2025년 3월호\n",
      "2\n",
      "미국 국가AI자문위원회, 트럼프 행정부 대상 AI 정책 보고서 발간\n",
      "n AI 정책에 관하여 대통령과 연방 정부에 자문을 제공하는 미국 국가AI자문위원회(NAIAC)가 \n",
      "트럼프 행정부가 우선적으로 추진해야 할 AI 정책을 정리한 보고서를 발표\n",
      "n 보고서는 정책 우선순위로 △노동력 △AI 인식과 리터러시 △교육 △과학 △보건 △정부 \n",
      "△중소기업 지원 △AI 거버넌스 △미국 시민 △법 집행을 제시\n",
      "KEY Contents\n",
      "£ 미국 국가AI자문위원회, 미국의 AI 주도권 유지를 위한 10대 정책 우선순위 제시\n",
      "n 미국 국가AI자문위원회는 2025년 1월 28일 미국의 기술 주도권 유지를 위해 트럼프 행정부가 추진\n",
      "해야 할 AI 중점 분야를 제시한 보고서를 발표하고, 정책 우선순위로 △노동력 △AI 인식과 리터러시 \n",
      "△교육 △과학 △보건 △정부 △중소기업 지원 △AI 거버넌스 △미국 시민 △법 집행을 선정\n",
      "∙(노동력) AI가 노동시장에 미치는 영향에 대응해 연방 정부와 주·지방 정부 간 협력을 강화하고 AI를 비롯한 \n",
      "기술 개발 지원 등 AI로 실직 위험에 처한 근로자 지원 전략을 마련\n",
      "∙(AI 인식과 리터러시) AI의 광범위한 도입을 위해 전국 규모의 AI 인식 제고 캠페인을 시행하고 AI 기초 \n",
      "교육, 전문과정, AI 자격증 과정과 같은 교육 프로그램을 강화\n",
      "∙(교육) 교육 환경에 특화된 AI 위험관리 프레임워크를 개발하고 AI 교육 과정과 AI 도구 개발 해커톤을 개최\n",
      "∙(과학) 중요한 사회 문제 해결을 위해 AI 적용을 확대하고, 과학 분야의 AI 연구에 대한 자금 우선순위를 \n",
      "설정하며 지원을 강화하는 전략을 추진\n",
      "∙(보건) 백악관 과학기술위원회(NSTC) 산하 AI특별위원회 내에 개인 건강정보의 안전하고 책임 있는 \n",
      "사용을 담당할 소위원회를 신설 \n",
      "∙(정부) AI로 정부의 운영 효율성을 향상하기 위해 국가AI이니셔티브 사무국에 인력과 자원을 충원하고 AI \n",
      "모델 평가 프레임워크를 구축\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "파리 AI 행동 정상회의(AI Action Summit)는 2025년 2월 10~11일 프랑스 파리에서 개최된 글로벌 AI 정상회의입니다. 이 회의에는 전 세계 87개국에서 정부, 기업, 국제기구, 시민단체 등 약 1,000여 명이 참여해 AI의 글로벌 거버넌스, 공공성, 지속가능성, 규제 완화, 투자 확대 등을 논의했습니다.\n",
      "\n",
      "주요 내용과 결과는 다음과 같습니다:\n",
      "\n",
      "1. **포용적이고 지속가능한 AI 선언문 발표**\n",
      "   - 한국을 포함한 60개국이 ‘인류와 지구를 위한 포용적이고 지속가능한 AI에 대한 선언문’을 공동 발표했습니다(미국, 영국은 불참).\n",
      "   - 선언문은 공익을 위한 AI, 지속가능한 AI를 목표로 하며, 구체적 행동으로\n",
      "     1) 공익을 위한 AI 플랫폼 및 인큐베이터 출범,\n",
      "     2) 환경적 지속가능성을 위한 AI 에너지 관측소 설립,\n",
      "     3) 일자리에 대한 AI 영향 관측 네트워크 구축 등을 제시했습니다.\n",
      "\n",
      "2. **공익 AI 프로젝트 ‘커런트 AI(Current AI)’ 출범**\n",
      "   - 9개국(프랑스, 독일, 핀란드, 스위스, 슬로베니아, 케냐, 나이지리아, 모로코, 칠레)과 구글, 세일즈포스 등 글로벌 기업이 4억 달러를 투자해 공익 AI 프로젝트를 시작했습니다.\n",
      "   - 이 프로젝트는 고품질 공공 데이터 접근성 확대, 오픈소스 인프라 지원, AI의 사회적·환경적 영향 측정 시스템 개발 등을 목표로 합니다.\n",
      "\n",
      "3. **AI 규제 완화 및 투자 확대 논의**\n",
      "   - 마크롱 프랑스 대통령은 1,090억 유로 규모의 AI 인프라 민간 투자 프로젝트를 발표했습니다.\n",
      "   - AI 규제 완화와 투자 확대가 핵심 의제로 부상했습니다.\n",
      "\n",
      "4. **EU의 AI 정책 발표**\n",
      "   - EU 집행위원회는 2,000억 유로 규모의 ‘인베스트AI’ 계획의 일환으로 200억 유로를 투입해 4개의 AI 기가팩토리(대규모 AI 데이터센터)를 건설하겠다고 발표했습니다.\n",
      "   - AI 적용 전략을 통해 제조업, 에너지, 자동차, 로봇공학, 제약, 항공, 금융 서비스 등 다양한 산업에 AI 도입을 촉진할 계획입니다.\n",
      "\n",
      "**요약**: 파리 AI 행동 정상회의는 AI의 공공성, 지속가능성, 규제 완화, 투자 확대를 논의하는 글로벌 협력의 장으로, 포용적 AI 선언문과 공익 AI 프로젝트 출범 등 실질적 결과를 도출한 것이 특징입니다."
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# RAG 서버를 위한 StdIO 서버 파라미터 설정\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    args=[\"./mcp_server_rag.py\"],\n",
    ")\n",
    "\n",
    "# StdIO 클라이언트를 사용하여 RAG 서버와 통신\n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # 클라이언트 세션 생성\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # 연결 초기화\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP 도구 로드 (여기서는 retriever 도구)\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # 에이전트 생성 및 실행\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # 에이전트 응답 스트리밍\n",
    "        await astream_graph(\n",
    "            agent, {\"messages\": \"파리 AI 행동 정상회의에 대해 설명해줘\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSE 방식과 StdIO 방식 혼합 사용\n",
    "\n",
    "- 파일: `mcp_server_rag.py` 는 StdIO 방식으로 통신\n",
    "- `langchain-dev-docs` 는 SSE 방식으로 통신\n",
    "\n",
    "SSE 방식과 StdIO 방식을 혼합하여 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# 1. 다중 서버 MCP 클라이언트 생성\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py 파일의 절대 경로로 업데이트해야 합니다\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio 방식으로 통신 (표준 입출력 사용)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"langchain-dev-docs\": {\n",
    "            # SSE 서버가 실행 중인지 확인하세요\n",
    "            \"url\": \"https://teddynote.io/mcp/langchain/sse\",\n",
    "            # SSE(Server-Sent Events) 방식으로 통신\n",
    "            \"transport\": \"sse\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 비동기 컨텍스트 매니저를 통한 명시적 연결 초기화\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph 의 `create_react_agent` 를 사용하여 에이전트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "prompt = (\n",
    "    \"You are a smart agent. \"\n",
    "    \"Use `retriever` tool to search on AI related documents and answer questions.\"\n",
    "    \"Use `langchain-dev-docs` tool to search on langchain / langgraph related documents and answer questions.\"\n",
    "    \"Answer in Korean.\"\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    model, client.get_tools(), prompt=prompt, checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구축해 놓은 `mcp_server_rag.py` 에서 정의한 `retriever` 도구를 사용하여 검색을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` 도구를 사용해서 파리 AI 행동 정상회의에 대해 설명해줘\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 `langchain-dev-docs` 도구를 사용하여 검색을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\"messages\": \"langgraph-dev-docs 참고해서 self-rag 의 정의에 대해서 알려줘\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MemorySaver` 를 사용하여 단기 기억을 유지합니다. 따라서, multi-turn 대화도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent, {\"messages\": \"이전의 내용을 bullet point 로 요약해줘\"}, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain 에 통합된 도구 + MCP 도구\n",
    "\n",
    "여기서는 LangChain 에 통합된 도구를 기존의 MCP 로만 이루어진 도구와 함께 사용이 가능한지 테스트 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily 검색 도구를 초기화 합니다. (news 타입, 최근 3일 내 뉴스)\n",
    "tavily = TavilySearchResults(max_results=3, topic=\"news\", days=3)\n",
    "\n",
    "# 기존의 MCP 도구와 함께 사용합니다.\n",
    "tools = client.get_tools() + [tavily]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph 의 `create_react_agent` 를 사용하여 에이전트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 재귀 제한 및 스레드 아이디 설정\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=2)\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = \"You are a smart agent with various tools. Answer questions in Korean.\"\n",
    "\n",
    "# 에이전트 생성\n",
    "agent = create_react_agent(model, tools, prompt=prompt, checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "새롭게 추가한 `tavily` 도구를 사용하여 검색을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(agent, {\"messages\": \"오늘 뉴스 찾아줘\"}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retriever` 도구가 원활하게 작동하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` 도구를 사용해서 삼성전자가 개발한 생성형 AI 이름을 검색해줘\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smithery 에서 제공하는 MCP 서버\n",
    "\n",
    "- 링크: https://smithery.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용한 도구 목록은 아래와 같습니다.\n",
    "\n",
    "- Sequential Thinking: https://smithery.ai/server/@smithery-ai/server-sequential-thinking\n",
    "  - 구조화된 사고 프로세스를 통해 역동적이고 성찰적인 문제 해결을 위한 도구를 제공하는 MCP 서버\n",
    "- Desktop Commander: https://smithery.ai/server/@wonderwhy-er/desktop-commander\n",
    "  - 다양한 편집 기능으로 터미널 명령을 실행하고 파일을 관리하세요. 코딩, 셸 및 터미널, 작업 자동화\n",
    "\n",
    "**참고**\n",
    "\n",
    "- smithery 에서 제공하는 도구를 JSON 형식으로 가져올때, 아래의 예시처럼 `\"transport\": \"stdio\"` 로 꼭 설정해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# LLM 모델 초기화\n",
    "model = ChatAnthropic(model=\"claude-3-7-sonnet-latest\", temperature=0, max_tokens=20000)\n",
    "\n",
    "# 1. 클라이언트 생성\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"server-sequential-thinking\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@smithery-ai/server-sequential-thinking\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio 방식으로 통신을 추가합니다.\n",
    "        },\n",
    "        \"desktop-commander\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@wonderwhy-er/desktop-commander\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio 방식으로 통신을 추가합니다.\n",
    "        },\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py 파일의 절대 경로로 업데이트해야 합니다\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio 방식으로 통신 (표준 입출력 사용)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. 명시적으로 연결 초기화\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph 의 `create_react_agent` 를 사용하여 에이전트를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=3)\n",
    "agent = create_react_agent(model, client.get_tools(), checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Desktop Commander` 도구를 사용하여 터미널 명령을 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"현재 경로를 포함한 하위 폴더 구조를 tree 로 그려줘. 단, .venv 폴더는 제외하고 출력해줘.\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 `Sequential Thinking` 도구를 사용하여 비교적 복잡한 작업을 수행할 수 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"`retriever` 도구를 사용해서 삼성전자가 개발한 생성형 AI 관련 내용을 검색하고 \"\n",
    "            \"`Sequential Thinking` 도구를 사용해서 보고서를 작성해줘.\"\n",
    "        )\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
