{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP + LangGraph Client Example\n",
    "\n",
    "**ì°¸ê³ ìë£Œ**\n",
    "- https://modelcontextprotocol.io/introduction\n",
    "- https://github.com/langchain-ai/langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## í™˜ê²½ì„¤ì •\n",
    "\n",
    "ì•„ë˜ ì„¤ì¹˜ ë°©ë²•ì„ ì°¸ê³ í•˜ì—¬ `uv` ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "**uv ì„¤ì¹˜ ë°©ë²•**\n",
    "\n",
    "```bash\n",
    "# macOS/Linux\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Windows (PowerShell)\n",
    "irm https://astral.sh/uv/install.ps1 | iex\n",
    "```\n",
    "\n",
    "**ì˜ì¡´ì„± ì„¤ì¹˜**\n",
    "\n",
    "```bash\n",
    "uv pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "í™˜ê²½ë³€ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ì „ì— `mcp_server_remote.py` ë¥¼ ì‹¤í–‰í•´ë‘¡ë‹ˆë‹¤. í„°ë¯¸ë„ì„ ì—´ê³  ê°€ìƒí™˜ê²½ì´ í™œì„±í™” ë˜ì–´ ìˆëŠ” ìƒíƒœì—ì„œ ì„œë²„ë¥¼ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "> ëª…ë ¹ì–´\n",
    "```bash\n",
    "source .venv/bin/activate\n",
    "python mcp_server_remote.py\n",
    "```\n",
    "\n",
    "`async with` ë¡œ ì¼ì‹œì ì¸ Session ì—°ê²°ì„ ìƒì„± í›„ í•´ì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_db_schema_info', description='\\n    Get the db schema for Tumblbug Database.\\n    Returns the original json contents without summarizing.\\n    ', args_schema={'properties': {}, 'title': 'get_db_schema_infoArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x121d3fa60>)]\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "{\n",
      "  \"query_tips\": [\n",
      "    \"ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸, íœ´ëŒ€í°ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ ë“±ì˜ ë¯¼ê°í•œ ê°œì¸ì •ë³´ëŠ” ë…¸ì¶œë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•´ ì£¼ì„¸ìš”.\",\n",
      "    \"ìƒì„±ì¼, ìˆ˜ì •ì¼, í”„ë¡œì íŠ¸ ì‹œì‘ì¼, í”„ë¡œì íŠ¸ ì¢…ë£Œì¼ ë“±ì˜ ë‚ ì§œ ì»¬ëŸ¼ì„ whereì ˆì—ì„œ ì‚¬ìš©ì‹œ D+0 ë³´ë‹¤ í¬ê±°ë‚˜ ê°™ê³  D+1 ë³´ë‹¤ëŠ” ì‘ê²Œ ì¿¼ë¦¬ë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.\"\n",
      "  ],\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"table_name\": \"users\",\n",
      "      \"description\": \"ì‚¬ìš©ì í…Œì´ë¸”\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"ì‚¬ìš©ìid|ì°½ì‘ìid|í›„ì›ìid\",\n",
      "        \"login\": \"ì´ë©”ì¼\",\n",
      "        \"created_at\": \"ìƒì„±ì¼\",\n",
      "        \"updated_at\": \"ìˆ˜ì •ì¼\",\n",
      "        \"admin\": \"ì–´ë“œë¯¼ ì—¬ë¶€\",\n",
      "        \"is_creator\": \"ì°½ì‘ì ì—¬ë¶€\",\n",
      "        \"is_star_creator\": \"ìŠ¤íƒ€ ì°½ì‘ì ì—¬ë¶€\",\n",
      "        \"fullname\": \"ì´ë¦„\",\n",
      "        \"short_description\": \"ì„¤ëª…\",\n",
      "        \"user_permalink\": \"ì‚¬ìš©ì ë§í¬|ì‚¬ìš©ì í¼ë¨¸ë§í¬\",\n",
      "        \"homepage\": \"í™ˆí˜ì´ì§€URL\",\n",
      "        \"locname\": \"ì§€ì—­\",\n",
      "        \"phone1\": \"íœ´ëŒ€í°ë²ˆí˜¸ ì•ìë¦¬\",\n",
      "        \"phone2\": \"íœ´ëŒ€í°ë²ˆí˜¸ ì¤‘ê°„ìë¦¬\",\n",
      "        \"phone3\": \"íœ´ëŒ€í°ë²ˆí˜¸ ë§ˆì§€ë§‰ìë¦¬\",\n",
      "        \"gender\": \"ì„±ë³„\",\n",
      "        \"email_verified\": \"ì´ë©”ì¼ ì¸ì¦ ì—¬ë¶€\",\n",
      "        \"address\": \"ì£¼ì†Œ\",\n",
      "        \"last_logged_ip\": \"ìµœì¢… ë¡œê·¸ì¸ ip\",\n",
      "        \"last_logged_in\": \"ìµœì¢… ë¡œê·¸ì¸ ì‹œê°\",\n",
      "        \"last_logged_out\": \"ìµœì¢… ë¡œê·¸ì•„ì›ƒ ì‹œê°\",\n",
      "        \"receive_newsletters\": \"ë‰´ìŠ¤ë ˆí„° ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_receive_project_notification\": \"í”„ë¡œì íŠ¸ ì•Œë¦¼ ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_receive_message_notification\": \"ë©”ì‹œì§€ ì•Œë¦¼ ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"state\": \"ìƒíƒœ (0:ì •ìƒ,1:íƒˆí‡´)\",\n",
      "        \"age_range\": \"ë‚˜ì´ ë²”ìœ„\",\n",
      "        \"age_range_start\": \"ë‚˜ì´ ë²”ìœ„ ì‹œì‘\",\n",
      "        \"birthday\": \"ìƒë…„ì›”ì¼\",\n",
      "        \"is_adult\": \"ì„±ì¸ ì—¬ë¶€\",\n",
      "        \"profile_image_filename\": \"í”„ë¡œí•„ ì´ë¯¸ì§€\",\n",
      "        \"uuid\": \"ì‚¬ìš©ì uuid\",\n",
      "        \"is_more_than_14yrs_old\": \"14ì„¸ ì´ìƒ ì—¬ë¶€\",\n",
      "        \"is_auth\": \"ë³¸ì¸ ì¸ì¦ ì—¬ë¶€\",\n",
      "        \"is_open_pledge_history\": \"í›„ì› ë‚´ì—­ ê³µê°œ ì—¬ë¶€\",\n",
      "        \"last_passwd_changed_at\": \"ìµœì¢… íŒ¨ìŠ¤ì›Œë“œ ë³€ê²½ì¼\",\n",
      "        \"is_push_project_update\": \"í”„ë¡œì íŠ¸ ì—…ë°ì´íŠ¸ push ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_push_project_progress\": \"í”„ë¡œì íŠ¸ ì§„í–‰ìƒí™© ì—…ë°ì´íŠ¸ push ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_push_message\": \"ë©”ì‹œì§€ push ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_push_activity\": \"í™œë™ push ìˆ˜ì‹  ì—¬ë¶€\",\n",
      "        \"is_push_marketing\": \"ë§ˆì¼€íŒ… push ìˆ˜ì‹  ì—¬ë¶€\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"projects\",\n",
      "      \"description\": \"í”„ë¡œì íŠ¸ í…Œì´ë¸”\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"í”„ë¡œì íŠ¸id\",\n",
      "        \"title\": \"í”„ë¡œì íŠ¸ ì œëª©\",\n",
      "        \"permalink\": \"í”„ë¡œì íŠ¸ ë§í¬|í”„ë¡œì íŠ¸ í¼ë¨¸ë§í¬\",\n",
      "        \"project_type\": \"í”„ë¡œì íŠ¸ íƒ€ì…(FUNDING:í€ë”©,PREORDER:í”„ë¦¬ì˜¤ë”,PREORDER_FANCALL:í”„ë¦¬ì˜¤ë” íŒ¬ì½œ,PREORDER_GLOBAL:í”„ë¦¬ì˜¤ë” ê¸€ë¡œë²Œ)\",\n",
      "        \"rate_plan_type\": \"í”„ë¡œì íŠ¸ ìš”ê¸ˆì œ\",\n",
      "        \"completemoney\": \"í”„ë¡œì íŠ¸ ëª©í‘œì•¡\",\n",
      "        \"shipping_fee\": \"í”„ë¡œì íŠ¸ ë°°ì†¡ë¹„\",\n",
      "        \"free_shipping_min_money\": \"í”„ë¡œì íŠ¸ ë¬´ë£Œ ë°°ì†¡ ê°€ëŠ¥ ìµœì†Œ ë¹„ìš©\",\n",
      "        \"created_at\": \"í”„ë¡œì íŠ¸ ìƒì„±ì¼\",\n",
      "        \"updated_at\": \"í”„ë¡œì íŠ¸ ë³€ê²½ì¼\",\n",
      "        \"short_description\": \"í”„ë¡œì íŠ¸ ìš”ì•½\",\n",
      "        \"start_date\": \"í”„ë¡œì íŠ¸ ì‹œì‘ì¼\",\n",
      "        \"creator_id\": \"ì°½ì‘ìid\",\n",
      "        \"description\": \"í”„ë¡œì íŠ¸ ì„¤ëª…\",\n",
      "        \"user_description\": \"ì°½ì‘ì ì„¤ëª…\",\n",
      "        \"locname\": \"ì§€ì—­\",\n",
      "        \"public_setting\": \"í”„ë¡œì íŠ¸ ê³µê°œ ì—¬ë¶€\",\n",
      "        \"featured\": \"í”„ë¡œì íŠ¸ í”¼ì²˜ë“œ ì—¬ë¶€\",\n",
      "        \"success_mailed\": \"í”„ë¡œì íŠ¸ ì„±ê³µ ë©”ì¼ ë°œì†¡ ì—¬ë¶€\",\n",
      "        \"published_at\": \"í”„ë¡œì íŠ¸ ì‹¬ì‚¬ ìš”ì²­ ì¼ì‹œ\",\n",
      "        \"end_date\": \"í”„ë¡œì íŠ¸ ì¢…ë£Œì¼\",\n",
      "        \"prelaunched_at\": \"í”„ë¡œì íŠ¸ ê³µê°œ ì˜ˆì • ì‹œì‘ì¼\",\n",
      "        \"opened_at\": \"ì°½ì‘ìê°€ ì…ë ¥í•œ í”„ë¡œì íŠ¸ ì‹œì‘ì¼\",\n",
      "        \"use_prelaunch\": \"í”„ë¡œì íŠ¸ ê³µê°œ ì˜ˆì • ì‚¬ìš© ì—¬ë¶€\",\n",
      "        \"planned_at\": \"ì°½ì‘ìê°€ ì§€ì •í•œ í”„ë¡œì íŠ¸ ì‹œì‘ì¼\",\n",
      "        \"is_fixed_plan\": \"í”„ë¡œì íŠ¸ ì‹œì‘ì¼ì„ ì°½ì‘ìê°€ ì§€ì •í–ˆëŠ”ì§€ ì—¬ë¶€\",\n",
      "        \"expected_delivery_date\": \"ì˜ˆìƒ ë°°ì†¡ì¼\",\n",
      "        \"progress_status\": \"í”„ë¡œì íŠ¸ ì„±ê³µ ì´í›„ ì§„í–‰ ìƒí™©(FUNDING_SUCCESS:í€ë”©|ëª¨ê¸ˆ ì„±ê³µ,IN_PROGRESS:ì§„í–‰ì¤‘,DELIVERY_START:ë°°ì†¡ì‹œì‘,DELIVERY_COMPLETE:ë°°ì†¡ì™„ë£Œ)\",\n",
      "        \"is_reward_delivery_delayed\": \"ë°°ì†¡ ì§€ì—° ì—¬ë¶€\",\n",
      "        \"delivery_completed_at\": \"ë°°ì†¡ ì™„ë£Œì¼\",\n",
      "        \"estimated_settlement_date\": \"í”„ë¡œì íŠ¸ ì •ì‚° ì˜ˆì •ì¼\",\n",
      "        \"current_money\": \"í”„ë¡œì íŠ¸ í˜„ì¬ ëª¨ê¸ˆì•¡|í”„ë¡œì íŠ¸ í˜„ì¬ í›„ì›ì•¡\",\n",
      "        \"mailed_at\": \"ë©”ì¼ ë°œì†¡ì¼\",\n",
      "        \"warranty_count_cache\": \"í”„ë¡œì íŠ¸ í›„ì›ìˆ˜|í”„ë¡œì íŠ¸ ëª¨ê¸ˆìˆ˜\",\n",
      "        \"state\": \"í”„ë¡œì íŠ¸ ìƒíƒœ(draft:ì‘ì„±ì¤‘,submitted:ì‹¬ì‚¬ìš”ì²­,verified:ìŠ¹ì¸,rejected:ë³´ì™„ìš”ì²­,final_rejected:ë°˜ë ¤,cancelled:ì·¨ì†Œ,failed:ì‹¤íŒ¨,ongoing_not_reached:ì§„í–‰ì¤‘,ongoing_reached:ì§„í–‰ì¤‘/ëª©í‘œê¸ˆì•¡ ë„ë‹¬,succeeded_not_balanced:ì„±ê³µ,succeeded_balanced:ì„±ê³µ/ì •ì‚°ì™„ë£Œ,prelaunched:ê³µê°œì˜ˆì •)\",\n",
      "        \"weekly_project_warranties_count\": \"ì£¼ê°„ í”„ë¡œì íŠ¸ í›„ì›ìˆ˜|ì£¼ê°„ í”„ë¡œì íŠ¸ ëª¨ê¸ˆìˆ˜\",\n",
      "        \"short_title\": \"í”„ë¡œì íŠ¸ ì§§ì€ ì œëª©\",\n",
      "        \"uuid\": \"í”„ë¡œì íŠ¸ uuid\",\n",
      "        \"public_state\": \"í”„ë¡œì íŠ¸ ê³µê°œ ì—¬ë¶€(0:ë¹„ê³µê°œ,1:ê³µê°œ,2:ë¹„ê³µê°œ,3:ë¹„ê³µê°œ,4:ë¹„ê³µê°œ)\",\n",
      "        \"deposit_account_id\": \"í”„ë¡œì íŠ¸ ì •ì‚°id\",\n",
      "        \"cover_image_filename\": \"í”„ë¡œì íŠ¸ ëŒ€í‘œì´ë¯¸ì§€, 'https://img.tumblbug.com/'ë¥¼ ë¶™ì—¬ì„œ ì‚¬ìš©\",\n",
      "        \"taxpayer_id\": \"ì„¸ê¸ˆê³„ì‚°ì„œid\",\n",
      "        \"taxpayer_type\": \"ì„¸ê¸ˆê³„ì‚°ì„œ íƒ€ì…\",\n",
      "        \"posts_count\": \"í¬ìŠ¤íŠ¸ ì‘ì„± ìˆ˜\",\n",
      "        \"creator_posts_count_cache\": \"ì°½ì‘ì í¬ìŠ¤íŠ¸ ì‘ì„± ìˆ˜\",\n",
      "        \"backer_posts_count_cache\": \"í›„ì›ì í¬ìŠ¤íŠ¸ ì‘ì„± ìˆ˜\",\n",
      "        \"review_count_cache\": \"ë¦¬ë·° ì‘ì„± ìˆ˜\",\n",
      "        \"tags\": \"í”„ë¡œì íŠ¸ íƒœê·¸\",\n",
      "        \"category_id\": \"í”„ë¡œì íŠ¸ ì¹´í…Œê³ ë¦¬id\",\n",
      "        \"is_active\": \"í”„ë¡œì íŠ¸ í™œì„±í™” ì—¬ë¶€\",\n",
      "        \"liked_count_cache\": \"í”„ë¡œì íŠ¸ ì¢‹ì•„ìš” ìˆ˜\",\n",
      "        \"is_only_adult\": \"ì„±ì¸ í”„ë¡œì íŠ¸ ì—¬ë¶€\",\n",
      "        \"use_community\": \"ì»¤ë®¤ë‹ˆí‹° ê¸°ëŠ¥ ì‚¬ìš©ì—¬ë¶€ (0:ë¯¸ì‚¬ìš©,1:ì‚¬ìš©)\",\n",
      "        \"payout_at\": \"ì •ì‚° ì™„ë£Œì¼\",\n",
      "        \"original_project_id\": \"íŒ¬ì½œ í”„ë¡œì íŠ¸ì¸ ê²½ìš° ì›ë³¸ í”„ë¡œì íŠ¸id\",\n",
      "        \"is_request_fancall_available\": \"íŒ¬ì½œ ìš”ì²­ íˆ¬í‘œ ì˜¤í”ˆ ê°€ëŠ¥ ì—¬ë¶€\",\n",
      "        \"use_request_fancall\": \"íŒ¬ì½œ ìš”ì²­ íˆ¬í‘œ ê°œì‹œ ì—¬ë¶€\",\n",
      "        \"request_fancall_count_cache\": \"íŒ¬ì½œ ìš”ì²­ ë“í‘œ ìˆ˜\",\n",
      "        \"request_fancall_first_started_at\": \"íŒ¬ì½œ ìš”ì²­ íˆ¬í‘œ ìµœì´ˆ ì‹œì‘ ì¼ì‹œ\",\n",
      "        \"request_fancall_started_at\": \"íŒ¬ì½œ ìš”ì²­ íˆ¬í‘œ ìµœê·¼ ì‹œì‘ ì¼ì‹œ\",\n",
      "        \"request_fancall_ended_at\": \"íŒ¬ì½œ ìš”ì²­ íˆ¬í‘œ ë§ˆì§€ë§‰ ì¢…ë£Œ ì¼ì‹œ\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"project_descriptions\",\n",
      "      \"description\": \"í”„ë¡œì íŠ¸ ìƒì„¸ì„¤ëª… í…Œì´ë¸”\",\n",
      "      \"query_tips\": \"`í”„ë¡œì íŠ¸id`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ `í”„ë¡œì íŠ¸ ìƒì„¸ì„¤ëª…' selectì‹œ ì°¸ê³  ì¿¼ë¦¬ : \\\"select * from project_descriptions where project_id = `í”„ë¡œì íŠ¸id` order by updated_at desc limit 1\\\"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"í”„ë¡œì íŠ¸ ìƒì„¸ì„¤ëª…id\",\n",
      "        \"project_id\": \"í”„ë¡œì íŠ¸id\",\n",
      "        \"created_at\": \"ìƒì„±ì¼\",\n",
      "        \"updated_at\": \"ìˆ˜ì •ì¼, í”„ë¡œì íŠ¸ ìƒì„¸ì„¤ëª… selectì‹œì— ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •í•œ ê²ƒì„ select í•´ì•¼í•¨\",\n",
      "        \"purpose\": \"í”„ë¡œì íŠ¸ ì†Œê°œ\",\n",
      "        \"rewards_description\": \"í”„ë¡œì íŠ¸ ì„ ë¬¼ ì„¤ëª…\",\n",
      "        \"budget\": \"í”„ë¡œì íŠ¸ ì˜ˆì‚°\",\n",
      "        \"schedule\": \"í”„ë¡œì íŠ¸ ì¼ì •\",\n",
      "        \"introduction\": \"í”„ë¡œì íŠ¸ íŒ€ì†Œê°œ\",\n",
      "        \"is_admin\": \"ì–´ë“œë¯¼ ì—¬ë¶€\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"project_warranties\",\n",
      "      \"description\": \"í›„ì› ë‚´ì—­ í…Œì´ë¸”\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"address\": \"ë°°ì†¡ì£¼ì†Œ|ë°°ì†¡ì§€\",\n",
      "        \"cancelled_at\": \"í›„ì›ì·¨ì†Œì‹œê°„\",\n",
      "        \"card_quota\": \"ì‹ ìš©ì¹´ë“œë¬´ì´ìí• ë¶€ê°œì›”ìˆ˜(0:ì¼ì‹œë¶ˆ,ê·¸ì™¸ë¬´ì´ìí• ë¶€ê°œì›”ìˆ˜)\",\n",
      "        \"created_at\": \"ìƒì„±ì¼\",\n",
      "        \"delivered_at\": \"ë°°ì†¡ì™„ë£Œì¼\",\n",
      "        \"extra_money\": \"ì¶”ê°€ í›„ì›ê¸ˆ\",\n",
      "        \"id\": \"í›„ì›id|í›„ì›ë²ˆí˜¸\",\n",
      "        \"is_blocked\": \"í¬ìŠ¤íŠ¸ ì°¨ë‹¨\",\n",
      "        \"is_deleted\": \"ì‚­ì œ ì—¬ë¶€(0:ë¯¸ì‚­ì œ,1:ì‚­ì œ)\",\n",
      "        \"is_email_muted\": \"ë©”ì¼ ì°¨ë‹¨\",\n",
      "        \"is_reviewed\": \"ë¦¬ë·°ì‘ì„±ìƒíƒœ(0:ë¯¸ì‘ì„±,1:ì‘ì„±)\",\n",
      "        \"money\": \"í›„ì›ê¸ˆ\",\n",
      "        \"paid_at\": \"ê²°ì œì™„ë£Œì¼ì‹œ\",\n",
      "        \"paymenttype\": \"ê²°ì œë°©ë²•|ê²°ì œíƒ€ì…|ê²°ì œì¢…ë¥˜(0:ì‹ ìš©ì¹´ë“œ,1:ê³„ì¢Œì´ì²´,2:ë„¤ì´ë²„í˜ì´)\",\n",
      "        \"paymenttype_id\": \"ê²°ì œë°©ë²•id|ê²°ì œíƒ€ì…id|ê²°ì œì¢…ë¥˜id\",\n",
      "        \"phone\": \"íœ´ëŒ€í°ë²ˆí˜¸\",\n",
      "        \"project_id\": \"í”„ë¡œì íŠ¸id\",\n",
      "        \"receiver\": \"ë°›ëŠ”ì‚¬ëŒ|ìˆ˜ì·¨ì¸\",\n",
      "        \"reward_id\": \"ì¶”ê°€í›„ì› ì—…ë°ì´íŠ¸ í›„ ì‚¬ìš© ì•ˆí•¨\",\n",
      "        \"shipping_code\": \"íƒë°°ë²ˆí˜¸\",\n",
      "        \"shipping_corp\": \"íƒë°°ì‚¬\",\n",
      "        \"shipping_fee\": \"ë°°ì†¡ë¹„\",\n",
      "        \"shipping_modify_due_date\": \"ë°°ì†¡ì •ë³´ìˆ˜ì • ë§ˆê°ì¼ì. í›„ì›ìê°€ ë°°ì†¡ì •ë³´ë¥¼ ìˆ˜ì •í•  ìˆ˜ ìˆëŠ” ë§ˆê°ì¼\",\n",
      "        \"state\": \"í›„ì›ìƒíƒœ(0:í›„ì› ì¤‘,1:í›„ì› ì·¨ì†Œ,2:ê²°ì œ ì™„ë£Œ,3:ê²°ì œ ì¬ì‹œë„ ì¤‘,4:ê²°ì œ ëˆ„ë½,5:ê²°ì œ ëŒ€ê¸°,6:ê²°ì œ ì·¨ì†Œ,7:í™˜ë¶ˆ ìš”ì²­,8:í™˜ë¶ˆ ê±°ì ˆ,9:í™˜ë¶ˆ ì§„í–‰ ì¤‘,10:í™˜ë¶ˆ ì™„ë£Œ)\",\n",
      "        \"updated_at\": \"ìˆ˜ì •ì¼\",\n",
      "        \"uuid\": \"í›„ì›uuid\",\n",
      "        \"warrantier_id\": \"í›„ì›ìid|ì‚¬ìš©ìid\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"table_name\": \"withdraw_results\",\n",
      "      \"description\": \"ê²°ì œ ë‚´ì—­ í…Œì´ë¸”\",\n",
      "      \"query_tips\": \"\",\n",
      "      \"columns\": {\n",
      "        \"id\": \"ê²°ì œid\",\n",
      "        \"bank_name\": \"ì€í–‰ëª…\",\n",
      "        \"commission\": \"ê²°ì œìˆ˜ìˆ˜ë£Œ\",\n",
      "        \"created_at\": \"ìƒì„±ì¼\",\n",
      "        \"member_code\": \"ê²°ì œì½”ë“œ\",\n",
      "        \"money\": \"ê²°ì œê¸ˆì•¡\",\n",
      "        \"paymenttype\": \"ê²°ì œë°©ë²•|ê²°ì œíƒ€ì…|ê²°ì œì¢…ë¥˜(0:ì‹ ìš©ì¹´ë“œ,1:ê³„ì¢Œì´ì²´,2:ë„¤ì´ë²„í˜ì´)\",\n",
      "        \"paymenttype_id\": \"ê²°ì œë°©ë²•id|ê²°ì œíƒ€ì…id|ê²°ì œì¢…ë¥˜id\",\n",
      "        \"project_warranty_id\": \"í›„ì›id\",\n",
      "        \"service_type\": \"PGì‚¬ì¢…ë¥˜(0:Nice,1:CMS,2:Naverpay)\",\n",
      "        \"updated_at\": \"ìˆ˜ì •ì¼\",\n",
      "        \"withdraw_at\": \"ê²°ì œì™„ë£Œì¼ì‹œ\",\n",
      "        \"withdrawal_status\": \"ê²°ì œìƒíƒœ\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í…€ë¸”ë²… DB êµ¬ì¡°ëŠ” ì£¼ìš” í…Œì´ë¸”ë¡œ users, projects, project_descriptions, project_warranties, withdraw_resultsê°€ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. users (ì‚¬ìš©ì í…Œì´ë¸”)\n",
      "- id: ì‚¬ìš©ìid\n",
      "- login: ì´ë©”ì¼\n",
      "- fullname: ì´ë¦„\n",
      "- phone1, phone2, phone3: íœ´ëŒ€í°ë²ˆí˜¸\n",
      "- gender: ì„±ë³„\n",
      "- email_verified: ì´ë©”ì¼ ì¸ì¦ ì—¬ë¶€\n",
      "- address: ì£¼ì†Œ\n",
      "- created_at, updated_at: ìƒì„±ì¼, ìˆ˜ì •ì¼\n",
      "- admin: ì–´ë“œë¯¼ ì—¬ë¶€\n",
      "- is_creator: ì°½ì‘ì ì—¬ë¶€\n",
      "- is_star_creator: ìŠ¤íƒ€ ì°½ì‘ì ì—¬ë¶€\n",
      "- ê¸°íƒ€ ì•Œë¦¼ ìˆ˜ì‹  ì—¬ë¶€, ìƒíƒœ, ë‚˜ì´ ë²”ìœ„, í”„ë¡œí•„ ì´ë¯¸ì§€ ë“± ì‚¬ìš©ì ê´€ë ¨ ì •ë³´ ì»¬ëŸ¼ ë‹¤ìˆ˜\n",
      "\n",
      "2. projects (í”„ë¡œì íŠ¸ í…Œì´ë¸”)\n",
      "- id: í”„ë¡œì íŠ¸id\n",
      "- title: í”„ë¡œì íŠ¸ ì œëª©\n",
      "- permalink: í”„ë¡œì íŠ¸ ë§í¬\n",
      "- project_type: í”„ë¡œì íŠ¸ íƒ€ì… (í€ë”©, í”„ë¦¬ì˜¤ë” ë“±)\n",
      "- completemoney: ëª©í‘œì•¡\n",
      "- shipping_fee: ë°°ì†¡ë¹„\n",
      "- created_at, updated_at: ìƒì„±ì¼, ë³€ê²½ì¼\n",
      "- start_date, end_date: í”„ë¡œì íŠ¸ ì‹œì‘ì¼, ì¢…ë£Œì¼\n",
      "- creator_id: ì°½ì‘ìid\n",
      "- description, short_description: í”„ë¡œì íŠ¸ ì„¤ëª…\n",
      "- locname: ì§€ì—­\n",
      "- state: í”„ë¡œì íŠ¸ ìƒíƒœ (ì‘ì„±ì¤‘, ì‹¬ì‚¬ìš”ì²­, ìŠ¹ì¸, ë°˜ë ¤, ì·¨ì†Œ, ì‹¤íŒ¨, ì§„í–‰ì¤‘, ì„±ê³µ ë“±)\n",
      "- progress_status: ì§„í–‰ ìƒí™© (ëª¨ê¸ˆ ì„±ê³µ, ì§„í–‰ì¤‘, ë°°ì†¡ ì‹œì‘ ë“±)\n",
      "- current_money: í˜„ì¬ ëª¨ê¸ˆì•¡\n",
      "- cover_image_filename: ëŒ€í‘œ ì´ë¯¸ì§€\n",
      "- category_id: ì¹´í…Œê³ ë¦¬id\n",
      "- tags: íƒœê·¸\n",
      "- ê¸°íƒ€ í”„ë¡œì íŠ¸ ê´€ë ¨ ìƒì„¸ ì •ë³´ ì»¬ëŸ¼ ë‹¤ìˆ˜\n",
      "\n",
      "3. project_descriptions (í”„ë¡œì íŠ¸ ìƒì„¸ì„¤ëª… í…Œì´ë¸”)\n",
      "- id: ìƒì„¸ì„¤ëª…id\n",
      "- project_id: í”„ë¡œì íŠ¸id\n",
      "- purpose: í”„ë¡œì íŠ¸ ì†Œê°œ\n",
      "- rewards_description: ì„ ë¬¼ ì„¤ëª…\n",
      "- budget: ì˜ˆì‚°\n",
      "- schedule: ì¼ì •\n",
      "- introduction: íŒ€ì†Œê°œ\n",
      "- created_at, updated_at: ìƒì„±ì¼, ìˆ˜ì •ì¼\n",
      "\n",
      "4. project_warranties (í›„ì› ë‚´ì—­ í…Œì´ë¸”)\n",
      "- id: í›„ì›id\n",
      "- project_id: í”„ë¡œì íŠ¸id\n",
      "- warrantier_id: í›„ì›ìid\n",
      "- money: í›„ì›ê¸ˆ\n",
      "- state: í›„ì›ìƒíƒœ (í›„ì› ì¤‘, ì·¨ì†Œ, ê²°ì œ ì™„ë£Œ ë“±)\n",
      "- created_at, updated_at: ìƒì„±ì¼, ìˆ˜ì •ì¼\n",
      "- address, receiver, phone: ë°°ì†¡ ì£¼ì†Œ ë° ìˆ˜ì·¨ì¸ ì •ë³´\n",
      "- paymenttype: ê²°ì œë°©ë²•\n",
      "- cancelled_at, paid_at, delivered_at: í›„ì› ì·¨ì†Œ, ê²°ì œ ì™„ë£Œ, ë°°ì†¡ ì™„ë£Œ ì‹œê°\n",
      "- ê¸°íƒ€ í›„ì› ê´€ë ¨ ì •ë³´ ì»¬ëŸ¼ ë‹¤ìˆ˜\n",
      "\n",
      "5. withdraw_results (ê²°ì œ ë‚´ì—­ í…Œì´ë¸”)\n",
      "- id: ê²°ì œid\n",
      "- project_warranty_id: í›„ì›id\n",
      "- money: ê²°ì œê¸ˆì•¡\n",
      "- bank_name: ì€í–‰ëª…\n",
      "- commission: ê²°ì œìˆ˜ìˆ˜ë£Œ\n",
      "- paymenttype: ê²°ì œë°©ë²•\n",
      "- withdraw_at: ê²°ì œ ì™„ë£Œ ì‹œê°\n",
      "- withdrawal_status: ê²°ì œ ìƒíƒœ\n",
      "- created_at, updated_at: ìƒì„±ì¼, ìˆ˜ì •ì¼\n",
      "\n",
      "í•„ìš”í•œ í…Œì´ë¸”ì´ë‚˜ ì»¬ëŸ¼ì— ëŒ€í•´ ë” ìƒì„¸íˆ ì„¤ëª…í•´ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-mini\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"tbb-db-schema\": {\n",
    "            # ì„œë²„ì˜ í¬íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.(8005ë²ˆ í¬íŠ¸)\n",
    "            # \"url\": \"http://localhost:8005/sse\",\n",
    "            \"url\": \"http://localhost:8008/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    # answer = await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë– ë‹ˆ?\"})\n",
    "    answer = await astream_graph(agent, {\"messages\": \"í…€ë¸”ë²… ìŠ¤í‚¤ë§ˆ\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  + Exception Group Traceback (most recent call last):\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3665, in run_code\n",
      "  |     await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  |   File \"/var/folders/rc/w7m_bf7x39bfb8wclzs_8xsr0000gn/T/ipykernel_44989/1848944460.py\", line 10, in <module>\n",
      "  |     async with MultiServerMCPClient(\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 357, in __aenter__\n",
      "  |     await self.connect_to_server(server_name, **connection)\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 170, in connect_to_server\n",
      "  |     await self.connect_to_server_via_sse(\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/langchain_mcp_adapters/client.py\", line 276, in connect_to_server_via_sse\n",
      "  |     sse_transport = await self.exit_stack.enter_async_context(\n",
      "  |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 659, in enter_async_context\n",
      "  |     result = await _enter(cm)\n",
      "  |              ^^^^^^^^^^^^^^^^\n",
      "  |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "  |     return await anext(self.gen)\n",
      "  |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 43, in sse_client\n",
      "  |     async with anyio.create_task_group() as tg:\n",
      "  |                ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 772, in __aexit__\n",
      "  |     raise BaseExceptionGroup(\n",
      "  | ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)\n",
      "  +-+---------------- 1 ----------------\n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 101, in map_httpcore_exceptions\n",
      "    |     yield\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 394, in handle_async_request\n",
      "    |     resp = await self._pool.handle_async_request(req)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 256, in handle_async_request\n",
      "    |     raise exc from None\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection_pool.py\", line 236, in handle_async_request\n",
      "    |     response = await connection.handle_async_request(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 101, in handle_async_request\n",
      "    |     raise exc\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 78, in handle_async_request\n",
      "    |     stream = await self._connect(request)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_async/connection.py\", line 124, in _connect\n",
      "    |     stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "    |              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/auto.py\", line 31, in connect_tcp\n",
      "    |     return await self._backend.connect_tcp(\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_backends/anyio.py\", line 113, in connect_tcp\n",
      "    |     with map_exceptions(exc_map):\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py\", line 14, in map_exceptions\n",
      "    |     raise to_exc(exc) from exc\n",
      "    | httpcore.ConnectError: All connection attempts failed\n",
      "    | \n",
      "    | The above exception was the direct cause of the following exception:\n",
      "    | \n",
      "    | Traceback (most recent call last):\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/mcp/client/sse.py\", line 47, in sse_client\n",
      "    |     async with aconnect_sse(\n",
      "    |                ^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx_sse/_api.py\", line 69, in aconnect_sse\n",
      "    |     async with client.stream(method, url, headers=headers, **kwargs) as response:\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 210, in __aenter__\n",
      "    |     return await anext(self.gen)\n",
      "    |            ^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1583, in stream\n",
      "    |     response = await self.send(\n",
      "    |                ^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1629, in send\n",
      "    |     response = await self._send_handling_auth(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1657, in _send_handling_auth\n",
      "    |     response = await self._send_handling_redirects(\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1694, in _send_handling_redirects\n",
      "    |     response = await self._send_single_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 1730, in _send_single_request\n",
      "    |     response = await transport.handle_async_request(request)\n",
      "    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 393, in handle_async_request\n",
      "    |     with map_httpcore_exceptions():\n",
      "    |          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    |   File \"/opt/homebrew/Cellar/python@3.12/3.12.9/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py\", line 158, in __exit__\n",
      "    |     self.gen.throw(value)\n",
      "    |   File \"/Users/rock/Documents/dev-codes/python-projects/langgraph-mcp-agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py\", line 118, in map_httpcore_exceptions\n",
      "    |     raise mapped_exc(message) from exc\n",
      "    | httpx.ConnectError: All connection attempts failed\n",
      "    +------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            # ì„œë²„ì˜ í¬íŠ¸ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.(8005ë²ˆ í¬íŠ¸)\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())\n",
    "    agent = create_react_agent(model, client.get_tools())\n",
    "    answer = await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë‹¤ìŒì˜ ê²½ìš°ì—ëŠ” session ì´ ë‹«í˜”ê¸° ë•Œë¬¸ì— ë„êµ¬ì— ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "í˜„ì¬ ì €ëŠ” ì‹¤ì‹œê°„ ì¸í„°ë„· ì ‘ì†ì´ ë¶ˆê°€ëŠ¥í•˜ì—¬ ìµœì‹  ì„œìš¸ì˜ ë‚ ì”¨ ì •ë³´ë¥¼ ì§ì ‘ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ 6ì›”ì˜ ì„œìš¸ì€ ì´ˆì—¬ë¦„ ë‚ ì”¨ë¡œ, í‰ê·  ê¸°ì˜¨ì€ 20~28ë„ ì‚¬ì´ì´ë©°, ìŠµë„ê°€ ë†’ê³  ê°„í˜¹ ì†Œë‚˜ê¸°ê°€ ë‚´ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì •í™•í•œ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ë ¤ë©´ ë„¤ì´ë²„, ë‹¤ìŒ, ê¸°ìƒì²­, ë˜ëŠ” ìŠ¤ë§ˆíŠ¸í°ì˜ ë‚ ì”¨ ì•±ì„ ì°¸ê³ í•´ ì£¼ì„¸ìš”! í•„ìš”í•˜ë‹¤ë©´ ì„œìš¸ì˜ ê³„ì ˆë³„ ê¸°í›„ íŠ¹ì§•ì´ë‚˜ ì—¬í–‰ íŒë„ ì•Œë ¤ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_a1102cf978'}, id='run-40cb5132-6563-454d-83ec-cc4fb6567166'),\n",
       " 'metadata': {'langgraph_step': 1,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'checkpoint_ns': 'agent:b4bf4fc1-cd57-415d-f75a-adbb5b07bcb2',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ê·¸ëŸ¼ Async Session ì„ ìœ ì§€í•˜ë©° ë„êµ¬ì— ì ‘ê·¼í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_weather', description='\\n    Get current weather information for the specified location.\\n\\n    This function simulates a weather service by returning a fixed response.\\n    In a production environment, this would connect to a real weather API.\\n\\n    Args:\\n        location (str): The name of the location (city, region, etc.) to get weather for\\n\\n    Returns:\\n        str: A string containing the weather information for the specified location\\n    ', args_schema={'properties': {'location': {'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x10b898fe0>)]\n"
     ]
    }
   ],
   "source": [
    "# 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"weather\": {\n",
    "            \"url\": \"http://localhost:8005/sse\",\n",
    "            \"transport\": \"sse\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ì´ˆê¸°í™” (ì´ ë¶€ë¶„ì´ í•„ìš”í•¨)\n",
    "# ì´ˆê¸°í™”\n",
    "await client.__aenter__()\n",
    "\n",
    "# ì´ì œ ë„êµ¬ê°€ ë¡œë“œë¨\n",
    "print(client.get_tools())  # ë„êµ¬ê°€ í‘œì‹œë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_react_agent(model, client.get_tools())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "It's always Sunny in ì„œìš¸\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì„œìš¸ì˜ ë‚ ì”¨ëŠ” í•­ìƒ ë§‘ìŒì…ë‹ˆë‹¤! ì˜¤ëŠ˜ë„ í™”ì°½í•œ í•˜ë£¨ë¥¼ ë³´ë‚´ì‹¤ ìˆ˜ ìˆê² ë„¤ìš”."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node': 'agent',\n",
       " 'content': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_cf18407276'}, id='run-3f2f12d4-9aef-4379-9d53-3a83e3b18046'),\n",
       " 'metadata': {'langgraph_step': 3,\n",
       "  'langgraph_node': 'agent',\n",
       "  'langgraph_triggers': ('branch:to:agent',),\n",
       "  'langgraph_path': ('__pregel_pull', 'agent'),\n",
       "  'langgraph_checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'checkpoint_ns': 'agent:bfbec7ec-c929-5bdd-1650-5caa310cdd02',\n",
       "  'ls_provider': 'openai',\n",
       "  'ls_model_name': 'gpt-4.1',\n",
       "  'ls_model_type': 'chat',\n",
       "  'ls_temperature': 0.0,\n",
       "  'ls_max_tokens': 20000}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ í˜„ì¬ ì‹œê°„ì€?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stdio í†µì‹  ë°©ì‹\n",
    "\n",
    "Stdio í†µì‹  ë°©ì‹ì€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- í†µì‹ ì„ ìœ„í•´ í‘œì¤€ ì…ë ¥/ì¶œë ¥ ì‚¬ìš©\n",
    "\n",
    "ì°¸ê³ : ì•„ë˜ì˜ python ê²½ë¡œëŠ” ìˆ˜ì •í•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import ainvoke_graph, astream_graph\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# StdIO ì„œë²„ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "# - command: Python ì¸í„°í”„ë¦¬í„° ê²½ë¡œ\n",
    "# - args: ì‹¤í–‰í•  MCP ì„œë²„ ìŠ¤í¬ë¦½íŠ¸\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    # args=[\"mcp_server_local.py\"],\n",
    "    args=[\"./resources/mcp_rag_help_center/mcp_server.py\"],\n",
    ")\n",
    "\n",
    "# StdIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ì™€ í†µì‹ \n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # ì—°ê²° ì´ˆê¸°í™”\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP ë„êµ¬ ë¡œë“œ\n",
    "        tools = await load_mcp_tools(session)\n",
    "        print(tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„±\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        # await astream_graph(agent, {\"messages\": \"ì„œìš¸ì˜ ë‚ ì”¨ëŠ” ì–´ë– ë‹ˆ?\"})\n",
    "        await astream_graph(agent, {\"messages\": \"ì°½ì‘ìì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG ë¥¼ êµ¬ì¶•í•œ MCP ì„œë²„ ì‚¬ìš©\n",
    "\n",
    "- íŒŒì¼: `mcp_server_rag.py`\n",
    "\n",
    "ì‚¬ì „ì— langchain ìœ¼ë¡œ êµ¬ì¶•í•œ `mcp_server_rag.py` íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "stdio í†µì‹  ë°©ì‹ìœ¼ë¡œ ë„êµ¬ì— ëŒ€í•œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ì—¬ê¸°ì„œ ë„êµ¬ëŠ” `retriever` ë„êµ¬ë¥¼ ê°€ì ¸ì˜¤ê²Œ ë˜ë©°, ì´ ë„êµ¬ëŠ” `mcp_server_rag.py` ì—ì„œ ì •ì˜ëœ ë„êµ¬ì…ë‹ˆë‹¤. ì´ íŒŒì¼ì€ ì‚¬ì „ì— ì„œë²„ì—ì„œ ì‹¤í–‰ë˜ì§€ **ì•Šì•„ë„** ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36mtools\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "ì •ì±…ï½¥ë²•ì œ\n",
      "ê¸°ì—…ï½¥ì‚°ì—…\n",
      "ê¸°ìˆ ï½¥ì—°êµ¬\n",
      "ì¸ë ¥ï½¥êµìœ¡\n",
      "3\n",
      "íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜, AIì˜ ê³µê³µì„±Â·ì§€ì†ê°€ëŠ¥ì„±ê³¼ í•¨ê»˜ ê·œì œ ì™„í™” ë…¼ì˜\n",
      "n íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì˜ ì£¼ìš” ê²°ê³¼ë¬¼ë¡œ í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ìœ„í•œ ì„ ì–¸ë¬¸ì´ ë°œí‘œë˜ì—ˆìœ¼ë©°, \n",
      "ê³µìµì„ ìœ„í•œ AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AIâ€™ë„ ì¶œë²”\n",
      "n íŒŒë¦¬ AI ì •ìƒíšŒì˜ì—ì„œëŠ” AI ê·œì œ ì™„í™”ì™€ íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ ì˜ì œë¡œ ë– ì˜¬ëìœ¼ë©°, ë§ˆí¬ë¡± í”„ë‘ìŠ¤ \n",
      "ëŒ€í†µë ¹ì€ 1,090ì–µ ìœ ë¡œ ê·œëª¨ì˜ AI ì¸í”„ë¼ ë¯¼ê°„ íˆ¬ì í”„ë¡œì íŠ¸ë„ ë°œí‘œ\n",
      "KEY Contents\n",
      "Â£ ë¯¸êµ­ê³¼ ì˜êµ­ì„ ì œì™¸í•œ 60ê°œêµ­, í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸ ë°œí‘œ\n",
      "n í”„ë‘ìŠ¤ ì •ë¶€ê°€ 2025ë…„ 2ì›” 10~11ì¼, íŒŒë¦¬ì—ì„œ â€˜AI í–‰ë™ ì •ìƒíšŒì˜(AI Action Summit)â€™ë¥¼ ê°œìµœ\n",
      "âˆ™ì´ë²ˆ ì •ìƒíšŒì˜ì—ëŠ” ì „ ì„¸ê³„ 87ê°œ êµ­ê°€ì—ì„œ ê¸°ì—…, êµ­ì œê¸°êµ¬, ì‹œë¯¼ë‹¨ì²´ ë“± ì´ 1,000ì—¬ ëª…ì´ ì°¸ì—¬í•´ AI ê¸€ë¡œë²Œ \n",
      "ê±°ë²„ë„ŒìŠ¤ë¥¼ ì‹¬ë„ ìˆê²Œ ë…¼ì˜\n",
      "n ì •ìƒíšŒì˜ ì£¼ìš” ê²°ê³¼ë¬¼ë¡œ í•œêµ­ì„ í¬í•¨í•œ 60ê°œêµ­ì´ ê³µë™ ì°¸ì—¬í•œ â€˜ì¸ë¥˜ì™€ ì§€êµ¬ë¥¼ ìœ„í•œ í¬ìš©ì ì´ê³  \n",
      "ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸â€™ì´ ë°œí‘œë˜ì—ˆê³  ë¯¸êµ­ê³¼ ì˜êµ­ì€ ì„ ì–¸ì— ë¶ˆì°¸    \n",
      "âˆ™ì„ ì–¸ë¬¸ì€ ê³µìµì„ ìœ„í•œ AI ë° ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ëª©í‘œë¡œ ì œì‹œí•˜ê³ , ì´ë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ êµ¬ì²´ì  í–‰ë™ìœ¼ë¡œ \n",
      "â‘ ê³µìµì„ ìœ„í•œ AI í”Œë«í¼ ë° ì¸íë² ì´í„° ì¶œë²” â‘¡í™˜ê²½ì  ì§€ì†ê°€ëŠ¥ì„±ì„ ìœ„í•œ AI ì—ë„ˆì§€ ê´€ì¸¡ì†Œ ì„¤ë¦½ \n",
      "â‘¢ì¼ìë¦¬ì— ëŒ€í•œ AI ì˜í–¥ ê´€ì¸¡ ë„¤íŠ¸ì›Œí¬ë¥¼ ì œì‹œ\n",
      "n ì´ë²ˆ ì •ìƒíšŒì˜ì—ì„œëŠ” 9ê°œêµ­*ê³¼ êµ¬ê¸€, ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“±ì˜ ê¸°ì—…ì´ 4ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•´ ê³µìµì„ ìœ„í•œ \n",
      "AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AI(Current AI)â€™ë„ ì¶œë²”\n",
      "* ë‚˜ì´ì§€ë¦¬ì•„, ë…ì¼, ëª¨ë¡œì½”, ìŠ¤ìœ„ìŠ¤, ìŠ¬ë¡œë² ë‹ˆì•„, ì¹ ë ˆ, ì¼€ëƒ, í”„ë‘ìŠ¤, í•€ë€ë“œ  \n",
      "âˆ™ì´ í”„ë¡œì íŠ¸ëŠ” ê³µìµ AI í™˜ê²½ ì¡°ì„±ì„ ëª©í‘œë¡œ â–³AI í›ˆë ¨ì„ ìœ„í•œ ê³ í’ˆì§ˆ ê³µê³µ ë°ì´í„° ì ‘ê·¼ì„± í™•ëŒ€ \n",
      "â–³ì˜¤í”ˆì†ŒìŠ¤ ì¸í”„ë¼ ì§€ì› â–³AIì˜ ì‚¬íšŒì Â·í™˜ê²½ì  ì˜í–¥ì„ ì¸¡ì •í•˜ê¸° ìœ„í•œ ì‹œìŠ¤í…œ ê°œë°œ ì§€ì›ì„ ì¶”ì§„\n",
      "Â£ íŒŒë¦¬ AI ì •ìƒíšŒì˜, AI ê·œì œ ì™„í™” ë° AI íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ í™”ë‘ë¡œ ë¶€ìƒ\n",
      "SPRi AI Brief\n",
      "2025ë…„ 3ì›”í˜¸\n",
      "4\n",
      "EU ì§‘í–‰ìœ„ì›íšŒ, ê²½ìŸë ¥ ê°•í™” ë¡œë“œë§µì˜ ì¼í™˜ìœ¼ë¡œ AI ê¸°ê°€íŒ©í† ë¦¬ êµ¬ì¶• ì¶”ì§„\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒê°€ 5ê°œë…„ ì •ì±… ë¡œë“œë§µ â€˜ê²½ìŸë ¥ ë‚˜ì¹¨ë°˜â€™ì— ë”°ë¼ í˜ì‹  ê²©ì°¨ í•´ì†Œë¥¼ ìœ„í•œ AI ì •ì±…ìœ¼ë¡œ \n",
      "â€˜AI ê¸°ê°€íŒ©í† ë¦¬â€™ì™€ â€˜AI ì ìš©â€™ ì „ëµì„ ì œì‹œ\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒëŠ” íŒŒë¦¬ AI ì •ìƒíšŒì˜ì—ì„œ ì´ 2ì²œì–µ ìœ ë¡œ ê·œëª¨ì˜ â€˜ì¸ë² ìŠ¤íŠ¸AIâ€™ ê³„íšì˜ ì¼í™˜ìœ¼ë¡œ \n",
      "200ì–µ ìœ ë¡œë¥¼ íˆ¬ì…í•´ 4ê°œì˜ AI ê¸°ê°€íŒ©í† ë¦¬ë¥¼ ê±´ì„¤í•˜ê² ë‹¤ê³  ë°œí‘œ  \n",
      "KEY Contents\n",
      "Â£ EU ì§‘í–‰ìœ„ì›íšŒ, 5ê°œë…„ ì •ì±… ë¡œë“œë§µ í•˜ì—ì„œ AI ê¸°ê°€íŒ©í† ë¦¬ì™€ AI ì ìš© ì „ëµ ì¶”ì§„ \n",
      "n ìš°ë¥´ì¤„ë¼ í° ë°ì–´ ë¼ì´ì—”(Ursula von der Leyen) EU ì§‘í–‰ìœ„ì›ì¥ì´ 2025ë…„ 1ì›” 29ì¼ 2ê¸° EU \n",
      "ì§‘í–‰ë¶€(2024ë…„ 12ì›” ì¶œë²”)ì˜ 5ê°œë…„ ì •ì±… ë¡œë“œë§µ â€˜ê²½ìŸë ¥ ë‚˜ì¹¨ë°˜(Competitive Compass)â€™ì„ ë°œí‘œ\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒëŠ” ê²½ìŸë ¥ ì œê³ ë¥¼ ìœ„í•´ â–³í˜ì‹  ê²©ì°¨ í•´ì†Œ â–³è„«íƒ„ì†Œí™” â–³ê³µê¸‰ë§ ì•ˆë³´ì˜ 3ê°œ ì˜ì—­ì„ ì¤‘ì  \n",
      "ê³¼ì œë¡œ ì œì‹œí–ˆìœ¼ë©°, ì´ì¤‘ í˜ì‹  ê²©ì°¨ í•´ì†Œì™€ ê´€ë ¨í•´ AI ì •ì±…ì„ í¬í•¨\n",
      "n EU ì§‘í–‰ìœ„ì›íšŒëŠ” í•µì‹¬ ë¶„ì•¼ì˜ AI ê°œë°œê³¼ ì‚°ì—…ê³„ AI ë„ì… í™œì„±í™”ë¥¼ ìœ„í•œ â€˜AI ê¸°ê°€íŒ©í† ë¦¬(AI Gigafactory)â€™ì™€ \n",
      "â€˜AI ì ìš©(Apply AI)â€™ ì „ëµì„ ì œì•ˆ\n",
      "âˆ™AI ê¸°ê°€íŒ©í† ë¦¬ëŠ” ì…ë²• ì¶”ì§„ ì˜ˆì •ì¸ â€˜EU í´ë¼ìš°ë“œ ë° AI ê°œë°œë²•(EU Cloud and AI Development \n",
      "Act)â€™*ì„ í†µí•´ ê³µê³µê³¼ ë¯¼ê°„ ìê¸ˆì„ í™œìš©í•˜ì—¬ ì´ˆê±°ëŒ€ AI ëª¨ë¸ í›ˆë ¨ì— íŠ¹í™”ëœ ëŒ€ê·œëª¨ ë°ì´í„°ì„¼í„°ë¥¼ \n",
      "êµ¬ì¶•í•¨ìœ¼ë¡œì¨ EU ì „ì—­ì˜ AI ìƒíƒœê³„ë¥¼ í™œì„±í™”í•œë‹¤ëŠ” ê³„íš\n",
      "* ê³ ì„±ëŠ¥ ì—°ì‚° ìì›ê³¼ ë””ì§€í„¸ ì¸í”„ë¼ì— ëŒ€í•œ ê°•ë ¥í•œ ê·œì œ í”„ë ˆì„ì›Œí¬ë¥¼ í†µí•´ í´ë¼ìš°ë“œì™€ AI ë¶„ì•¼ì—ì„œ ìœ ëŸ½ì˜ ë¦¬ë”ì‹­ ê°•í™”ë¥¼ ìœ„í•œ ë²•ì•ˆ\n",
      "âˆ™AI ì ìš© ì „ëµì€ ì œì¡°ì—…, ì—ë„ˆì§€, ìë™ì°¨, ë¡œë´‡ê³µí•™, ì œì•½, í•­ê³µ, ê¸ˆìœµ ì„œë¹„ìŠ¤ ì‚°ì—…ì˜ AI ì ìš©ì„ ì´‰ì§„í•˜ê³  \n",
      "ë³´ê±´ê³¼ ì‚¬ë²• ë“±ì˜ ê³µê³µì„œë¹„ìŠ¤ ê°œì„ ì„ ì¶”ì§„\n",
      "CONTENTS\n",
      "ì •ì±…ï½¥ë²•ì œ\n",
      "âˆ™ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ëŒ€ìƒ AI ì •ì±… ë³´ê³ ì„œ ë°œê°„\n",
      "2\n",
      "âˆ™íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜, AIì˜ ê³µê³µì„±Â·ì§€ì†ê°€ëŠ¥ì„±ê³¼ í•¨ê»˜ ê·œì œ ì™„í™” ë…¼ì˜\n",
      "3\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒ, ê²½ìŸë ¥ ê°•í™” ë¡œë“œë§µì˜ ì¼í™˜ìœ¼ë¡œ AI ê¸°ê°€íŒ©í† ë¦¬ êµ¬ì¶• ì¶”ì§„\n",
      "4\n",
      "âˆ™EU ì§‘í–‰ìœ„ì›íšŒ, 2025ë…„ ì—…ë¬´ í”„ë¡œê·¸ë¨ì—ì„œ â€˜AI ì±…ì„ ì§€ì¹¨â€™ ì² íšŒ ê³„íš ë°œí‘œ\n",
      "5\n",
      "âˆ™ì˜êµ­, AIì•ˆì „ì—°êµ¬ì†Œì˜ ëª…ì¹­ AIë³´ì•ˆì—°êµ¬ì†Œë¡œ ë³€ê²½í•˜ê³  ì•¤ìŠ¤ë¡œí”½ê³¼ AI í˜‘ë ¥ ë°œí‘œ\n",
      "6\n",
      "ê¸°ì—…ï½¥ì‚°ì—…\n",
      "âˆ™êµ¬ê¸€, ì„±ëŠ¥ ê°œì„ í•œ â€˜ì œë¯¸ë‚˜ì´ 2.0â€™ ì œí’ˆêµ° í™•ëŒ€ ì¶œì‹œ\n",
      "8\n",
      "âˆ™ ì˜¤í”ˆAI, ì‹¬ì¸µ ì¡°ì‚¬ë¥¼ ìˆ˜í–‰í•˜ëŠ” ì—ì´ì „íŠ¸ â€˜ë”¥ ë¦¬ì„œì¹˜â€™ ê³µê°œ\n",
      "9\n",
      "âˆ™ì˜¤í”ˆAI, GPT-5 ì¶œì‹œ ë¡œë“œë§µ ë°œí‘œ ë° GPT-4.5 í”„ë¦¬ë·° ê³µê°œ\n",
      "10\n",
      "âˆ™xAI, ìµœì‹  AI ëª¨ë¸ â€˜ê·¸ë¡ 3â€™ í”„ë¦¬ë·° ì¶œì‹œ\n",
      "11\n",
      "âˆ™í¼í”Œë ‰ì‹œí‹°, ì‹¬ì¸µ ì¡°ì‚¬ì™€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ëŠ” â€˜ë”¥ ë¦¬ì„œì¹˜â€™ ë¬´ë£Œ ì¶œì‹œ\n",
      "12\n",
      "âˆ™ì•Œë¦¬ë°”ë°”, ë”¥ì‹œí¬ V3 ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥ì˜ â€˜íì›2.5-Maxâ€™ ì¶œì‹œ\n",
      "13\n",
      "âˆ™ì•„í¬ ì¸ë² ìŠ¤íŠ¸, 2025ë…„ í˜ì‹  ê¸°ìˆ  ì¤‘ í•˜ë‚˜ë¡œ AI ì—ì´ì „íŠ¸ ì„ ì •\n",
      "14\n",
      "ê¸°ìˆ ï½¥ì—°êµ¬\n",
      "âˆ™ìƒí•˜ì´êµí†µâ¼¤ ì—°êµ¬ì§„, ì†ŒëŸ‰ì˜ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•œ ì¶”ë¡  AI ëª¨ë¸ ê°œë°œ\n",
      "16\n",
      "âˆ™ìŠ¤íƒ í¬ë“œâ¼¤ì™€ ì›Œì‹±í„´â¼¤ ì—°êµ¬ì§„, ì €ë¹„ìš©ìœ¼ë¡œ ê³ ì„±ëŠ¥ ì¶”ë¡  AI ëª¨ë¸ ê°œë°œ\n",
      "17\n",
      "âˆ™ë°”ì´íŠ¸ëŒ„ìŠ¤, ì¸ë¬¼ ì›€ì§ì„ì„ ìƒì„±í•˜ëŠ” AI ëª¨ë¸ â€˜ì˜´ë‹ˆíœ´ë¨¼-1â€™ ê°œë°œ\n",
      "18\n",
      "âˆ™AIì•ˆì „ì„¼í„°ì™€ ìŠ¤ì¼€ì¼ AI, ê³ ë‚œë„ ë²¤ì¹˜ë§ˆí¬ â€˜HLEâ€™ ê³µê°œ\n",
      "19\n",
      "ì¸ë ¥ï½¥êµìœ¡ \n",
      "âˆ™ë”œë¡œì´íŠ¸ ì¡°ì‚¬ ê²°ê³¼, ì „ ì„¸ê³„ ê¸°ì—…ë“¤ì€ ì ì§„ì ìœ¼ë¡œ AI ë„ì… í™•ëŒ€\n",
      "21\n",
      "âˆ™ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì—°êµ¬ ê²°ê³¼, ìƒì„± AI ì‹ ë¢°í• ìˆ˜ë¡ ë¹„íŒì  ì‚¬ê³  ê°ì†Œ\n",
      "22\n",
      "âˆ™ì•¤ìŠ¤ë¡œí”½, AIê°€ ë…¸ë™ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•œ â€˜ì•¤ìŠ¤ë¡œí”½ ê²½ì œ ì§€ìˆ˜â€™ ê³µê°œ \n",
      "23\n",
      "âˆ™ì•¤ìŠ¤ë¡œí”½ì„ ë¹„ë¡¯í•œ ì—¬ëŸ¬ ê¸°ì—…ë“¤, ì…ì‚¬ ì§€ì› ì‹œ AI ë„êµ¬ ì‚¬ìš©ê¸ˆì§€ ìš”êµ¬\n",
      "24\n",
      "ì£¼ìš”í–‰ì‚¬ì¼ì •\n",
      "25\n",
      "| 2025ë…„ 3ì›”í˜¸ |\n",
      "SPRi AI Brief\n",
      "2025ë…„ 3ì›”í˜¸\n",
      "2\n",
      "ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ ëŒ€ìƒ AI ì •ì±… ë³´ê³ ì„œ ë°œê°„\n",
      "n AI ì •ì±…ì— ê´€í•˜ì—¬ ëŒ€í†µë ¹ê³¼ ì—°ë°© ì •ë¶€ì— ìë¬¸ì„ ì œê³µí•˜ëŠ” ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ(NAIAC)ê°€ \n",
      "íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ê°€ ìš°ì„ ì ìœ¼ë¡œ ì¶”ì§„í•´ì•¼ í•  AI ì •ì±…ì„ ì •ë¦¬í•œ ë³´ê³ ì„œë¥¼ ë°œí‘œ\n",
      "n ë³´ê³ ì„œëŠ” ì •ì±… ìš°ì„ ìˆœìœ„ë¡œ â–³ë…¸ë™ë ¥ â–³AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ â–³êµìœ¡ â–³ê³¼í•™ â–³ë³´ê±´ â–³ì •ë¶€ \n",
      "â–³ì¤‘ì†Œê¸°ì—… ì§€ì› â–³AI ê±°ë²„ë„ŒìŠ¤ â–³ë¯¸êµ­ ì‹œë¯¼ â–³ë²• ì§‘í–‰ì„ ì œì‹œ\n",
      "KEY Contents\n",
      "Â£ ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒ, ë¯¸êµ­ì˜ AI ì£¼ë„ê¶Œ ìœ ì§€ë¥¼ ìœ„í•œ 10ëŒ€ ì •ì±… ìš°ì„ ìˆœìœ„ ì œì‹œ\n",
      "n ë¯¸êµ­ êµ­ê°€AIìë¬¸ìœ„ì›íšŒëŠ” 2025ë…„ 1ì›” 28ì¼ ë¯¸êµ­ì˜ ê¸°ìˆ  ì£¼ë„ê¶Œ ìœ ì§€ë¥¼ ìœ„í•´ íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ê°€ ì¶”ì§„\n",
      "í•´ì•¼ í•  AI ì¤‘ì  ë¶„ì•¼ë¥¼ ì œì‹œí•œ ë³´ê³ ì„œë¥¼ ë°œí‘œí•˜ê³ , ì •ì±… ìš°ì„ ìˆœìœ„ë¡œ â–³ë…¸ë™ë ¥ â–³AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ \n",
      "â–³êµìœ¡ â–³ê³¼í•™ â–³ë³´ê±´ â–³ì •ë¶€ â–³ì¤‘ì†Œê¸°ì—… ì§€ì› â–³AI ê±°ë²„ë„ŒìŠ¤ â–³ë¯¸êµ­ ì‹œë¯¼ â–³ë²• ì§‘í–‰ì„ ì„ ì •\n",
      "âˆ™(ë…¸ë™ë ¥) AIê°€ ë…¸ë™ì‹œì¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€ì‘í•´ ì—°ë°© ì •ë¶€ì™€ ì£¼Â·ì§€ë°© ì •ë¶€ ê°„ í˜‘ë ¥ì„ ê°•í™”í•˜ê³  AIë¥¼ ë¹„ë¡¯í•œ \n",
      "ê¸°ìˆ  ê°œë°œ ì§€ì› ë“± AIë¡œ ì‹¤ì§ ìœ„í—˜ì— ì²˜í•œ ê·¼ë¡œì ì§€ì› ì „ëµì„ ë§ˆë ¨\n",
      "âˆ™(AI ì¸ì‹ê³¼ ë¦¬í„°ëŸ¬ì‹œ) AIì˜ ê´‘ë²”ìœ„í•œ ë„ì…ì„ ìœ„í•´ ì „êµ­ ê·œëª¨ì˜ AI ì¸ì‹ ì œê³  ìº í˜ì¸ì„ ì‹œí–‰í•˜ê³  AI ê¸°ì´ˆ \n",
      "êµìœ¡, ì „ë¬¸ê³¼ì •, AI ìê²©ì¦ ê³¼ì •ê³¼ ê°™ì€ êµìœ¡ í”„ë¡œê·¸ë¨ì„ ê°•í™”\n",
      "âˆ™(êµìœ¡) êµìœ¡ í™˜ê²½ì— íŠ¹í™”ëœ AI ìœ„í—˜ê´€ë¦¬ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œí•˜ê³  AI êµìœ¡ ê³¼ì •ê³¼ AI ë„êµ¬ ê°œë°œ í•´ì»¤í†¤ì„ ê°œìµœ\n",
      "âˆ™(ê³¼í•™) ì¤‘ìš”í•œ ì‚¬íšŒ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ AI ì ìš©ì„ í™•ëŒ€í•˜ê³ , ê³¼í•™ ë¶„ì•¼ì˜ AI ì—°êµ¬ì— ëŒ€í•œ ìê¸ˆ ìš°ì„ ìˆœìœ„ë¥¼ \n",
      "ì„¤ì •í•˜ë©° ì§€ì›ì„ ê°•í™”í•˜ëŠ” ì „ëµì„ ì¶”ì§„\n",
      "âˆ™(ë³´ê±´) ë°±ì•…ê´€ ê³¼í•™ê¸°ìˆ ìœ„ì›íšŒ(NSTC) ì‚°í•˜ AIíŠ¹ë³„ìœ„ì›íšŒ ë‚´ì— ê°œì¸ ê±´ê°•ì •ë³´ì˜ ì•ˆì „í•˜ê³  ì±…ì„ ìˆëŠ” \n",
      "ì‚¬ìš©ì„ ë‹´ë‹¹í•  ì†Œìœ„ì›íšŒë¥¼ ì‹ ì„¤ \n",
      "âˆ™(ì •ë¶€) AIë¡œ ì •ë¶€ì˜ ìš´ì˜ íš¨ìœ¨ì„±ì„ í–¥ìƒí•˜ê¸° ìœ„í•´ êµ­ê°€AIì´ë‹ˆì…”í‹°ë¸Œ ì‚¬ë¬´êµ­ì— ì¸ë ¥ê³¼ ìì›ì„ ì¶©ì›í•˜ê³  AI \n",
      "ëª¨ë¸ í‰ê°€ í”„ë ˆì„ì›Œí¬ë¥¼ êµ¬ì¶•\n",
      "==================================================\n",
      "ğŸ”„ Node: \u001b[1;36magent\u001b[0m ğŸ”„\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜(AI Action Summit)ëŠ” 2025ë…„ 2ì›” 10~11ì¼ í”„ë‘ìŠ¤ íŒŒë¦¬ì—ì„œ ê°œìµœëœ ê¸€ë¡œë²Œ AI ì •ìƒíšŒì˜ì…ë‹ˆë‹¤. ì´ íšŒì˜ì—ëŠ” ì „ ì„¸ê³„ 87ê°œêµ­ì—ì„œ ì •ë¶€, ê¸°ì—…, êµ­ì œê¸°êµ¬, ì‹œë¯¼ë‹¨ì²´ ë“± ì•½ 1,000ì—¬ ëª…ì´ ì°¸ì—¬í•´ AIì˜ ê¸€ë¡œë²Œ ê±°ë²„ë„ŒìŠ¤, ê³µê³µì„±, ì§€ì†ê°€ëŠ¥ì„±, ê·œì œ ì™„í™”, íˆ¬ì í™•ëŒ€ ë“±ì„ ë…¼ì˜í–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì£¼ìš” ë‚´ìš©ê³¼ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AI ì„ ì–¸ë¬¸ ë°œí‘œ**\n",
      "   - í•œêµ­ì„ í¬í•¨í•œ 60ê°œêµ­ì´ â€˜ì¸ë¥˜ì™€ ì§€êµ¬ë¥¼ ìœ„í•œ í¬ìš©ì ì´ê³  ì§€ì†ê°€ëŠ¥í•œ AIì— ëŒ€í•œ ì„ ì–¸ë¬¸â€™ì„ ê³µë™ ë°œí‘œí–ˆìŠµë‹ˆë‹¤(ë¯¸êµ­, ì˜êµ­ì€ ë¶ˆì°¸).\n",
      "   - ì„ ì–¸ë¬¸ì€ ê³µìµì„ ìœ„í•œ AI, ì§€ì†ê°€ëŠ¥í•œ AIë¥¼ ëª©í‘œë¡œ í•˜ë©°, êµ¬ì²´ì  í–‰ë™ìœ¼ë¡œ\n",
      "     1) ê³µìµì„ ìœ„í•œ AI í”Œë«í¼ ë° ì¸íë² ì´í„° ì¶œë²”,\n",
      "     2) í™˜ê²½ì  ì§€ì†ê°€ëŠ¥ì„±ì„ ìœ„í•œ AI ì—ë„ˆì§€ ê´€ì¸¡ì†Œ ì„¤ë¦½,\n",
      "     3) ì¼ìë¦¬ì— ëŒ€í•œ AI ì˜í–¥ ê´€ì¸¡ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶• ë“±ì„ ì œì‹œí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2. **ê³µìµ AI í”„ë¡œì íŠ¸ â€˜ì»¤ëŸ°íŠ¸ AI(Current AI)â€™ ì¶œë²”**\n",
      "   - 9ê°œêµ­(í”„ë‘ìŠ¤, ë…ì¼, í•€ë€ë“œ, ìŠ¤ìœ„ìŠ¤, ìŠ¬ë¡œë² ë‹ˆì•„, ì¼€ëƒ, ë‚˜ì´ì§€ë¦¬ì•„, ëª¨ë¡œì½”, ì¹ ë ˆ)ê³¼ êµ¬ê¸€, ì„¸ì¼ì¦ˆí¬ìŠ¤ ë“± ê¸€ë¡œë²Œ ê¸°ì—…ì´ 4ì–µ ë‹¬ëŸ¬ë¥¼ íˆ¬ìí•´ ê³µìµ AI í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.\n",
      "   - ì´ í”„ë¡œì íŠ¸ëŠ” ê³ í’ˆì§ˆ ê³µê³µ ë°ì´í„° ì ‘ê·¼ì„± í™•ëŒ€, ì˜¤í”ˆì†ŒìŠ¤ ì¸í”„ë¼ ì§€ì›, AIì˜ ì‚¬íšŒì Â·í™˜ê²½ì  ì˜í–¥ ì¸¡ì • ì‹œìŠ¤í…œ ê°œë°œ ë“±ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3. **AI ê·œì œ ì™„í™” ë° íˆ¬ì í™•ëŒ€ ë…¼ì˜**\n",
      "   - ë§ˆí¬ë¡± í”„ë‘ìŠ¤ ëŒ€í†µë ¹ì€ 1,090ì–µ ìœ ë¡œ ê·œëª¨ì˜ AI ì¸í”„ë¼ ë¯¼ê°„ íˆ¬ì í”„ë¡œì íŠ¸ë¥¼ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n",
      "   - AI ê·œì œ ì™„í™”ì™€ íˆ¬ì í™•ëŒ€ê°€ í•µì‹¬ ì˜ì œë¡œ ë¶€ìƒí–ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4. **EUì˜ AI ì •ì±… ë°œí‘œ**\n",
      "   - EU ì§‘í–‰ìœ„ì›íšŒëŠ” 2,000ì–µ ìœ ë¡œ ê·œëª¨ì˜ â€˜ì¸ë² ìŠ¤íŠ¸AIâ€™ ê³„íšì˜ ì¼í™˜ìœ¼ë¡œ 200ì–µ ìœ ë¡œë¥¼ íˆ¬ì…í•´ 4ê°œì˜ AI ê¸°ê°€íŒ©í† ë¦¬(ëŒ€ê·œëª¨ AI ë°ì´í„°ì„¼í„°)ë¥¼ ê±´ì„¤í•˜ê² ë‹¤ê³  ë°œí‘œí–ˆìŠµë‹ˆë‹¤.\n",
      "   - AI ì ìš© ì „ëµì„ í†µí•´ ì œì¡°ì—…, ì—ë„ˆì§€, ìë™ì°¨, ë¡œë´‡ê³µí•™, ì œì•½, í•­ê³µ, ê¸ˆìœµ ì„œë¹„ìŠ¤ ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì— AI ë„ì…ì„ ì´‰ì§„í•  ê³„íšì…ë‹ˆë‹¤.\n",
      "\n",
      "**ìš”ì•½**: íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ëŠ” AIì˜ ê³µê³µì„±, ì§€ì†ê°€ëŠ¥ì„±, ê·œì œ ì™„í™”, íˆ¬ì í™•ëŒ€ë¥¼ ë…¼ì˜í•˜ëŠ” ê¸€ë¡œë²Œ í˜‘ë ¥ì˜ ì¥ìœ¼ë¡œ, í¬ìš©ì  AI ì„ ì–¸ë¬¸ê³¼ ê³µìµ AI í”„ë¡œì íŠ¸ ì¶œë²” ë“± ì‹¤ì§ˆì  ê²°ê³¼ë¥¼ ë„ì¶œí•œ ê²ƒì´ íŠ¹ì§•ì…ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_mcp_adapters.tools import load_mcp_tools\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import astream_graph\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# RAG ì„œë²„ë¥¼ ìœ„í•œ StdIO ì„œë²„ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "server_params = StdioServerParameters(\n",
    "    command=\"./.venv/bin/python\",\n",
    "    args=[\"./mcp_server_rag.py\"],\n",
    ")\n",
    "\n",
    "# StdIO í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ RAG ì„œë²„ì™€ í†µì‹ \n",
    "async with stdio_client(server_params) as (read, write):\n",
    "    # í´ë¼ì´ì–¸íŠ¸ ì„¸ì…˜ ìƒì„±\n",
    "    async with ClientSession(read, write) as session:\n",
    "        # ì—°ê²° ì´ˆê¸°í™”\n",
    "        await session.initialize()\n",
    "\n",
    "        # MCP ë„êµ¬ ë¡œë“œ (ì—¬ê¸°ì„œëŠ” retriever ë„êµ¬)\n",
    "        tools = await load_mcp_tools(session)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ìƒì„± ë° ì‹¤í–‰\n",
    "        agent = create_react_agent(model, tools)\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°\n",
    "        await astream_graph(\n",
    "            agent, {\"messages\": \"íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSE ë°©ì‹ê³¼ StdIO ë°©ì‹ í˜¼í•© ì‚¬ìš©\n",
    "\n",
    "- íŒŒì¼: `mcp_server_rag.py` ëŠ” StdIO ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "- `langchain-dev-docs` ëŠ” SSE ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "\n",
    "SSE ë°©ì‹ê³¼ StdIO ë°©ì‹ì„ í˜¼í•©í•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1\", temperature=0, max_tokens=20000\n",
    ")\n",
    "\n",
    "# 1. ë‹¤ì¤‘ ì„œë²„ MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹  (í‘œì¤€ ì…ì¶œë ¥ ì‚¬ìš©)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"langchain-dev-docs\": {\n",
    "            # SSE ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”\n",
    "            \"url\": \"https://teddynote.io/mcp/langchain/sse\",\n",
    "            # SSE(Server-Sent Events) ë°©ì‹ìœ¼ë¡œ í†µì‹ \n",
    "            \"transport\": \"sse\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¥¼ í†µí•œ ëª…ì‹œì  ì—°ê²° ì´ˆê¸°í™”\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "prompt = (\n",
    "    \"You are a smart agent. \"\n",
    "    \"Use `retriever` tool to search on AI related documents and answer questions.\"\n",
    "    \"Use `langchain-dev-docs` tool to search on langchain / langgraph related documents and answer questions.\"\n",
    "    \"Answer in Korean.\"\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    model, client.get_tools(), prompt=prompt, checkpointer=MemorySaver()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "êµ¬ì¶•í•´ ë†“ì€ `mcp_server_rag.py` ì—ì„œ ì •ì˜í•œ `retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ íŒŒë¦¬ AI í–‰ë™ ì •ìƒíšŒì˜ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” `langchain-dev-docs` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RunnableConfig(recursion_limit=30, thread_id=1)\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    {\"messages\": \"langgraph-dev-docs ì°¸ê³ í•´ì„œ self-rag ì˜ ì •ì˜ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\"},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MemorySaver` ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ê¸° ê¸°ì–µì„ ìœ ì§€í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, multi-turn ëŒ€í™”ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent, {\"messages\": \"ì´ì „ì˜ ë‚´ìš©ì„ bullet point ë¡œ ìš”ì•½í•´ì¤˜\"}, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain ì— í†µí•©ëœ ë„êµ¬ + MCP ë„êµ¬\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” LangChain ì— í†µí•©ëœ ë„êµ¬ë¥¼ ê¸°ì¡´ì˜ MCP ë¡œë§Œ ì´ë£¨ì–´ì§„ ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©ì´ ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tavily ê²€ìƒ‰ ë„êµ¬ë¥¼ ì´ˆê¸°í™” í•©ë‹ˆë‹¤. (news íƒ€ì…, ìµœê·¼ 3ì¼ ë‚´ ë‰´ìŠ¤)\n",
    "tavily = TavilySearchResults(max_results=3, topic=\"news\", days=3)\n",
    "\n",
    "# ê¸°ì¡´ì˜ MCP ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "tools = client.get_tools() + [tavily]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# ì¬ê·€ ì œí•œ ë° ìŠ¤ë ˆë“œ ì•„ì´ë”” ì„¤ì •\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=2)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "prompt = \"You are a smart agent with various tools. Answer questions in Korean.\"\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ìƒì„±\n",
    "agent = create_react_agent(model, tools, prompt=prompt, checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìƒˆë¡­ê²Œ ì¶”ê°€í•œ `tavily` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(agent, {\"messages\": \"ì˜¤ëŠ˜ ë‰´ìŠ¤ ì°¾ì•„ì¤˜\"}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`retriever` ë„êµ¬ê°€ ì›í™œí•˜ê²Œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ì´ë¦„ì„ ê²€ìƒ‰í•´ì¤˜\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smithery ì—ì„œ ì œê³µí•˜ëŠ” MCP ì„œë²„\n",
    "\n",
    "- ë§í¬: https://smithery.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‚¬ìš©í•œ ë„êµ¬ ëª©ë¡ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "- Sequential Thinking: https://smithery.ai/server/@smithery-ai/server-sequential-thinking\n",
    "  - êµ¬ì¡°í™”ëœ ì‚¬ê³  í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•´ ì—­ë™ì ì´ê³  ì„±ì°°ì ì¸ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” MCP ì„œë²„\n",
    "- Desktop Commander: https://smithery.ai/server/@wonderwhy-er/desktop-commander\n",
    "  - ë‹¤ì–‘í•œ í¸ì§‘ ê¸°ëŠ¥ìœ¼ë¡œ í„°ë¯¸ë„ ëª…ë ¹ì„ ì‹¤í–‰í•˜ê³  íŒŒì¼ì„ ê´€ë¦¬í•˜ì„¸ìš”. ì½”ë”©, ì…¸ ë° í„°ë¯¸ë„, ì‘ì—… ìë™í™”\n",
    "\n",
    "**ì°¸ê³ **\n",
    "\n",
    "- smithery ì—ì„œ ì œê³µí•˜ëŠ” ë„êµ¬ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¬ë•Œ, ì•„ë˜ì˜ ì˜ˆì‹œì²˜ëŸ¼ `\"transport\": \"stdio\"` ë¡œ ê¼­ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# LLM ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatAnthropic(model=\"claude-3-7-sonnet-latest\", temperature=0, max_tokens=20000)\n",
    "\n",
    "# 1. í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"server-sequential-thinking\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@smithery-ai/server-sequential-thinking\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        },\n",
    "        \"desktop-commander\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@smithery/cli@latest\",\n",
    "                \"run\",\n",
    "                \"@wonderwhy-er/desktop-commander\",\n",
    "                \"--key\",\n",
    "                \"89a4780a-53b7-4b7b-92e9-a29815f2669b\",\n",
    "            ],\n",
    "            \"transport\": \"stdio\",  # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹ ì„ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "        },\n",
    "        \"document-retriever\": {\n",
    "            \"command\": \"./.venv/bin/python\",\n",
    "            # mcp_server_rag.py íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "            \"args\": [\"./mcp_server_rag.py\"],\n",
    "            # stdio ë°©ì‹ìœ¼ë¡œ í†µì‹  (í‘œì¤€ ì…ì¶œë ¥ ì‚¬ìš©)\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 2. ëª…ì‹œì ìœ¼ë¡œ ì—°ê²° ì´ˆê¸°í™”\n",
    "await client.__aenter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "langgraph ì˜ `create_react_agent` ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(recursion_limit=30, thread_id=3)\n",
    "agent = create_react_agent(model, client.get_tools(), checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Desktop Commander` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í„°ë¯¸ë„ ëª…ë ¹ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": \"í˜„ì¬ ê²½ë¡œë¥¼ í¬í•¨í•œ í•˜ìœ„ í´ë” êµ¬ì¡°ë¥¼ tree ë¡œ ê·¸ë ¤ì¤˜. ë‹¨, .venv í´ë”ëŠ” ì œì™¸í•˜ê³  ì¶œë ¥í•´ì¤˜.\"\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë²ˆì—ëŠ” `Sequential Thinking` ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„êµì  ë³µì¡í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    agent,\n",
    "    {\n",
    "        \"messages\": (\n",
    "            \"`retriever` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ì‚¼ì„±ì „ìê°€ ê°œë°œí•œ ìƒì„±í˜• AI ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ê³  \"\n",
    "            \"`Sequential Thinking` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ì¤˜.\"\n",
    "        )\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
